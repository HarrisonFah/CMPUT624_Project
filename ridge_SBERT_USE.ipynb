{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eO1tSqzp8YE"
   },
   "source": [
    "This file contains the implementation of ridge (L2) regression for mapping fMRI embeddings to CLIP and word2vec embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d14zQ3DZq6MK"
   },
   "source": [
    "First setup baseline model (word2vec) (Not yet implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT4mOgANq4sG",
    "outputId": "da6cf362-0555-454c-8199-8c5feabb7ffb"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# semeval-2016-2017-task3-subtaskA-unannotated\n",
    "model = api.load(\"glove-twitter-25\")  # download the model and return as object ready for use\n",
    "# model.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 12:49:25.729961: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GahCiBSmdpZc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import nibabel as nib\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "# from google.colab import drive\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z63hCATpLLOt",
    "outputId": "b6eba5ad-53b3-4753-d60a-a774b16e59c8"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n",
    "fMRI_folder = Path('./doi_10.5061_dryad.gt413__v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1SWm20pKzuU",
    "outputId": "0b848180-1242-48c4-c82d-06e6e80349b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 0\n",
      "Subject: 1\n",
      "Subject: 2\n",
      "Subject: 3\n",
      "Subject: 4\n",
      "Subject: 5\n",
      "Subject: 6\n",
      "Subject: 7\n"
     ]
    }
   ],
   "source": [
    "NUM_SUBJS = 8\n",
    "subjects_fmri = [] #stores all 8 subject fmri np arrays\n",
    "\n",
    "# fMRI_folder = Path('./doi_10.5061_dryad.gt413__v1')\n",
    "# assert fMRI_folder.exists(), f\"Foldder: {fMRI_folder} does not exist.\"\n",
    "\n",
    "for subj_id in range(8):\n",
    "    print(\"Subject:\",subj_id)\n",
    "#     fmri_file_name = str(subj_id) + '_masked_2d.npy'\n",
    "#     fmri = np.load(fMRI_folder / fmri_file_name)\n",
    "    fmri_file_name = str(subj_id) + '_smooth_nifti_4d.nii'\n",
    "    fmri = nib.load(fMRI_folder / fmri_file_name)\n",
    "    fmri = np.array(fmri.dataobj)\n",
    "    assert isinstance(fmri, np.ndarray), f\"Imported fmri_scan for subject {subj_id} is not of type numpy.ndarray\"\n",
    "    assert(fmri.ndim) == 4, f\"Imported fmri_scan for subject {subj_id} is not 4 dimensional\"\n",
    "    subjects_fmri.append(fmri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBZTp5VgVEom",
    "outputId": "dfe79b3d-f7d0-4b42-c69b-6a7635586ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n"
     ]
    }
   ],
   "source": [
    "for x in subjects_fmri:\n",
    "    print(np.shape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 60 50\n",
      "51 60 49\n",
      "53 59 47\n",
      "53 59 44\n",
      "51 59 45\n",
      "49 56 51\n",
      "52 60 49\n",
      "52 60 48\n"
     ]
    }
   ],
   "source": [
    "mat_files = sorted(list(fMRI_folder.glob('subject_*.mat')))\n",
    "sub_num = 0\n",
    "matrices = []\n",
    "for file in mat_files:\n",
    "    mat_contents = sio.loadmat(file)\n",
    "    matrix = np.zeros((np.shape(subjects_fmri[sub_num])[3],mat_contents[\"meta\"][0][0][2][0][0],))\n",
    "    fmri = subjects_fmri[int(str(file)[-5])-1]\n",
    "    #print(np.shape(fmri))\n",
    "    #print(mat_contents[\"meta\"])\n",
    "\n",
    "    print(mat_contents[\"meta\"][0][0][3][0][0],mat_contents[\"meta\"][0][0][4][0][0],mat_contents[\"meta\"][0][0][5][0][0])\n",
    "    for x in range(mat_contents[\"meta\"][0][0][3][0][0]):\n",
    "        for y in range(mat_contents[\"meta\"][0][0][4][0][0]):\n",
    "            for z in range(mat_contents[\"meta\"][0][0][5][0][0]):\n",
    "                col = mat_contents[\"meta\"][0][0][7][x][y][z]\n",
    "                matrix[:,col] = fmri[x-1][y-1][z-1][:]\n",
    "    matrices.append(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HKm-vOaOJwZH"
   },
   "outputs": [],
   "source": [
    "feature_matrix = np.zeros((5176,195)) #stores the feature vectors as a row for each word\n",
    "feature_names = [] #stores the names of all features in order\n",
    "feature_types = {} #stores the types of features and all the names of the features for each type\n",
    "\n",
    "features = sio.loadmat(fMRI_folder/'story_features.mat')\n",
    "feature_count = 0\n",
    "for feature_type in features['features'][0]:\n",
    "    feature_types[feature_type[0][0]] = []\n",
    "    if isinstance(feature_type[1][0], str):\n",
    "        feature_types[feature_type[0][0]].append(feature_type[1][0])\n",
    "        feature_names.append(feature_type[1][0])\n",
    "    else:\n",
    "        for feature in feature_type[1][0]:\n",
    "            feature_types[feature_type[0][0]].append(feature[0])\n",
    "            feature_names.append(feature[0])\n",
    "    feature_matrix[:, feature_count:feature_count+feature_type[2].shape[1]] = feature_type[2] #adds the (5176xN) feature values to the feature matrix for the current feature group\n",
    "    feature_count += feature_type[2].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9Ks5wTcKJmjz"
   },
   "outputs": [],
   "source": [
    "words_info = [] #stores tuples of (word, time, features) sorted by time appeared\n",
    "\n",
    "mat_file = 'subject_1.mat' #only looks at the first subject file, somewhere it said all the timings were the same so this should be safe\n",
    "mat_contents = sio.loadmat(fMRI_folder/mat_file)\n",
    "# print(mat_content)\n",
    "for count, row in enumerate(mat_contents['words'][0]):\n",
    "    word_value = row[0][0][0][0]\n",
    "    time = row[1][0][0]\n",
    "    \n",
    "    word_tuple = (word_value, time, feature_matrix[count,:])\n",
    "    words_info.append(word_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DP3j_XQJnJR",
    "outputId": "094873e7-c700-4223-84ae-087150e3f246"
   },
   "outputs": [],
   "source": [
    "chapter_nine_text = \"\"\n",
    "for row in mat_contents['words'][0]:\n",
    "    chapter_nine_text += row[0][0][0][0] + \" \"\n",
    "# print(chapter_nine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjvOavtmUsTG",
    "outputId": "a69f8cd4-dd3c-47be-99a2-b1fcfdf391de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (53, 60, 50, 1311)\n",
      "1 (53, 60, 50, 1311)\n",
      "2 (53, 60, 50, 1311)\n",
      "3 (53, 60, 50, 1311)\n",
      "4 (53, 60, 50, 1311)\n",
      "5 (53, 60, 50, 1311)\n",
      "6 (53, 60, 50, 1311)\n",
      "7 (53, 60, 50, 1311)\n"
     ]
    }
   ],
   "source": [
    "for count, subject in enumerate(subjects_fmri):\n",
    "    print(count, np.shape(subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fmri_indices', 'rb') as f:\n",
    "    fmri_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrf_alignment_2(num_words, words_info, NUM_SUBJS, subjects_fmri):\n",
    "    #for each word, get the next 4 fMRI scans weighted by the gaussian window for each subject\n",
    "    #then save the word fMRI scans for each subject and the words in an pandas file\n",
    "    window = signal.windows.gaussian(16, std=1) #gaussian window for the 4 fMRI scans\n",
    "    subject_words_dict = [{'file_name':[], 'word':[], 'time':[]} for i in range(8)]\n",
    "    for word_count in words_info:\n",
    "        word = word_count[0]\n",
    "        time = word_count[1]\n",
    "        #print(word, time)\n",
    "        fmri_count = 0\n",
    "        subject_scans = []\n",
    "        for i in range(1,17):\n",
    "            delay = 0.5*i #time after word was read\n",
    "            try:\n",
    "                curr_fmri_idx = fmri_indices.index((time + delay)/2) #checks if an fMRI scan happens at this time point\n",
    "                weight = window[int(2*delay)-1]\n",
    "                for count, subject in enumerate(subjects_fmri):\n",
    "                    if fmri_count == 0:\n",
    "                        subject_scans.append(weight*subject[:,:,:,curr_fmri_idx])\n",
    "                    else:\n",
    "                        subject_scans[count] += weight*subject[:,:,:,curr_fmri_idx]\n",
    "                fmri_count += 1\n",
    "            except Exception as e:\n",
    "                #print(e)\n",
    "                pass\n",
    "        #print(fmri_count)\n",
    "        if fmri_count == 4:\n",
    "            for count, subject in enumerate(subjects_fmri):\n",
    "                #save filename with (word, time) in file\n",
    "                file_name = \"./word_fmris/\" + str(count) + \"_subject_word_weighted_\" + str(time) + \".pt\"\n",
    "                scan = torch.tensor(subject_scans[count])\n",
    "                with open(file_name, 'wb') as f:\n",
    "                    torch.save(scan, f)\n",
    "                subject_words_dict[count]['file_name'].append(file_name)\n",
    "                subject_words_dict[count]['word'].append(word)\n",
    "                subject_words_dict[count]['time'].append(time)\n",
    "        for count, subject in enumerate(subjects_fmri):\n",
    "            df = pd.DataFrame(subject_words_dict[count])\n",
    "            df.to_csv(\"./\" + str(count) + \"_subject_word_fmri_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muTykRqfJcpY"
   },
   "source": [
    "Harrison's implementation of Gaussian weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FOE-RCeGJcNV"
   },
   "outputs": [],
   "source": [
    "def hrf_alignment(num_words, words_info, NUM_SUBJS, subjects_fmri):\n",
    "\n",
    "    subjects_samples = [[] for i in range(NUM_SUBJS)] #stores lists of all the samples for each subject\n",
    "    window = signal.windows.gaussian(16, std=1) #gaussian window for the 4 fMRI scans\n",
    "    num_words = num_words\n",
    "    word_count = 0\n",
    "    while word_count < len(words_info) - 24:\n",
    "        #gets the 4 input words, and the 4 consecutive words while verifying they were read in sequence\n",
    "        scan_words = []\n",
    "        start_time = words_info[word_count][1]\n",
    "        in_sequence = True #tracks if the words are in sequence or not\n",
    "        for i in range(num_words):\n",
    "            word_info = words_info[word_count + i]\n",
    "            if word_info[1] != start_time + 0.5*i:\n",
    "                #if some of the words are not in sequence, skip forward 1 word after innter loop\n",
    "                in_sequence = False\n",
    "            scan_words.append(word_info[0])\n",
    "        if not in_sequence:\n",
    "            word_count +=1\n",
    "            continue\n",
    "        fmri_time = start_time #fMRI is taken at first word read\n",
    "        fmri_index = fmri_time//2 #since a scan happens every two seconds, the index is the time divided by 2\n",
    "        if not np.issubdtype(fmri_index, np.integer):\n",
    "            #if the first word is not aligned with the fmri scan (i.e. its not the first word in a TR)\n",
    "            word_count += 1\n",
    "            continue\n",
    "        break_found = False\n",
    "        for count, subject in enumerate(subjects_fmri):\n",
    "#             print(\"Subject:\",count)\n",
    "            #adds tuple of (fmri_scan, four words)\n",
    "            for i in range(num_words): #time delay of reading word after fMRI scan\n",
    "                delay = 0.5*i #delay after first word\n",
    "                for j in range(1,5): #get next 4 fMRI scans\n",
    "                    fMRI_delay = 2*j - delay #delay until jth next fMRI scan\n",
    "                    weight = window[int(2*fMRI_delay)-1] #gets the gaussian weighting (16 points instead of 8 to allow for .5)\n",
    "                    try:\n",
    "                        curr_fmri_idx = fmri_indices.index((start_time + math.floor(i/4) + 2*j)//2) #gets the index of the jth next fMRI scan\n",
    "                    except:\n",
    "#                         print(\"break found at index:\",(start_time + math.floor(i/4) + 2*j)//2)\n",
    "                        break_found = True\n",
    "                        break\n",
    "                    #adds weight fMRI scan\n",
    "                    if j == 1:\n",
    "                        word_scan = weight*subject[:][curr_fmri_idx]\n",
    "                    else:\n",
    "                        word_scan += weight*subject[:][curr_fmri_idx]\n",
    "                if break_found:\n",
    "                    break\n",
    "                if i == 0:\n",
    "                    summed_weighted_scans = word_scan\n",
    "                else:\n",
    "                    summed_weighted_scans += word_scan\n",
    "            if break_found:\n",
    "                break\n",
    "            subjects_samples[count].append((summed_weighted_scans/num_words, scan_words))\n",
    "        if break_found:\n",
    "            word_count += 1\n",
    "            continue \n",
    "#         print(\"Created sample:\")\n",
    "#         print(\"\\tScan time:\", str(start_time))\n",
    "#         print(\"\\tInput words:\", str(scan_words))\n",
    "        #if successful, skip forward to the next set of 4 words\n",
    "        word_count += 4\n",
    "    return subjects_samples\n",
    "\n",
    "    print(\"Total number of samples:\", str(len(subjects_samples[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hDooPY-xnS96"
   },
   "outputs": [],
   "source": [
    "def get_fMRI_embedding(subjects_samples):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    flattened_shape = reduce(np.multiply, subjects_samples[0][0].shape)\n",
    "    X_matrix = np.zeros((len(subjects_samples), flattened_shape))\n",
    "\n",
    "    for idx, sample in enumerate(subjects_samples):\n",
    "        tmp = sample[0]\n",
    "        # Reshape the voxels \n",
    "        tmp = tmp.ravel()\n",
    "        X_matrix[idx,:] = tmp\n",
    "        \n",
    "    # Apply voxelwise standardization        \n",
    "    X_matrix = scaler.fit_transform(X_matrix)\n",
    "    #print(np.shape(X_matrix))\n",
    "    return X_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZoeD2JzgXvSY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, DistilBertTokenizer,DistilBertModel\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SBERT_embedding(subject_sample):\n",
    "    word_list = []\n",
    "    context_length = 0\n",
    "\n",
    "    for i in range(len(subject_sample)):\n",
    "        context_length = len(subject_sample[i][1])\n",
    "        word_list.append(subject_sample[i][1])\n",
    "    new_word_list = [(' '.join(sublist)) for sublist in word_list]\n",
    "    print(context_length)\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    x = model.encode(new_word_list,convert_to_tensor=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "#module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "#model = hub.load(module_url)\n",
    "#print (\"module %s loaded\" % module_url)\n",
    "##def embed(input):\n",
    " # return model(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/large/versions/2\"\n",
    "model_USE = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_USE_embedding(subject_sample):\n",
    "    word_list = []\n",
    "    context_length = 0\n",
    "\n",
    "    for i in range(len(subject_sample)):\n",
    "        context_length = len(subject_sample[i][1])\n",
    "        word_list.append(subject_sample[i][1])\n",
    "    new_word_list = [(' '.join(sublist)) for sublist in word_list]\n",
    "    #print(new_word_list)\n",
    "    #print(context_length)\n",
    "    #model = hub.load(module_url)\n",
    "    #print (\"module %s loaded\" % module_url)\n",
    "    sentence_embeddings = model_USE(new_word_list)\n",
    "\n",
    "    return np.array(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_matrix = get_USE_embedding(subjects_samples[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1235, 512)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jai's Implementation of clip embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_embedding(subject_sample, model,processor):\n",
    "    word_list = []\n",
    "    for i in range(len(subject_sample)):\n",
    "        word_list.append(subject_sample[i][1])\n",
    "    new_word_list = [' '.join(sublist) for sublist in word_list]\n",
    "\n",
    "    inputs = processor(text=new_word_list, images=image, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # text_embeds is in the same space as the given image\n",
    "        text_embeds = outputs['text_embeds']\n",
    "\n",
    "        # pooler_output is just the text embedding \n",
    "        # This is what we want to use I think \n",
    "        pooler_output = outputs['text_model_output']['pooler_output']\n",
    "#         print(pooler_output.numpy().shape)\n",
    "    #return pooler_output\n",
    "    return text_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UzhyDXB3qNsU"
   },
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "\n",
    "def split_data(X_matrix, Y_matrix):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_matrix, y_matrix,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=1234,\n",
    "                                                        shuffle=False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XTAuddpyeVcI"
   },
   "outputs": [],
   "source": [
    "# Train Ridge Regression Model\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    model = ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "D_M1TZx5Ru1n"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, random_text_embedding):\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Predict text embedding from test fMRI data\n",
    "    y_pred = model.predict(X_test)\n",
    "#     print(np.shape(y_pred))\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    prediction_similarity_true = cosine_similarity(y_test, y_pred)\n",
    "    prediction_similarity_random = cosine_similarity(random_text_embedding, y_pred)\n",
    "#     print(np.shape(prediction_similarity_true), np.shape(prediction_similarity_true))\n",
    "    \n",
    "     # Count the occurrences of \"1\" in the first column    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if prediction_similarity_true[i].mean() >= prediction_similarity_random[i].mean():\n",
    "            correct_predictions +=1\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = (correct_predictions / X_test.shape[0])\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Z4cuRbSqqRza",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_two_way_class_result(model, X_test, y_test, y_matrix, batches):\n",
    "    accuracy = []\n",
    "    for i in range(batches):\n",
    "        idx = np.arange(len(y_test))\n",
    "        np.random.shuffle(idx)\n",
    "\n",
    "        random_text_embedding = y_matrix[idx]\n",
    "\n",
    "        test_accuracy = evaluate_model(model, X_test, y_test, random_text_embedding)\n",
    "        accuracy.append(test_accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracy)/ batches\n",
    "    \n",
    "    #print(accuracy)\n",
    "    #print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NEaDKYWTR7Mp",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining aligned fMRI scan for context length: 4---------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kp/2c01k3yd3mxf7_5q6bcqn7rm0000gn/T/ipykernel_10147/4179916272.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Step 1: Obtain aligned fMRI embedding with words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msubjects_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhrf_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_SUBJS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#y_matrix = get_BERT_embedding(subjects_samples[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_USE_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kp/2c01k3yd3mxf7_5q6bcqn7rm0000gn/T/ipykernel_10147/784498596.py\u001b[0m in \u001b[0;36mhrf_alignment\u001b[0;34m(num_words, words_info, NUM_SUBJS, subjects_fmri)\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;31m#adds weight fMRI scan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                         \u001b[0mword_scan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_fmri_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mword_scan\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_fmri_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "context_lengths = [4,8,12,16,20]\n",
    "NUM_SUBJS = 8\n",
    "\n",
    "for length in context_lengths:\n",
    "    # Step 1: Obtain aligned fMRI embedding with words\n",
    "    print(f'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------')\n",
    "    subjects_samples = hrf_alignment(length, words_info, NUM_SUBJS, matrices)\n",
    "    #y_matrix = get_BERT_embedding(subjects_samples[0])\n",
    "    y_matrix = get_USE_embedding(subjects_samples[0])\n",
    "\n",
    "    #y_matrix = get_clip_embedding(subjects_samples[0],model,processor)\n",
    "\n",
    "    # Step 2: Obtain text and fMRI embedding\n",
    "    # get embeddings for subject 1\n",
    "    for subject in range(NUM_SUBJS):\n",
    "        #print(f'---------Obtaining clip and fMRI embedding for subject {subject}-----------------')\n",
    "        #y_matrix = get_clip_embedding(subjects_samples[subject],model,processor)\n",
    "        X_matrix = get_fMRI_embedding(subjects_samples[subject])\n",
    "        #print(f'Subject {subject} \\n fMRI Embedding Shape: {np.shape(X_matrix)} \\n Text Embedding Shape: {np.shape(y_matrix)}')\n",
    "\n",
    "        # Split data for training\n",
    "        #print(f'---------Spliting data for subject {subject}-----------------')\n",
    "        #X_train, X_test, y_train, y_test = split_data(X_matrix, y_matrix)        #print(f'---------Training started for subject {subject}-----------------')\n",
    "        # Train model\n",
    "        model_ = train_model(X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        #print(f'---------Getting two way classification accuracy for subject {subject}-----------------\\n')\n",
    "\n",
    "        batches = 8\n",
    "        accuracy = obtain_two_way_class_result(model_, X_test, y_test, y_matrix, batches)\n",
    "        \n",
    "        print(f'{accuracy*100:.2f}')\n",
    "        \n",
    "##use2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining aligned fMRI scan for context length: 4---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous-multioutput is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous-multioutput is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous-multioutput is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous-multioutput is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:839: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 355, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 220, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous-multioutput is not supported\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kp/2c01k3yd3mxf7_5q6bcqn7rm0000gn/T/ipykernel_10147/1567240324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobtain_two_way_class_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{accuracy*100:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "context_lengths = [4,8,12,16,20]\n",
    "NUM_SUBJS = 8\n",
    "\n",
    "for length in context_lengths:\n",
    "    # Step 1: Obtain aligned fMRI embedding with words\n",
    "    print(f'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------')\n",
    "    subjects_samples = hrf_alignment(length, words_info, NUM_SUBJS, matrices)\n",
    "    #y_matrix = get_BERT_embedding(subjects_samples[0])\n",
    "    y_matrix = get_USE_embedding(subjects_samples[0])\n",
    "\n",
    "    #y_matrix = get_clip_embedding(subjects_samples[0],model,processor)\n",
    "\n",
    "    # Step 2: Obtain text and fMRI embedding\n",
    "    # get embeddings for subject 1\n",
    "    for subject in range(NUM_SUBJS):\n",
    "        #print(f'---------Obtaining clip and fMRI embedding for subject {subject}-----------------')\n",
    "        #y_matrix = get_clip_embedding(subjects_samples[subject],model,processor)\n",
    "        X_matrix = get_fMRI_embedding(subjects_samples[subject])\n",
    "        #print(f'Subject {subject} \\n fMRI Embedding Shape: {np.shape(X_matrix)} \\n Text Embedding Shape: {np.shape(y_matrix)}')\n",
    "        #cv = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "        # Split data for training\n",
    "        #print(f'---------Spliting data for subject {subject}-----------------')\n",
    "        #X_train, X_test, y_train, y_test = split_data(X_matrix, y_matrix)\n",
    "        \n",
    "        #print(f'---------Training started for subject {subject}-----------------')\n",
    "        # Train model\n",
    "        model_ = Ridge(alpha=1.0)\n",
    "        kf = KFold(n_splits=5)\n",
    "        # Evaluate model\n",
    "        #print(f'---------Getting two way classification accuracy for subject {subject}-----------------\\n')\n",
    "        print(cross_val_score(model_, X_matrix, y_matrix, cv=kf,scoring=\"accuracy\"))\n",
    "        batches = 8\n",
    "        accuracy = obtain_two_way_class_result(model_, X_test, y_test, y_matrix, batches)\n",
    "        \n",
    "        print(f'{accuracy*100:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
