{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import CLIPConfig, CLIPModel, CLIPProcessor, CLIPImageProcessor, CLIPTokenizerFast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from gensim.models import Word2Vec\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load word and fMRI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 3d fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SUBJS = 8\n",
    "subjects_fmri = [] #stores all 8 subject fmri np arrays\n",
    "\n",
    "fMRI_folder = Path('./doi_10.5061_dryad.gt413__v1')\n",
    "assert fMRI_folder.exists(), f\"Foldder: {fMRI_folder} does not exist.\"\n",
    "\n",
    "for subj_id in range(8):\n",
    "#     fmri_file_name = str(subj_id) + '_masked_2d.npy'\n",
    "#     fmri = np.load(fMRI_folder / fmri_file_name)  \n",
    "    fmri_file_name = str(subj_id) + '_smooth_nifti_4d.nii'\n",
    "    fmri = nib.load(fMRI_folder / fmri_file_name)\n",
    "    fmri = np.array(fmri.dataobj)\n",
    "    assert isinstance(fmri, np.ndarray), f\"Imported fmri_scan for subject {subj_id} is not of type numpy.ndarray\"\n",
    "    assert(fmri.ndim) == 4, f\"Imported fmri_scan for subject {subj_id} is not 4 dimensional\"\n",
    "    subjects_fmri.append(fmri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.zeros((5176,195)) #stores the feature vectors as a row for each word\n",
    "feature_names = [] #stores the names of all features in order\n",
    "feature_types = {} #stores the types of features and all the names of the features for each type\n",
    "\n",
    "features = sio.loadmat(fMRI_folder / 'story_features.mat')\n",
    "feature_count = 0\n",
    "for feature_type in features['features'][0]:\n",
    "    feature_types[feature_type[0][0]] = []\n",
    "    if isinstance(feature_type[1][0], str):\n",
    "        feature_types[feature_type[0][0]].append(feature_type[1][0])\n",
    "        feature_names.append(feature_type[1][0])\n",
    "    else:\n",
    "        for feature in feature_type[1][0]:\n",
    "            feature_types[feature_type[0][0]].append(feature[0])\n",
    "            feature_names.append(feature[0])\n",
    "    feature_matrix[:, feature_count:feature_count+feature_type[2].shape[1]] = feature_type[2] #adds the (5176xN) feature values to the feature matrix for the current feature group\n",
    "    feature_count += feature_type[2].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_info = [] #stores tuples of (word, time, features) sorted by time appeared\n",
    "\n",
    "mat_file = fMRI_folder / 'subject_1.mat' #only looks at the first subject file, somewhere it said all the timings were the same so this should be safe\n",
    "mat_contents = sio.loadmat(mat_file)\n",
    "for count, row in enumerate(mat_contents['words'][0]):\n",
    "    word_value = row[0][0][0][0]\n",
    "    time = row[1][0][0]\n",
    "    word_tuple = (word_value, time, feature_matrix[count,:])\n",
    "    words_info.append(word_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry had never believed he would meet a boy he hated more than Dudley, but that was before he met Draco Malfoy. Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have to put up with Malfoy much. Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common room that made them all groan. Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin would be learning together. + \"Typical,\" said Harry darkly. \"Just what I always wanted. To make a fool of myself on a broomstick in front of Malfoy.\" + He had been looking forward to learning to fly more than anything else. \"You don't know that you'll make a fool of yourself,\" said Ron reasonably. \"Anyway, I know Malfoy's always going on about how good he is at Quidditch, but I bet that's all talk.\" + Malfoy certainly did talk about flying a lot. He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end with him narrowly escaping Muggles in helicopters. He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood zooming around the countryside on his broomstick. Even Ron would tell anyone who'd listen about the time he'd almost hit a hang glider on Charlie's old broom. Everyone from wizarding families talked about Quidditch constantly. Ron had already had a big argument with Dean Thomas, who shared their dormitory, about soccer. Ron couldn't see what was exciting about a game with only one ball where no one was allowed to fly. Harry had caught Ron prodding Dean's poster of West Ham soccer team, trying to make the players move. + Neville had never been on a broomstick in his life, because his grandmother had never let him near one. Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number of accidents even with both feet on the ground. + Hermione Granger was almost as nervous about flying as Neville was. This was something you couldn't learn by heart out of a book -- not that she hadn't tried. At breakfast on Thursday she bored them all stupid with flying tips she'd gotten out of a library book called @Quidditch @Through @the @Ages. Neville was hanging on to her every word, desperate for anything that might help him hang on to his broomstick later, but everybody else was very pleased when Hermione's lecture was interrupted by the arrival of the mail. + Harry hadn't had a single letter since Hagrid's note, something that Malfoy had been quick to notice, of course. Malfoy's eagle owl was always bringing him packages of sweets from home, which he opened gloatingly at the Slytherin table. + A barn owl brought Neville a small package from his grandmother. He opened it excitedly and showed them a glass ball the size of a large marble, which seemed to be full of white smoke. + \"It's a Remembrall!\" he explained. \"Gran knows I forget things -- this tells you if there's something you've forgotten to do. Look, you hold it tight like this and if it turns red -- oh …\" His face fell, because the Remembrall had suddenly glowed scarlet, \"… you've forgotten something …\" + Neville was trying to remember what he'd forgotten when Draco Malfoy, who was passing the Gryffindor table, snatched the Remembrall out of his hand. + Harry and Ron jumped to their feet. They were half hoping for a reason to fight Malfoy, but Professor McGonagall, who could spot trouble quicker than any teacher in the school, was there in a flash. + \"What's going on?\" + \"Malfoy's got my Remembrall, Professor.\" + Scowling, Malfoy quickly dropped the Remembrall back on the table. + \"Just looking,\" he said, and he sloped away with Crabbe and Goyle behind him. + + At three-thirty that afternoon, Harry, Ron, and the other Gryffindors hurried down the front steps onto the grounds for their first flying lesson. It was a clear, breezy day, and the grass rippled under their feet as they marched down the sloping lawns toward a smooth, flat lawn on the opposite side of the grounds to the forbidden forest, whose trees were swaying darkly in the distance. + The Slytherins were already there, and so were twenty broomsticks lying in neat lines on the ground. Harry had heard Fred and George Weasley complain about the school brooms, saying that some of them started to vibrate if you flew too high, or always flew slightly to the left. + Their teacher, Madam Hooch, arrived. She had short, gray hair, and yellow eyes like a hawk. + \"Well, what are you all waiting for?\" she barked. \"Everyone stand by a broomstick. Come on, hurry up.\" + Harry glanced down at his broom. It was old and some of the twigs stuck out at odd angles. + \"Stick out your right hand over your broom,\" called Madam Hooch at the front, \"and say ‘Up!'\" + \"UP!\" everyone shouted. + Harry's broom jumped into his hand at once, but it was one of the few that did. Hermione Granger's had simply rolled over on the ground, and Neville's hadn't moved at all. Perhaps brooms, like horses, could tell when you were afraid, thought Harry; there was a quaver in Neville's voice that said only too clearly that he wanted to keep his feet on the ground. + Madam Hooch then showed them how to mount their brooms without sliding off the end, and walked up and down the rows correcting their grips. Harry and Ron were delighted when she told Malfoy he'd been doing it wrong for years. + \"Now, when I blow my whistle, you kick off from the ground, hard,\" said Madam Hooch. \"Keep your brooms steady, rise a few feet, and then come straight back down by leaning forward slightly. On my whistle -- three -- two —\" + But Neville, nervous and jumpy and frightened of being left on the ground, pushed off hard before the whistle had touched Madam Hooch's lips. + \"Come back, boy!\" she shouted, but Neville was rising straight up like a cork shot out of a bottle -- twelve feet -- twenty feet. Harry saw his scared white face look down at the ground falling away, saw him gasp, slip sideways off the broom and -- + WHAM -- a thud and a nasty crack and Neville lay facedown on the grass in a heap. His broomstick was still rising higher and higher, and started to drift lazily toward the forbidden forest and out of sight. + Madam Hooch was bending over Neville, her face as white as his. \"Broken wrist,\" Harry heard her mutter. \"Come on, boy -- it's all right, up you get.\" + She turned to the rest of the class. \"None of you is to move while I take this boy to the hospital wing! You leave those brooms where they are or you'll be out of Hogwarts before you can say ‘Quidditch.' Come on, dear.\" + Neville, his face tear-streaked, clutching his wrist, hobbled off with Madam Hooch, who had her arm around him. + No sooner were they out of earshot than Malfoy burst into laughter. + \"Did you see his face, the great lump?\" + The other Slytherins joined in. + \"Shut up, Malfoy,\" snapped Parvati Patil. + \"Ooh, sticking up for Longbottom?\" said Pansy Parkinson, a hard-faced Slytherin girl. \"Never thought @you'd like fat little crybabies, Parvati.\" + \"Look!\" said Malfoy, darting forward and snatching something out of the grass. \"It's that stupid thing Longbottom's gran sent him.\" + The Remembrall glittered in the sun as he held it up. + \"Give that here, Malfoy,\" said Harry quietly. Everyone stopped talking to watch. + Malfoy smiled nastily. \"I think I'll leave it somewhere for Longbottom to find -- how about -- up a tree?\" + \"Give it @here!\" Harry yelled, but Malfoy had leapt onto his broomstick and taken off. He hadn't been lying, he @could fly well. Hovering level with the topmost branches of an oak he called, \"Come and get it, Potter!\" + Harry grabbed his broom. + @\"No!\" shouted Hermione Granger. \"Madam Hooch told us not to move -- you'll get us all into trouble.\" + Harry ignored her. Blood was pounding in his ears. He mounted the broom and kicked hard against the ground and up, up he soared; air rushed through his hair, and his robes whipped out behind him -- and in a rush of fierce joy he realized he'd found something he could do without being taught -- this was easy, this was @wonderful. He pulled his broomstick up a little to take it even higher, and heard screams and gasps of girls back on the ground and an admiring whoop from Ron. + He turned his broomstick sharply to face Malfoy in midair. + Malfoy looked stunned. \"Give it here,\" Harry called, \"or I'll knock you off that broom!\" + \"Oh, yeah?\" said Malfoy, trying to sneer, but looking worried. + Harry knew, somehow, what to do. He leaned forward and grasped the broom tightly in both hands, and it shot toward Malfoy like a javelin. Malfoy only just got out of the way in time; Harry made a sharp about-face and held the broom steady. A few people below were clapping. + \"No Crabbe and Goyle up here to save your neck, Malfoy,\" Harry called. + The same thought seemed to have struck Malfoy. + \"Catch it if you can, then!\" he shouted, and he threw the glass ball high into the air and streaked back toward the ground. + Harry saw, as though in slow motion, the ball rise up in the air and then start to fall. He leaned forward and pointed his broom handle down -- next second he was gathering speed in a steep dive, racing the ball -- wind whistled in his ears, mingled with the screams of people watching -- he stretched out his hand -- a foot from the ground he caught it, just in time to pull his broom straight, and he toppled gently onto the grass with the Remembrall clutched safely in his fist. + \"HARRY POTTER!\" + His heart sank faster than he'd just dived. Professor McGonagall was running toward them. He got to his feet, trembling. + @\"Never -- in all my time at Hogwarts —\" Professor McGonagall was almost speechless with shock, and her glasses flashed furiously, \"— how @dare you -- might have broken your neck —\" + \"It wasn't his fault, Professor —\" + \"Be quiet, Miss Patil —\" + \"But Malfoy —\" \"That's enough, Mr. Weasley. Potter, follow me, now.\" + Harry caught sight of Malfoy, Crabbe, and Goyle's triumphant faces as he left, walking numbly in Professor McGonagall's wake as she strode toward the castle. He was going to be expelled, he just knew it. He wanted to say something to defend himself, but there seemed to be something wrong with his voice. Professor McGonagall was sweeping along without even looking at him; he had to jog to keep up. Now he'd done it. He hadn't even lasted two weeks. He'd be packing his bags in ten minutes. What would the Dursleys say when he turned up on the doorstep? + Up the front steps, up the marble staircase inside, and still Professor McGonagall didn't say a word to him. She wrenched open doors and marched along corridors with Harry trotting miserably behind her. Maybe she was taking him to Dumbledore. He thought of Hagrid, expelled but allowed to stay on as gamekeeper. Perhaps he could be Hagrid's assistant. His stomach twisted as he imagined it, watching Ron and the others becoming wizards while he stumped around the grounds carrying Hagrid's bag. + Professor McGonagall stopped outside a classroom. She opened the door and poked her head inside. + \"Excuse me, Professor Flitwick, could I borrow Wood for a moment?\" + Wood? thought Harry, bewildered; was Wood a cane she was going to use on him? But Wood turned out to be a person, a burly fifth-year boy who came out of Flitwick's class looking confused. + \"Follow me, you two,\" said Professor McGonagall, and they marched on up the corridor, Wood looking curiously at Harry. + \"In here.\" + Professor McGonagall pointed them into a classroom that was empty except for Peeves, who was busy writing rude words on the blackboard. + \"Out, Peeves!\" she barked. Peeves threw the chalk into a bin, which clanged loudly, and he swooped out cursing. Professor McGonagall slammed the door behind him and turned to face the two boys. + \"Potter, this is Oliver Wood. Wood -- I've found you a Seeker.\" + Wood's expression changed from puzzlement to delight. + \"Are you serious, Professor?\" + \"Absolutely,\" said Professor McGonagall crisply. \"The boy's a natural. I've never seen anything like it. Was that your first time on a broomstick, Potter?\" + Harry nodded silently. He didn't have a clue what was going on, but he didn't seem to be being expelled, and some of the feeling started coming back to his legs. + \"He caught that thing in his hand after a fifty-foot dive,\" Professor McGonagall told Wood. \"Didn't even scratch himself. Charlie Weasley couldn't have done it.\" + Wood was now looking as though all his dreams had come true at once. + \"Ever seen a game of Quidditch, Potter?\" he asked excitedly. + \"Wood's captain of the Gryffindor team,\" Professor McGonagall explained. + \"He's just the build for a Seeker, too,\" said Wood, now walking around Harry and staring at him. \"Light -- speedy -- we'll have to get him a decent broom, Professor -- a Nimbus Two Thousand or a Cleansweep Seven, I'd say.\" + \"I shall speak to Professor Dumbledore and see if we can't bend the first-year rule. Heaven knows, we need a better team than last year. Flattened in that last match by Slytherin, I couldn't look Severus Snape in the face for weeks. ….\" + Professor McGonagall peered sternly over her glasses at Harry. + \"I want to hear you're training hard, Potter, or I may change my mind about punishing you.\" + Then she suddenly smiled. + \"Your father would have been proud,\" she said. \"He was an excellent Quidditch player himself.\" + + \"You're @joking.\" + It was dinnertime. Harry had just finished telling Ron what had happened when he'd left the grounds with Professor McGonagall. Ron had a piece of steak and kidney pie halfway to his mouth, but he'd forgotten all about it. + @\"Seeker?\" he said. \"But first years @never -- you must be the youngest House player in about —\" + \"— a century,\" said Harry, shoveling pie into his mouth. He felt particularly hungry after the excitement of the afternoon. \"Wood told me.\" + Ron was so amazed, so impressed, he just sat and gaped at Harry. + \"I start training next week,\" said Harry. \"Only don't tell anyone, Wood wants to keep it a secret.\" + Fred and George Weasley now came into the hall, spotted Harry, and hurried over. + \"Well done,\" said George in a low voice. \"Wood told us. We're on the team too -- Beaters.\" + \"I tell you, we're going to win that Quidditch Cup for sure this year,\" said Fred. \"We haven't won since Charlie left, but this year's team is going to be brilliant. You must be good, Harry, Wood was almost skipping when he told us.\" + \"Anyway, we've got to go, Lee Jordan reckons he's found a new secret passageway out of the school.\" + \"Bet it's that one behind the statue of Gregory the Smarmy that we found in our first week. See you.\" + Fred and George had hardly disappeared when someone far less welcome turned up: Malfoy, flanked by Crabbe and Goyle. + \"Having a last meal, Potter? When are you getting the train back to the Muggles?\" + \"You're a lot braver now that you're back on the ground and you've got your little friends with you,\" said Harry coolly. There was of course nothing at all little about Crabbe and Goyle, but as the High Table was full of teachers, neither of them could do more than crack their knuckles and scowl. + \"I'd take you on anytime on my own,\" said Malfoy. \"Tonight, if you want. Wizard's duel. Wands only -- no contact. What's the matter? Never heard of a wizard's duel before, I suppose?\" + \"Of course he has,\" said Ron, wheeling around. \"I'm his second, who's yours?\" + Malfoy looked at Crabbe and Goyle, sizing them up. + \"Crabbe,\" he said. \"Midnight all right? We'll meet you in the trophy room; that's always unlocked.\" + When Malfoy had gone, Ron and Harry looked at each other. + \"What @is a wizard's duel?\" said Harry. \"And what do you mean, you're my second?\" + \"Well, a second's there to take over if you die,\" said Ron casually, getting started at last on his cold pie. Catching the look on Harry's face, he added quickly, \"But people only die in proper duels, you know, with real wizards. The most you and Malfoy'll be able to do is send sparks at each other. Neither of you knows enough magic to do any real damage. I bet he expected you to refuse, anyway.\" + \"And what if I wave my wand and nothing happens?\" + \"Throw it away and punch him on the nose,\" Ron suggested. + \"Excuse me.\" + They both looked up. It was Hermione Granger. + \"Can't a person eat in peace in this place?\" said Ron. + Hermione ignored him and spoke to Harry. \"I couldn't help overhearing what you and Malfoy were saying —\" + \"Bet you could,\" Ron muttered. + \"— and you @mustn't go wandering around the school at night, think of the points you'll lose Gryffindor if you're caught, and you're bound to be. It's really very selfish of you.\" + \"And it's really none of your business,\" said Harry. + \"Good-bye,\" said Ron. + + All the same, it wasn't what you'd call the perfect end to the day, Harry thought, as he lay awake much later listening to Dean and Seamus falling asleep (Neville wasn't back from the hospital wing). Ron had spent all evening giving him advice such as \"If he tries to curse you, you'd better dodge it, because I can't remember how to block them.\" There was a very good chance they were going to get caught by Filch or Mrs. Norris, and Harry felt he was pushing his luck, breaking another school rule today. On the other hand, Malfoy's sneering face kept looming up out of the darkness -- this was his big chance to beat Malfoy face-to-face. He couldn't miss it. + \"Half-past eleven,\" Ron muttered at last, \"we'd better go.\" + They pulled on their bathrobes, picked up their wands, and crept across the tower room, down the spiral staircase, and into the Gryffindor common room. A few embers were still glowing in the fireplace, turning all the armchairs into hunched black shadows. They had almost reached the portrait hole when a voice spoke from the chair nearest them, \"I can't believe you're going to do this, Harry.\" + A lamp flickered on. It was Hermione Granger, wearing a pink bathrobe and a frown. + @\"You!\" said Ron furiously. \"Go back to bed!\" + \"I almost told your brother,\" Hermione snapped, \"Percy -- he's a prefect, he'd put a stop to this.\" + Harry couldn't believe anyone could be so interfering. + \"Come on,\" he said to Ron. He pushed open the portrait of the Fat Lady and climbed through the hole. + Hermione wasn't going to give up that easily. She followed Ron through the portrait hole, hissing at them like an angry goose. \"Don't you @care about Gryffindor, do you @only care about yourselves, I don't want Slytherin to win the House Cup, and you'll lose all the points I got from Professor McGonagall for knowing about Switching Spells.\" + \"Go away.\" + \"All right, but I warned you, you just remember what I said when you're on the train home tomorrow, you're so —\" + But what they were, they didn't find out. Hermione had turned to the portrait of the Fat Lady to get back inside and found herself facing an empty painting. The Fat Lady had gone on a nighttime visit and Hermione was locked out of Gryffindor Tower. + \"Now what am I going to do?\" she asked shrilly. + \"That's your problem,\" said Ron. \"We've got to go, we're going to be late.\" + They hadn't even reached the end of the corridor when Hermione caught up with them. + \"I'm coming with you,\" she said. \"You are @not.\" + \"D'you think I'm going to stand out here and wait for Filch to catch me? If he finds all three of us I'll tell him the truth, that I was trying to stop you, and you can back me up.\" + \"You've got some nerve —\" said Ron loudly. + \"Shut up, both of you!\" said Harry sharply. \"I heard something.\" + It was a sort of snuffling. + \"Mrs. Norris?\" breathed Ron, squinting through the dark. + It wasn't Mrs. Norris. It was Neville. He was curled up on the floor, fast asleep, but jerked suddenly awake as they crept nearer. + \"Thank goodness you found me! I've been out here for hours, I couldn't remember the new password to get in to bed.\" + \"Keep your voice down, Neville. The password's ‘Pig snout' but it won't help you now, the Fat Lady's gone off somewhere.\" + \"How's your arm?\" said Harry. + \"Fine,\" said Neville, showing them. \"Madam Pomfrey mended it in about a minute.\" + \"Good -- well, look, Neville, we've got to be somewhere, we'll see you later —\" + \"Don't leave me!\" said Neville, scrambling to his feet, \"I don't want to stay here alone, the Bloody Baron's been past twice already.\" + Ron looked at his watch and then glared furiously at Hermione and Neville. + \"If either of you get us caught, I'll never rest until I've learned that Curse of the Bogies Quirrell told us about, and used it on you.\" + Hermione opened her mouth, perhaps to tell Ron exactly how to use the Curse of the Bogies, but Harry hissed at her to be quiet and beckoned them all forward. + They flitted along corridors striped with bars of moonlight from the high windows. At every turn Harry expected to run into Filch or Mrs. Norris, but they were lucky. They sped up a staircase to the third floor and tiptoed toward the trophy room. + Malfoy and Crabbe weren't there yet. The crystal trophy cases glimmered where the moonlight caught them. Cups, shields, plates, and statues winked silver and gold in the darkness. They edged along the walls, keeping their eyes on the doors at either end of the room. Harry took out his wand in case Malfoy leapt in and started at once. The minutes crept by. + \"He's late, maybe he's chickened out,\" Ron whispered. + Then a noise in the next room made them jump. Harry had only just raised his wand when they heard someone speak -- and it wasn't Malfoy. + \"Sniff around, my sweet, they might be lurking in a corner.\" + It was Filch speaking to Mrs. Norris. Horror-struck, Harry waved madly at the other three to follow him as quickly as possible; they scurried silently toward the door, away from Filch's voice. Neville's robes had barely whipped round the corner when they heard Filch enter the trophy room. + \"They're in here somewhere,\" they heard him mutter, \"probably hiding.\" + \"This way!\" Harry mouthed to the others and, petrified, they began to creep down a long gallery full of suits of armor. + They could hear Filch getting nearer. Neville suddenly let out a frightened squeak and broke into a run -- he tripped, grabbed Ron around the waist, and the pair of them toppled right into a suit of armor. + The clanging and crashing were enough to wake the whole castle. + \"RUN!\" Harry yelled, and the four of them sprinted down the gallery, not looking back to see whether Filch was following -- they swung around the doorpost and galloped down one corridor then another, Harry in the lead, without any idea where they were or where they were going -- they ripped through a tapestry and found themselves in a hidden passageway, hurtled along it and came out near their Charms classroom, which they knew was miles from the trophy room. + \"I think we've lost him,\" Harry panted, leaning against the cold wall and wiping his forehead. Neville was bent double, wheezing and spluttering. + \"I -- @told -- you,\" Hermione gasped, clutching at the stitch in her chest, \"I -- told -- you.\" + \"We've got to get back to Gryffindor Tower,\" said Ron, \"quickly as possible.\" + \"Malfoy tricked you,\" Hermione said to Harry. \"You realize that, don't you? He was never going to meet you -- Filch knew someone was going to be in the trophy room, Malfoy must have tipped him off.\" + Harry thought she was probably right, but he wasn't going to tell her that. + \"Let's go.\" + It wasn't going to be that simple. They hadn't gone more than a dozen paces when a doorknob rattled and something came shooting out of a classroom in front of them. + It was Peeves. He caught sight of them and gave a squeal of delight. + \"Shut up, Peeves -- please -- you'll get us thrown out.\" + Peeves cackled. + \"Wandering around at midnight, Ickle Firsties? Tut, tut, tut. Naughty, naughty, you'll get caughty.\" + \"Not if you don't give us away, Peeves, please.\" + \"Should tell Filch, I should,\" said Peeves in a saintly voice, but his eyes glittered wickedly. \"It's for your own good, you know.\" + \"Get out of the way,\" snapped Ron, taking a swipe at Peeves -- this was a big mistake. + \"STUDENTS OUT OF BED!\" Peeves bellowed, \"STUDENTS OUT OF BED DOWN THE CHARMS CORRIDOR!\" + Ducking under Peeves, they ran for their lives, right to the end of the corridor where they slammed into a door -- and it was locked. + \"This is it!\" Ron moaned, as they pushed helplessly at the door, \"We're done for! This is the end!\" + They could hear footsteps, Filch running as fast as he could toward Peeves's shouts. + \"Oh, move over,\" Hermione snarled. She grabbed Harry's wand, tapped the lock, and whispered, @\"Alohomora!\" + The lock clicked and the door swung open -- they piled through it, shut it quickly, and pressed their ears against it, listening. + \"Which way did they go, Peeves?\" Filch was saying. \"Quick, tell me.\" \"Say ‘please.'\" + \"Don't mess with me, Peeves, now @where @did @they @go?\" \"Shan't say nothing if you don't say please,\" said Peeves in his annoying singsong voice. \"All right -- @please.\" + \"NOTHING! Ha haaa! Told you I wouldn't say nothing if you didn't say please! Ha ha! Haaaaaa!\" And they heard the sound of Peeves whooshing away and Filch cursing in rage. + \"He thinks this door is locked,\" Harry whispered. \"I think we'll be okay -- get @off, Neville!\" For Neville had been tugging on the sleeve of Harry's bathrobe for the last minute. @\"What?\" + Harry turned around -- and saw, quite clearly, what. For a moment, he was sure he'd walked into a nightmare -- this was too much, on top of everything that had happened so far. + They weren't in a room, as he had supposed. They were in a corridor. The forbidden corridor on the third floor. And now they knew why it was forbidden. + They were looking straight into the eyes of a monstrous dog, a dog that filled the whole space between ceiling and floor. It had three heads. Three pairs of rolling, mad eyes; three noses, twitching and quivering in their direction; three drooling mouths, saliva hanging in slippery ropes from yellowish fangs. + It was standing quite still, all six eyes staring at them, and Harry knew that the only reason they weren't already dead was that their sudden appearance had taken it by surprise, but it was quickly getting over that, there was no mistaking what those thunderous growls meant. + Harry groped for the doorknob -- between Filch and death, he'd take Filch. + They fell backward -- Harry slammed the door shut, and they ran, they almost flew, back down the corridor. Filch must have hurried off to look for them somewhere else, because they didn't see him anywhere, but they hardly cared -- all they wanted to do was put as much space as possible between them and that monster. They didn't stop running until they reached the portrait of the Fat Lady on the seventh floor. + \"Where on earth have you all been?\" she asked, looking at their bathrobes hanging off their shoulders and their flushed, sweaty faces. + \"Never mind that -- pig snout, pig snout,\" panted Harry, and the portrait swung forward. They scrambled into the common room and collapsed, trembling, into armchairs. + It was a while before any of them said anything. Neville, indeed, looked as if he'd never speak again. + \"What do they think they're doing, keeping a thing like that locked up in a school?\" said Ron finally. \"If any dog needs exercise, that one does.\" + Hermione had got both her breath and her bad temper back again. + \"You don't use your eyes, any of you, do you?\" she snapped. \"Didn't you see what it was standing on?\" + \"The floor?\" Harry suggested. \"I wasn't looking at its feet, I was too busy with its heads.\" + \"No, @not the floor. It was standing on a trapdoor. It's obviously guarding something.\" + She stood up, glaring at them. + \"I hope you're pleased with yourselves. We could all have been killed -- or worse, expelled. Now, if you don't mind, I'm going to bed.\" + Ron stared after her, his mouth open. \"No, we don't mind,\" he said. \"You'd think we dragged her along, wouldn't you?\" + But Hermione had given Harry something else to think about as he climbed back into bed. The dog was guarding something. . . . What had Hagrid said? Gringotts was the safest place in the world for something you wanted to hide -- except perhaps Hogwarts. + It looked as though Harry had found out where the grubby little package from vault seven hundred and thirteen was. + \n"
     ]
    }
   ],
   "source": [
    "chapter_nine_text = \"\"\n",
    "for row in mat_contents['words'][0]:\n",
    "    chapter_nine_text += row[0][0][0][0] + \" \"\n",
    "print(chapter_nine_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align fMRI scans with sets of 4 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample:\n",
      "\tScan time: 20\n",
      "\tInput words: ['Harry', 'had', 'never', 'believed']\n",
      "Created sample:\n",
      "\tScan time: 22\n",
      "\tInput words: ['he', 'would', 'meet', 'a']\n",
      "Created sample:\n",
      "\tScan time: 24\n",
      "\tInput words: ['boy', 'he', 'hated', 'more']\n",
      "Created sample:\n",
      "\tScan time: 26\n",
      "\tInput words: ['than', 'Dudley,', 'but', 'that']\n",
      "Created sample:\n",
      "\tScan time: 28\n",
      "\tInput words: ['was', 'before', 'he', 'met']\n",
      "Created sample:\n",
      "\tScan time: 30\n",
      "\tInput words: ['Draco', 'Malfoy.', 'Still,', 'first-year']\n",
      "Created sample:\n",
      "\tScan time: 32\n",
      "\tInput words: ['Gryffindors', 'only', 'had', 'Potions']\n",
      "Created sample:\n",
      "\tScan time: 34\n",
      "\tInput words: ['with', 'the', 'Slytherins,', 'so']\n",
      "Created sample:\n",
      "\tScan time: 36\n",
      "\tInput words: ['they', \"didn't\", 'have', 'to']\n",
      "Created sample:\n",
      "\tScan time: 38\n",
      "\tInput words: ['put', 'up', 'with', 'Malfoy']\n",
      "Created sample:\n",
      "\tScan time: 40\n",
      "\tInput words: ['much.', 'Or', 'at', 'least,']\n",
      "Created sample:\n",
      "\tScan time: 42\n",
      "\tInput words: ['they', \"didn't\", 'until', 'they']\n",
      "Created sample:\n",
      "\tScan time: 44\n",
      "\tInput words: ['spotted', 'a', 'notice', 'pinned']\n",
      "Created sample:\n",
      "\tScan time: 46\n",
      "\tInput words: ['up', 'in', 'the', 'Gryffindor']\n",
      "Created sample:\n",
      "\tScan time: 48\n",
      "\tInput words: ['common', 'room', 'that', 'made']\n",
      "Created sample:\n",
      "\tScan time: 50\n",
      "\tInput words: ['them', 'all', 'groan.', 'Flying']\n",
      "Created sample:\n",
      "\tScan time: 52\n",
      "\tInput words: ['lessons', 'would', 'be', 'starting']\n",
      "Created sample:\n",
      "\tScan time: 54\n",
      "\tInput words: ['on', 'Thursday', '--', 'and']\n",
      "Created sample:\n",
      "\tScan time: 56\n",
      "\tInput words: ['Gryffindor', 'and', 'Slytherin', 'would']\n",
      "Created sample:\n",
      "\tScan time: 58\n",
      "\tInput words: ['be', 'learning', 'together.', '+']\n",
      "Created sample:\n",
      "\tScan time: 60\n",
      "\tInput words: ['\"Typical,\"', 'said', 'Harry', 'darkly.']\n",
      "Created sample:\n",
      "\tScan time: 62\n",
      "\tInput words: ['\"Just', 'what', 'I', 'always']\n",
      "Created sample:\n",
      "\tScan time: 64\n",
      "\tInput words: ['wanted.', 'To', 'make', 'a']\n",
      "Created sample:\n",
      "\tScan time: 66\n",
      "\tInput words: ['fool', 'of', 'myself', 'on']\n",
      "Created sample:\n",
      "\tScan time: 68\n",
      "\tInput words: ['a', 'broomstick', 'in', 'front']\n",
      "Created sample:\n",
      "\tScan time: 70\n",
      "\tInput words: ['of', 'Malfoy.\"', '+', 'He']\n",
      "Created sample:\n",
      "\tScan time: 72\n",
      "\tInput words: ['had', 'been', 'looking', 'forward']\n",
      "Created sample:\n",
      "\tScan time: 74\n",
      "\tInput words: ['to', 'learning', 'to', 'fly']\n",
      "Created sample:\n",
      "\tScan time: 76\n",
      "\tInput words: ['more', 'than', 'anything', 'else.']\n",
      "Created sample:\n",
      "\tScan time: 78\n",
      "\tInput words: ['\"You', \"don't\", 'know', 'that']\n",
      "Created sample:\n",
      "\tScan time: 80\n",
      "\tInput words: [\"you'll\", 'make', 'a', 'fool']\n",
      "Created sample:\n",
      "\tScan time: 82\n",
      "\tInput words: ['of', 'yourself,\"', 'said', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 84\n",
      "\tInput words: ['reasonably.', '\"Anyway,', 'I', 'know']\n",
      "Created sample:\n",
      "\tScan time: 86\n",
      "\tInput words: [\"Malfoy's\", 'always', 'going', 'on']\n",
      "Created sample:\n",
      "\tScan time: 88\n",
      "\tInput words: ['about', 'how', 'good', 'he']\n",
      "Created sample:\n",
      "\tScan time: 90\n",
      "\tInput words: ['is', 'at', 'Quidditch,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 92\n",
      "\tInput words: ['I', 'bet', \"that's\", 'all']\n",
      "Created sample:\n",
      "\tScan time: 94\n",
      "\tInput words: ['talk.\"', '+', 'Malfoy', 'certainly']\n",
      "Created sample:\n",
      "\tScan time: 96\n",
      "\tInput words: ['did', 'talk', 'about', 'flying']\n",
      "Created sample:\n",
      "\tScan time: 98\n",
      "\tInput words: ['a', 'lot.', 'He', 'complained']\n",
      "Created sample:\n",
      "\tScan time: 100\n",
      "\tInput words: ['loudly', 'about', 'first', 'years']\n",
      "Created sample:\n",
      "\tScan time: 102\n",
      "\tInput words: ['never', 'getting', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 104\n",
      "\tInput words: ['House', 'Quidditch', 'teams', 'and']\n",
      "Created sample:\n",
      "\tScan time: 106\n",
      "\tInput words: ['told', 'long,', 'boastful', 'stories']\n",
      "Created sample:\n",
      "\tScan time: 108\n",
      "\tInput words: ['that', 'always', 'seemed', 'to']\n",
      "Created sample:\n",
      "\tScan time: 110\n",
      "\tInput words: ['end', 'with', 'him', 'narrowly']\n",
      "Created sample:\n",
      "\tScan time: 112\n",
      "\tInput words: ['escaping', 'Muggles', 'in', 'helicopters.']\n",
      "Created sample:\n",
      "\tScan time: 114\n",
      "\tInput words: ['He', \"wasn't\", 'the', 'only']\n",
      "Created sample:\n",
      "\tScan time: 116\n",
      "\tInput words: ['one,', 'though:', 'the', 'way']\n",
      "Created sample:\n",
      "\tScan time: 118\n",
      "\tInput words: ['Seamus', 'Finnigan', 'told', 'it,']\n",
      "Created sample:\n",
      "\tScan time: 120\n",
      "\tInput words: [\"he'd\", 'spent', 'most', 'of']\n",
      "Created sample:\n",
      "\tScan time: 122\n",
      "\tInput words: ['his', 'childhood', 'zooming', 'around']\n",
      "Created sample:\n",
      "\tScan time: 124\n",
      "\tInput words: ['the', 'countryside', 'on', 'his']\n",
      "Created sample:\n",
      "\tScan time: 126\n",
      "\tInput words: ['broomstick.', 'Even', 'Ron', 'would']\n",
      "Created sample:\n",
      "\tScan time: 128\n",
      "\tInput words: ['tell', 'anyone', \"who'd\", 'listen']\n",
      "Created sample:\n",
      "\tScan time: 130\n",
      "\tInput words: ['about', 'the', 'time', \"he'd\"]\n",
      "Created sample:\n",
      "\tScan time: 132\n",
      "\tInput words: ['almost', 'hit', 'a', 'hang']\n",
      "Created sample:\n",
      "\tScan time: 134\n",
      "\tInput words: ['glider', 'on', \"Charlie's\", 'old']\n",
      "Created sample:\n",
      "\tScan time: 136\n",
      "\tInput words: ['broom.', 'Everyone', 'from', 'wizarding']\n",
      "Created sample:\n",
      "\tScan time: 138\n",
      "\tInput words: ['families', 'talked', 'about', 'Quidditch']\n",
      "Created sample:\n",
      "\tScan time: 140\n",
      "\tInput words: ['constantly.', 'Ron', 'had', 'already']\n",
      "Created sample:\n",
      "\tScan time: 142\n",
      "\tInput words: ['had', 'a', 'big', 'argument']\n",
      "Created sample:\n",
      "\tScan time: 144\n",
      "\tInput words: ['with', 'Dean', 'Thomas,', 'who']\n",
      "Created sample:\n",
      "\tScan time: 146\n",
      "\tInput words: ['shared', 'their', 'dormitory,', 'about']\n",
      "Created sample:\n",
      "\tScan time: 148\n",
      "\tInput words: ['soccer.', 'Ron', \"couldn't\", 'see']\n",
      "Created sample:\n",
      "\tScan time: 150\n",
      "\tInput words: ['what', 'was', 'exciting', 'about']\n",
      "Created sample:\n",
      "\tScan time: 152\n",
      "\tInput words: ['a', 'game', 'with', 'only']\n",
      "Created sample:\n",
      "\tScan time: 154\n",
      "\tInput words: ['one', 'ball', 'where', 'no']\n",
      "Created sample:\n",
      "\tScan time: 156\n",
      "\tInput words: ['one', 'was', 'allowed', 'to']\n",
      "Created sample:\n",
      "\tScan time: 158\n",
      "\tInput words: ['fly.', 'Harry', 'had', 'caught']\n",
      "Created sample:\n",
      "\tScan time: 160\n",
      "\tInput words: ['Ron', 'prodding', \"Dean's\", 'poster']\n",
      "Created sample:\n",
      "\tScan time: 162\n",
      "\tInput words: ['of', 'West', 'Ham', 'soccer']\n",
      "Created sample:\n",
      "\tScan time: 164\n",
      "\tInput words: ['team,', 'trying', 'to', 'make']\n",
      "Created sample:\n",
      "\tScan time: 166\n",
      "\tInput words: ['the', 'players', 'move.', '+']\n",
      "Created sample:\n",
      "\tScan time: 168\n",
      "\tInput words: ['Neville', 'had', 'never', 'been']\n",
      "Created sample:\n",
      "\tScan time: 170\n",
      "\tInput words: ['on', 'a', 'broomstick', 'in']\n",
      "Created sample:\n",
      "\tScan time: 172\n",
      "\tInput words: ['his', 'life,', 'because', 'his']\n",
      "Created sample:\n",
      "\tScan time: 174\n",
      "\tInput words: ['grandmother', 'had', 'never', 'let']\n",
      "Created sample:\n",
      "\tScan time: 176\n",
      "\tInput words: ['him', 'near', 'one.', 'Privately,']\n",
      "Created sample:\n",
      "\tScan time: 178\n",
      "\tInput words: ['Harry', 'felt', \"she'd\", 'had']\n",
      "Created sample:\n",
      "\tScan time: 180\n",
      "\tInput words: ['good', 'reason,', 'because', 'Neville']\n",
      "Created sample:\n",
      "\tScan time: 182\n",
      "\tInput words: ['managed', 'to', 'have', 'an']\n",
      "Created sample:\n",
      "\tScan time: 184\n",
      "\tInput words: ['extraordinary', 'number', 'of', 'accidents']\n",
      "Created sample:\n",
      "\tScan time: 186\n",
      "\tInput words: ['even', 'with', 'both', 'feet']\n",
      "Created sample:\n",
      "\tScan time: 188\n",
      "\tInput words: ['on', 'the', 'ground.', '+']\n",
      "Created sample:\n",
      "\tScan time: 190\n",
      "\tInput words: ['Hermione', 'Granger', 'was', 'almost']\n",
      "Created sample:\n",
      "\tScan time: 192\n",
      "\tInput words: ['as', 'nervous', 'about', 'flying']\n",
      "Created sample:\n",
      "\tScan time: 194\n",
      "\tInput words: ['as', 'Neville', 'was.', 'This']\n",
      "Created sample:\n",
      "\tScan time: 196\n",
      "\tInput words: ['was', 'something', 'you', \"couldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 198\n",
      "\tInput words: ['learn', 'by', 'heart', 'out']\n",
      "Created sample:\n",
      "\tScan time: 200\n",
      "\tInput words: ['of', 'a', 'book', '--']\n",
      "Created sample:\n",
      "\tScan time: 202\n",
      "\tInput words: ['not', 'that', 'she', \"hadn't\"]\n",
      "Created sample:\n",
      "\tScan time: 204\n",
      "\tInput words: ['tried.', 'At', 'breakfast', 'on']\n",
      "Created sample:\n",
      "\tScan time: 206\n",
      "\tInput words: ['Thursday', 'she', 'bored', 'them']\n",
      "Created sample:\n",
      "\tScan time: 208\n",
      "\tInput words: ['all', 'stupid', 'with', 'flying']\n",
      "Created sample:\n",
      "\tScan time: 210\n",
      "\tInput words: ['tips', \"she'd\", 'gotten', 'out']\n",
      "Created sample:\n",
      "\tScan time: 212\n",
      "\tInput words: ['of', 'a', 'library', 'book']\n",
      "Created sample:\n",
      "\tScan time: 214\n",
      "\tInput words: ['called', '@Quidditch', '@Through', '@the']\n",
      "Created sample:\n",
      "\tScan time: 216\n",
      "\tInput words: ['@Ages.', 'Neville', 'was', 'hanging']\n",
      "Created sample:\n",
      "\tScan time: 218\n",
      "\tInput words: ['on', 'to', 'her', 'every']\n",
      "Created sample:\n",
      "\tScan time: 220\n",
      "\tInput words: ['word,', 'desperate', 'for', 'anything']\n",
      "Created sample:\n",
      "\tScan time: 222\n",
      "\tInput words: ['that', 'might', 'help', 'him']\n",
      "Created sample:\n",
      "\tScan time: 224\n",
      "\tInput words: ['hang', 'on', 'to', 'his']\n",
      "Created sample:\n",
      "\tScan time: 226\n",
      "\tInput words: ['broomstick', 'later,', 'but', 'everybody']\n",
      "Created sample:\n",
      "\tScan time: 228\n",
      "\tInput words: ['else', 'was', 'very', 'pleased']\n",
      "Created sample:\n",
      "\tScan time: 230\n",
      "\tInput words: ['when', \"Hermione's\", 'lecture', 'was']\n",
      "Created sample:\n",
      "\tScan time: 232\n",
      "\tInput words: ['interrupted', 'by', 'the', 'arrival']\n",
      "Created sample:\n",
      "\tScan time: 234\n",
      "\tInput words: ['of', 'the', 'mail.', '+']\n",
      "Created sample:\n",
      "\tScan time: 236\n",
      "\tInput words: ['Harry', \"hadn't\", 'had', 'a']\n",
      "Created sample:\n",
      "\tScan time: 238\n",
      "\tInput words: ['single', 'letter', 'since', \"Hagrid's\"]\n",
      "Created sample:\n",
      "\tScan time: 240\n",
      "\tInput words: ['note,', 'something', 'that', 'Malfoy']\n",
      "Created sample:\n",
      "\tScan time: 242\n",
      "\tInput words: ['had', 'been', 'quick', 'to']\n",
      "Created sample:\n",
      "\tScan time: 244\n",
      "\tInput words: ['notice,', 'of', 'course.', \"Malfoy's\"]\n",
      "Created sample:\n",
      "\tScan time: 246\n",
      "\tInput words: ['eagle', 'owl', 'was', 'always']\n",
      "Created sample:\n",
      "\tScan time: 248\n",
      "\tInput words: ['bringing', 'him', 'packages', 'of']\n",
      "Created sample:\n",
      "\tScan time: 250\n",
      "\tInput words: ['sweets', 'from', 'home,', 'which']\n",
      "Created sample:\n",
      "\tScan time: 252\n",
      "\tInput words: ['he', 'opened', 'gloatingly', 'at']\n",
      "Created sample:\n",
      "\tScan time: 254\n",
      "\tInput words: ['the', 'Slytherin', 'table.', '+']\n",
      "Created sample:\n",
      "\tScan time: 256\n",
      "\tInput words: ['A', 'barn', 'owl', 'brought']\n",
      "Created sample:\n",
      "\tScan time: 258\n",
      "\tInput words: ['Neville', 'a', 'small', 'package']\n",
      "Created sample:\n",
      "\tScan time: 260\n",
      "\tInput words: ['from', 'his', 'grandmother.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 262\n",
      "\tInput words: ['opened', 'it', 'excitedly', 'and']\n",
      "Created sample:\n",
      "\tScan time: 264\n",
      "\tInput words: ['showed', 'them', 'a', 'glass']\n",
      "Created sample:\n",
      "\tScan time: 266\n",
      "\tInput words: ['ball', 'the', 'size', 'of']\n",
      "Created sample:\n",
      "\tScan time: 268\n",
      "\tInput words: ['a', 'large', 'marble,', 'which']\n",
      "Created sample:\n",
      "\tScan time: 270\n",
      "\tInput words: ['seemed', 'to', 'be', 'full']\n",
      "Created sample:\n",
      "\tScan time: 272\n",
      "\tInput words: ['of', 'white', 'smoke.', '+']\n",
      "Created sample:\n",
      "\tScan time: 274\n",
      "\tInput words: ['\"It\\'s', 'a', 'Remembrall!\"', 'he']\n",
      "Created sample:\n",
      "\tScan time: 276\n",
      "\tInput words: ['explained.', '\"Gran', 'knows', 'I']\n",
      "Created sample:\n",
      "\tScan time: 278\n",
      "\tInput words: ['forget', 'things', '--', 'this']\n",
      "Created sample:\n",
      "\tScan time: 280\n",
      "\tInput words: ['tells', 'you', 'if', \"there's\"]\n",
      "Created sample:\n",
      "\tScan time: 282\n",
      "\tInput words: ['something', \"you've\", 'forgotten', 'to']\n",
      "Created sample:\n",
      "\tScan time: 284\n",
      "\tInput words: ['do.', 'Look,', 'you', 'hold']\n",
      "Created sample:\n",
      "\tScan time: 286\n",
      "\tInput words: ['it', 'tight', 'like', 'this']\n",
      "Created sample:\n",
      "\tScan time: 288\n",
      "\tInput words: ['and', 'if', 'it', 'turns']\n",
      "Created sample:\n",
      "\tScan time: 290\n",
      "\tInput words: ['red', '--', 'oh', '…\"']\n",
      "Created sample:\n",
      "\tScan time: 292\n",
      "\tInput words: ['His', 'face', 'fell,', 'because']\n",
      "Created sample:\n",
      "\tScan time: 294\n",
      "\tInput words: ['the', 'Remembrall', 'had', 'suddenly']\n",
      "Created sample:\n",
      "\tScan time: 296\n",
      "\tInput words: ['glowed', 'scarlet,', '\"…', \"you've\"]\n",
      "Created sample:\n",
      "\tScan time: 298\n",
      "\tInput words: ['forgotten', 'something', '…\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 300\n",
      "\tInput words: ['Neville', 'was', 'trying', 'to']\n",
      "Created sample:\n",
      "\tScan time: 302\n",
      "\tInput words: ['remember', 'what', \"he'd\", 'forgotten']\n",
      "Created sample:\n",
      "\tScan time: 304\n",
      "\tInput words: ['when', 'Draco', 'Malfoy,', 'who']\n",
      "Created sample:\n",
      "\tScan time: 306\n",
      "\tInput words: ['was', 'passing', 'the', 'Gryffindor']\n",
      "Created sample:\n",
      "\tScan time: 308\n",
      "\tInput words: ['table,', 'snatched', 'the', 'Remembrall']\n",
      "Created sample:\n",
      "\tScan time: 310\n",
      "\tInput words: ['out', 'of', 'his', 'hand.']\n",
      "Created sample:\n",
      "\tScan time: 312\n",
      "\tInput words: ['+', 'Harry', 'and', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 314\n",
      "\tInput words: ['jumped', 'to', 'their', 'feet.']\n",
      "Created sample:\n",
      "\tScan time: 316\n",
      "\tInput words: ['They', 'were', 'half', 'hoping']\n",
      "Created sample:\n",
      "\tScan time: 318\n",
      "\tInput words: ['for', 'a', 'reason', 'to']\n",
      "Created sample:\n",
      "\tScan time: 320\n",
      "\tInput words: ['fight', 'Malfoy,', 'but', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 322\n",
      "\tInput words: ['McGonagall,', 'who', 'could', 'spot']\n",
      "Created sample:\n",
      "\tScan time: 324\n",
      "\tInput words: ['trouble', 'quicker', 'than', 'any']\n",
      "Created sample:\n",
      "\tScan time: 326\n",
      "\tInput words: ['teacher', 'in', 'the', 'school,']\n",
      "Created sample:\n",
      "\tScan time: 328\n",
      "\tInput words: ['was', 'there', 'in', 'a']\n",
      "Created sample:\n",
      "\tScan time: 330\n",
      "\tInput words: ['flash.', '+', '\"What\\'s', 'going']\n",
      "Created sample:\n",
      "\tScan time: 332\n",
      "\tInput words: ['on?\"', '+', '\"Malfoy\\'s', 'got']\n",
      "Created sample:\n",
      "\tScan time: 334\n",
      "\tInput words: ['my', 'Remembrall,', 'Professor.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 336\n",
      "\tInput words: ['Scowling,', 'Malfoy', 'quickly', 'dropped']\n",
      "Created sample:\n",
      "\tScan time: 338\n",
      "\tInput words: ['the', 'Remembrall', 'back', 'on']\n",
      "Created sample:\n",
      "\tScan time: 340\n",
      "\tInput words: ['the', 'table.', '+', '\"Just']\n",
      "Created sample:\n",
      "\tScan time: 342\n",
      "\tInput words: ['looking,\"', 'he', 'said,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 344\n",
      "\tInput words: ['he', 'sloped', 'away', 'with']\n",
      "Created sample:\n",
      "\tScan time: 346\n",
      "\tInput words: ['Crabbe', 'and', 'Goyle', 'behind']\n",
      "Created sample:\n",
      "\tScan time: 348\n",
      "\tInput words: ['him.', '+', '+', 'At']\n",
      "Created sample:\n",
      "\tScan time: 350\n",
      "\tInput words: ['three-thirty', 'that', 'afternoon,', 'Harry,']\n",
      "Created sample:\n",
      "\tScan time: 352\n",
      "\tInput words: ['Ron,', 'and', 'the', 'other']\n",
      "Created sample:\n",
      "\tScan time: 354\n",
      "\tInput words: ['Gryffindors', 'hurried', 'down', 'the']\n",
      "Created sample:\n",
      "\tScan time: 356\n",
      "\tInput words: ['front', 'steps', 'onto', 'the']\n",
      "Created sample:\n",
      "\tScan time: 358\n",
      "\tInput words: ['grounds', 'for', 'their', 'first']\n",
      "Created sample:\n",
      "\tScan time: 360\n",
      "\tInput words: ['flying', 'lesson.', 'It', 'was']\n",
      "Created sample:\n",
      "\tScan time: 362\n",
      "\tInput words: ['a', 'clear,', 'breezy', 'day,']\n",
      "Created sample:\n",
      "\tScan time: 364\n",
      "\tInput words: ['and', 'the', 'grass', 'rippled']\n",
      "Created sample:\n",
      "\tScan time: 366\n",
      "\tInput words: ['under', 'their', 'feet', 'as']\n",
      "Created sample:\n",
      "\tScan time: 368\n",
      "\tInput words: ['they', 'marched', 'down', 'the']\n",
      "Created sample:\n",
      "\tScan time: 370\n",
      "\tInput words: ['sloping', 'lawns', 'toward', 'a']\n",
      "Created sample:\n",
      "\tScan time: 372\n",
      "\tInput words: ['smooth,', 'flat', 'lawn', 'on']\n",
      "Created sample:\n",
      "\tScan time: 374\n",
      "\tInput words: ['the', 'opposite', 'side', 'of']\n",
      "Created sample:\n",
      "\tScan time: 376\n",
      "\tInput words: ['the', 'grounds', 'to', 'the']\n",
      "Created sample:\n",
      "\tScan time: 378\n",
      "\tInput words: ['forbidden', 'forest,', 'whose', 'trees']\n",
      "Created sample:\n",
      "\tScan time: 380\n",
      "\tInput words: ['were', 'swaying', 'darkly', 'in']\n",
      "Created sample:\n",
      "\tScan time: 382\n",
      "\tInput words: ['the', 'distance.', '+', 'The']\n",
      "Created sample:\n",
      "\tScan time: 384\n",
      "\tInput words: ['Slytherins', 'were', 'already', 'there,']\n",
      "Created sample:\n",
      "\tScan time: 386\n",
      "\tInput words: ['and', 'so', 'were', 'twenty']\n",
      "Created sample:\n",
      "\tScan time: 388\n",
      "\tInput words: ['broomsticks', 'lying', 'in', 'neat']\n",
      "Created sample:\n",
      "\tScan time: 390\n",
      "\tInput words: ['lines', 'on', 'the', 'ground.']\n",
      "Created sample:\n",
      "\tScan time: 392\n",
      "\tInput words: ['Harry', 'had', 'heard', 'Fred']\n",
      "Created sample:\n",
      "\tScan time: 394\n",
      "\tInput words: ['and', 'George', 'Weasley', 'complain']\n",
      "Created sample:\n",
      "\tScan time: 396\n",
      "\tInput words: ['about', 'the', 'school', 'brooms,']\n",
      "Created sample:\n",
      "\tScan time: 398\n",
      "\tInput words: ['saying', 'that', 'some', 'of']\n",
      "Created sample:\n",
      "\tScan time: 400\n",
      "\tInput words: ['them', 'started', 'to', 'vibrate']\n",
      "Created sample:\n",
      "\tScan time: 402\n",
      "\tInput words: ['if', 'you', 'flew', 'too']\n",
      "Created sample:\n",
      "\tScan time: 404\n",
      "\tInput words: ['high,', 'or', 'always', 'flew']\n",
      "Created sample:\n",
      "\tScan time: 406\n",
      "\tInput words: ['slightly', 'to', 'the', 'left.']\n",
      "Created sample:\n",
      "\tScan time: 408\n",
      "\tInput words: ['+', 'Their', 'teacher,', 'Madam']\n",
      "Created sample:\n",
      "\tScan time: 410\n",
      "\tInput words: ['Hooch,', 'arrived.', 'She', 'had']\n",
      "Created sample:\n",
      "\tScan time: 412\n",
      "\tInput words: ['short,', 'gray', 'hair,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 414\n",
      "\tInput words: ['yellow', 'eyes', 'like', 'a']\n",
      "Created sample:\n",
      "\tScan time: 416\n",
      "\tInput words: ['hawk.', '+', '\"Well,', 'what']\n",
      "Created sample:\n",
      "\tScan time: 418\n",
      "\tInput words: ['are', 'you', 'all', 'waiting']\n",
      "Created sample:\n",
      "\tScan time: 420\n",
      "\tInput words: ['for?\"', 'she', 'barked.', '\"Everyone']\n",
      "Created sample:\n",
      "\tScan time: 422\n",
      "\tInput words: ['stand', 'by', 'a', 'broomstick.']\n",
      "Created sample:\n",
      "\tScan time: 424\n",
      "\tInput words: ['Come', 'on,', 'hurry', 'up.\"']\n",
      "Created sample:\n",
      "\tScan time: 426\n",
      "\tInput words: ['+', 'Harry', 'glanced', 'down']\n",
      "Created sample:\n",
      "\tScan time: 428\n",
      "\tInput words: ['at', 'his', 'broom.', 'It']\n",
      "Created sample:\n",
      "\tScan time: 430\n",
      "\tInput words: ['was', 'old', 'and', 'some']\n",
      "Created sample:\n",
      "\tScan time: 432\n",
      "\tInput words: ['of', 'the', 'twigs', 'stuck']\n",
      "Created sample:\n",
      "\tScan time: 434\n",
      "\tInput words: ['out', 'at', 'odd', 'angles.']\n",
      "Created sample:\n",
      "\tScan time: 436\n",
      "\tInput words: ['+', '\"Stick', 'out', 'your']\n",
      "Created sample:\n",
      "\tScan time: 438\n",
      "\tInput words: ['right', 'hand', 'over', 'your']\n",
      "Created sample:\n",
      "\tScan time: 440\n",
      "\tInput words: ['broom,\"', 'called', 'Madam', 'Hooch']\n",
      "Created sample:\n",
      "\tScan time: 442\n",
      "\tInput words: ['at', 'the', 'front,', '\"and']\n",
      "Created sample:\n",
      "\tScan time: 444\n",
      "\tInput words: ['say', '‘Up!\\'\"', '+', '\"UP!\"']\n",
      "Created sample:\n",
      "\tScan time: 446\n",
      "\tInput words: ['everyone', 'shouted.', '+', \"Harry's\"]\n",
      "Created sample:\n",
      "\tScan time: 448\n",
      "\tInput words: ['broom', 'jumped', 'into', 'his']\n",
      "Created sample:\n",
      "\tScan time: 450\n",
      "\tInput words: ['hand', 'at', 'once,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 452\n",
      "\tInput words: ['it', 'was', 'one', 'of']\n",
      "Created sample:\n",
      "\tScan time: 454\n",
      "\tInput words: ['the', 'few', 'that', 'did.']\n",
      "Created sample:\n",
      "\tScan time: 456\n",
      "\tInput words: ['Hermione', \"Granger's\", 'had', 'simply']\n",
      "Created sample:\n",
      "\tScan time: 458\n",
      "\tInput words: ['rolled', 'over', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 460\n",
      "\tInput words: ['ground,', 'and', \"Neville's\", \"hadn't\"]\n",
      "Created sample:\n",
      "\tScan time: 462\n",
      "\tInput words: ['moved', 'at', 'all.', 'Perhaps']\n",
      "Created sample:\n",
      "\tScan time: 464\n",
      "\tInput words: ['brooms,', 'like', 'horses,', 'could']\n",
      "Created sample:\n",
      "\tScan time: 466\n",
      "\tInput words: ['tell', 'when', 'you', 'were']\n",
      "Created sample:\n",
      "\tScan time: 468\n",
      "\tInput words: ['afraid,', 'thought', 'Harry;', 'there']\n",
      "Created sample:\n",
      "\tScan time: 470\n",
      "\tInput words: ['was', 'a', 'quaver', 'in']\n",
      "Created sample:\n",
      "\tScan time: 472\n",
      "\tInput words: [\"Neville's\", 'voice', 'that', 'said']\n",
      "Created sample:\n",
      "\tScan time: 474\n",
      "\tInput words: ['only', 'too', 'clearly', 'that']\n",
      "Created sample:\n",
      "\tScan time: 476\n",
      "\tInput words: ['he', 'wanted', 'to', 'keep']\n",
      "Created sample:\n",
      "\tScan time: 478\n",
      "\tInput words: ['his', 'feet', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 480\n",
      "\tInput words: ['ground.', '+', 'Madam', 'Hooch']\n",
      "Created sample:\n",
      "\tScan time: 482\n",
      "\tInput words: ['then', 'showed', 'them', 'how']\n",
      "Created sample:\n",
      "\tScan time: 484\n",
      "\tInput words: ['to', 'mount', 'their', 'brooms']\n",
      "Created sample:\n",
      "\tScan time: 486\n",
      "\tInput words: ['without', 'sliding', 'off', 'the']\n",
      "Created sample:\n",
      "\tScan time: 488\n",
      "\tInput words: ['end,', 'and', 'walked', 'up']\n",
      "Created sample:\n",
      "\tScan time: 490\n",
      "\tInput words: ['and', 'down', 'the', 'rows']\n",
      "Created sample:\n",
      "\tScan time: 492\n",
      "\tInput words: ['correcting', 'their', 'grips.', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 494\n",
      "\tInput words: ['and', 'Ron', 'were', 'delighted']\n",
      "Created sample:\n",
      "\tScan time: 496\n",
      "\tInput words: ['when', 'she', 'told', 'Malfoy']\n",
      "Created sample:\n",
      "\tScan time: 498\n",
      "\tInput words: [\"he'd\", 'been', 'doing', 'it']\n",
      "Created sample:\n",
      "\tScan time: 500\n",
      "\tInput words: ['wrong', 'for', 'years.', '+']\n",
      "Created sample:\n",
      "\tScan time: 502\n",
      "\tInput words: ['\"Now,', 'when', 'I', 'blow']\n",
      "Created sample:\n",
      "\tScan time: 504\n",
      "\tInput words: ['my', 'whistle,', 'you', 'kick']\n",
      "Created sample:\n",
      "\tScan time: 506\n",
      "\tInput words: ['off', 'from', 'the', 'ground,']\n",
      "Created sample:\n",
      "\tScan time: 508\n",
      "\tInput words: ['hard,\"', 'said', 'Madam', 'Hooch.']\n",
      "Created sample:\n",
      "\tScan time: 510\n",
      "\tInput words: ['\"Keep', 'your', 'brooms', 'steady,']\n",
      "Created sample:\n",
      "\tScan time: 512\n",
      "\tInput words: ['rise', 'a', 'few', 'feet,']\n",
      "Created sample:\n",
      "\tScan time: 514\n",
      "\tInput words: ['and', 'then', 'come', 'straight']\n",
      "Created sample:\n",
      "\tScan time: 516\n",
      "\tInput words: ['back', 'down', 'by', 'leaning']\n",
      "Created sample:\n",
      "\tScan time: 518\n",
      "\tInput words: ['forward', 'slightly.', 'On', 'my']\n",
      "Created sample:\n",
      "\tScan time: 520\n",
      "\tInput words: ['whistle', '--', 'three', '--']\n",
      "Created sample:\n",
      "\tScan time: 522\n",
      "\tInput words: ['two', '—\"', '+', 'But']\n",
      "Created sample:\n",
      "\tScan time: 524\n",
      "\tInput words: ['Neville,', 'nervous', 'and', 'jumpy']\n",
      "Created sample:\n",
      "\tScan time: 526\n",
      "\tInput words: ['and', 'frightened', 'of', 'being']\n",
      "Created sample:\n",
      "\tScan time: 528\n",
      "\tInput words: ['left', 'on', 'the', 'ground,']\n",
      "Created sample:\n",
      "\tScan time: 530\n",
      "\tInput words: ['pushed', 'off', 'hard', 'before']\n",
      "Created sample:\n",
      "\tScan time: 532\n",
      "\tInput words: ['the', 'whistle', 'had', 'touched']\n",
      "Created sample:\n",
      "\tScan time: 534\n",
      "\tInput words: ['Madam', \"Hooch's\", 'lips.', '+']\n",
      "Created sample:\n",
      "\tScan time: 536\n",
      "\tInput words: ['\"Come', 'back,', 'boy!\"', 'she']\n",
      "Created sample:\n",
      "\tScan time: 538\n",
      "\tInput words: ['shouted,', 'but', 'Neville', 'was']\n",
      "Created sample:\n",
      "\tScan time: 540\n",
      "\tInput words: ['rising', 'straight', 'up', 'like']\n",
      "Created sample:\n",
      "\tScan time: 542\n",
      "\tInput words: ['a', 'cork', 'shot', 'out']\n",
      "Created sample:\n",
      "\tScan time: 544\n",
      "\tInput words: ['of', 'a', 'bottle', '--']\n",
      "Created sample:\n",
      "\tScan time: 546\n",
      "\tInput words: ['twelve', 'feet', '--', 'twenty']\n",
      "Created sample:\n",
      "\tScan time: 548\n",
      "\tInput words: ['feet.', 'Harry', 'saw', 'his']\n",
      "Created sample:\n",
      "\tScan time: 550\n",
      "\tInput words: ['scared', 'white', 'face', 'look']\n",
      "Created sample:\n",
      "\tScan time: 552\n",
      "\tInput words: ['down', 'at', 'the', 'ground']\n",
      "Created sample:\n",
      "\tScan time: 554\n",
      "\tInput words: ['falling', 'away,', 'saw', 'him']\n",
      "Created sample:\n",
      "\tScan time: 556\n",
      "\tInput words: ['gasp,', 'slip', 'sideways', 'off']\n",
      "Created sample:\n",
      "\tScan time: 558\n",
      "\tInput words: ['the', 'broom', 'and', '--']\n",
      "Created sample:\n",
      "\tScan time: 560\n",
      "\tInput words: ['+', 'WHAM', '--', 'a']\n",
      "Created sample:\n",
      "\tScan time: 562\n",
      "\tInput words: ['thud', 'and', 'a', 'nasty']\n",
      "Created sample:\n",
      "\tScan time: 564\n",
      "\tInput words: ['crack', 'and', 'Neville', 'lay']\n",
      "Created sample:\n",
      "\tScan time: 566\n",
      "\tInput words: ['facedown', 'on', 'the', 'grass']\n",
      "Created sample:\n",
      "\tScan time: 568\n",
      "\tInput words: ['in', 'a', 'heap.', 'His']\n",
      "Created sample:\n",
      "\tScan time: 570\n",
      "\tInput words: ['broomstick', 'was', 'still', 'rising']\n",
      "Created sample:\n",
      "\tScan time: 572\n",
      "\tInput words: ['higher', 'and', 'higher,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 574\n",
      "\tInput words: ['started', 'to', 'drift', 'lazily']\n",
      "Created sample:\n",
      "\tScan time: 576\n",
      "\tInput words: ['toward', 'the', 'forbidden', 'forest']\n",
      "Created sample:\n",
      "\tScan time: 578\n",
      "\tInput words: ['and', 'out', 'of', 'sight.']\n",
      "Created sample:\n",
      "\tScan time: 580\n",
      "\tInput words: ['+', 'Madam', 'Hooch', 'was']\n",
      "Created sample:\n",
      "\tScan time: 582\n",
      "\tInput words: ['bending', 'over', 'Neville,', 'her']\n",
      "Created sample:\n",
      "\tScan time: 584\n",
      "\tInput words: ['face', 'as', 'white', 'as']\n",
      "Created sample:\n",
      "\tScan time: 586\n",
      "\tInput words: ['his.', '\"Broken', 'wrist,\"', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 588\n",
      "\tInput words: ['heard', 'her', 'mutter.', '\"Come']\n",
      "Created sample:\n",
      "\tScan time: 590\n",
      "\tInput words: ['on,', 'boy', '--', \"it's\"]\n",
      "Created sample:\n",
      "\tScan time: 592\n",
      "\tInput words: ['all', 'right,', 'up', 'you']\n",
      "Created sample:\n",
      "\tScan time: 594\n",
      "\tInput words: ['get.\"', '+', 'She', 'turned']\n",
      "Created sample:\n",
      "\tScan time: 596\n",
      "\tInput words: ['to', 'the', 'rest', 'of']\n",
      "Created sample:\n",
      "\tScan time: 598\n",
      "\tInput words: ['the', 'class.', '\"None', 'of']\n",
      "Created sample:\n",
      "\tScan time: 600\n",
      "\tInput words: ['you', 'is', 'to', 'move']\n",
      "Created sample:\n",
      "\tScan time: 602\n",
      "\tInput words: ['while', 'I', 'take', 'this']\n",
      "Created sample:\n",
      "\tScan time: 604\n",
      "\tInput words: ['boy', 'to', 'the', 'hospital']\n",
      "Created sample:\n",
      "\tScan time: 606\n",
      "\tInput words: ['wing!', 'You', 'leave', 'those']\n",
      "Created sample:\n",
      "\tScan time: 608\n",
      "\tInput words: ['brooms', 'where', 'they', 'are']\n",
      "Created sample:\n",
      "\tScan time: 610\n",
      "\tInput words: ['or', \"you'll\", 'be', 'out']\n",
      "Created sample:\n",
      "\tScan time: 612\n",
      "\tInput words: ['of', 'Hogwarts', 'before', 'you']\n",
      "Created sample:\n",
      "\tScan time: 614\n",
      "\tInput words: ['can', 'say', \"‘Quidditch.'\", 'Come']\n",
      "Created sample:\n",
      "\tScan time: 616\n",
      "\tInput words: ['on,', 'dear.\"', '+', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 618\n",
      "\tInput words: ['his', 'face', 'tear-streaked,', 'clutching']\n",
      "Created sample:\n",
      "\tScan time: 620\n",
      "\tInput words: ['his', 'wrist,', 'hobbled', 'off']\n",
      "Created sample:\n",
      "\tScan time: 622\n",
      "\tInput words: ['with', 'Madam', 'Hooch,', 'who']\n",
      "Created sample:\n",
      "\tScan time: 624\n",
      "\tInput words: ['had', 'her', 'arm', 'around']\n",
      "Created sample:\n",
      "\tScan time: 626\n",
      "\tInput words: ['him.', '+', 'No', 'sooner']\n",
      "Created sample:\n",
      "\tScan time: 628\n",
      "\tInput words: ['were', 'they', 'out', 'of']\n",
      "Created sample:\n",
      "\tScan time: 630\n",
      "\tInput words: ['earshot', 'than', 'Malfoy', 'burst']\n",
      "Created sample:\n",
      "\tScan time: 632\n",
      "\tInput words: ['into', 'laughter.', '+', '\"Did']\n",
      "Created sample:\n",
      "\tScan time: 634\n",
      "\tInput words: ['you', 'see', 'his', 'face,']\n",
      "Created sample:\n",
      "\tScan time: 636\n",
      "\tInput words: ['the', 'great', 'lump?\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 638\n",
      "\tInput words: ['The', 'other', 'Slytherins', 'joined']\n",
      "Created sample:\n",
      "\tScan time: 640\n",
      "\tInput words: ['in.', '+', '\"Shut', 'up,']\n",
      "Created sample:\n",
      "\tScan time: 642\n",
      "\tInput words: ['Malfoy,\"', 'snapped', 'Parvati', 'Patil.']\n",
      "Created sample:\n",
      "\tScan time: 644\n",
      "\tInput words: ['+', '\"Ooh,', 'sticking', 'up']\n",
      "Created sample:\n",
      "\tScan time: 646\n",
      "\tInput words: ['for', 'Longbottom?\"', 'said', 'Pansy']\n",
      "Created sample:\n",
      "\tScan time: 648\n",
      "\tInput words: ['Parkinson,', 'a', 'hard-faced', 'Slytherin']\n",
      "Created sample:\n",
      "\tScan time: 650\n",
      "\tInput words: ['girl.', '\"Never', 'thought', \"@you'd\"]\n",
      "Created sample:\n",
      "\tScan time: 652\n",
      "\tInput words: ['like', 'fat', 'little', 'crybabies,']\n",
      "Created sample:\n",
      "\tScan time: 654\n",
      "\tInput words: ['Parvati.\"', '+', '\"Look!\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 656\n",
      "\tInput words: ['Malfoy,', 'darting', 'forward', 'and']\n",
      "Created sample:\n",
      "\tScan time: 658\n",
      "\tInput words: ['snatching', 'something', 'out', 'of']\n",
      "Created sample:\n",
      "\tScan time: 660\n",
      "\tInput words: ['the', 'grass.', '\"It\\'s', 'that']\n",
      "Created sample:\n",
      "\tScan time: 662\n",
      "\tInput words: ['stupid', 'thing', \"Longbottom's\", 'gran']\n",
      "Created sample:\n",
      "\tScan time: 664\n",
      "\tInput words: ['sent', 'him.\"', '+', 'The']\n",
      "Created sample:\n",
      "\tScan time: 666\n",
      "\tInput words: ['Remembrall', 'glittered', 'in', 'the']\n",
      "Created sample:\n",
      "\tScan time: 700\n",
      "\tInput words: ['\"Give', 'that', 'here,', 'Malfoy,\"']\n",
      "Created sample:\n",
      "\tScan time: 702\n",
      "\tInput words: ['said', 'Harry', 'quietly.', 'Everyone']\n",
      "Created sample:\n",
      "\tScan time: 704\n",
      "\tInput words: ['stopped', 'talking', 'to', 'watch.']\n",
      "Created sample:\n",
      "\tScan time: 706\n",
      "\tInput words: ['+', 'Malfoy', 'smiled', 'nastily.']\n",
      "Created sample:\n",
      "\tScan time: 708\n",
      "\tInput words: ['\"I', 'think', \"I'll\", 'leave']\n",
      "Created sample:\n",
      "\tScan time: 710\n",
      "\tInput words: ['it', 'somewhere', 'for', 'Longbottom']\n",
      "Created sample:\n",
      "\tScan time: 712\n",
      "\tInput words: ['to', 'find', '--', 'how']\n",
      "Created sample:\n",
      "\tScan time: 714\n",
      "\tInput words: ['about', '--', 'up', 'a']\n",
      "Created sample:\n",
      "\tScan time: 716\n",
      "\tInput words: ['tree?\"', '+', '\"Give', 'it']\n",
      "Created sample:\n",
      "\tScan time: 718\n",
      "\tInput words: ['@here!\"', 'Harry', 'yelled,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 720\n",
      "\tInput words: ['Malfoy', 'had', 'leapt', 'onto']\n",
      "Created sample:\n",
      "\tScan time: 722\n",
      "\tInput words: ['his', 'broomstick', 'and', 'taken']\n",
      "Created sample:\n",
      "\tScan time: 724\n",
      "\tInput words: ['off.', 'He', \"hadn't\", 'been']\n",
      "Created sample:\n",
      "\tScan time: 726\n",
      "\tInput words: ['lying,', 'he', '@could', 'fly']\n",
      "Created sample:\n",
      "\tScan time: 728\n",
      "\tInput words: ['well.', 'Hovering', 'level', 'with']\n",
      "Created sample:\n",
      "\tScan time: 730\n",
      "\tInput words: ['the', 'topmost', 'branches', 'of']\n",
      "Created sample:\n",
      "\tScan time: 732\n",
      "\tInput words: ['an', 'oak', 'he', 'called,']\n",
      "Created sample:\n",
      "\tScan time: 734\n",
      "\tInput words: ['\"Come', 'and', 'get', 'it,']\n",
      "Created sample:\n",
      "\tScan time: 736\n",
      "\tInput words: ['Potter!\"', '+', 'Harry', 'grabbed']\n",
      "Created sample:\n",
      "\tScan time: 738\n",
      "\tInput words: ['his', 'broom.', '+', '@\"No!\"']\n",
      "Created sample:\n",
      "\tScan time: 740\n",
      "\tInput words: ['shouted', 'Hermione', 'Granger.', '\"Madam']\n",
      "Created sample:\n",
      "\tScan time: 742\n",
      "\tInput words: ['Hooch', 'told', 'us', 'not']\n",
      "Created sample:\n",
      "\tScan time: 744\n",
      "\tInput words: ['to', 'move', '--', \"you'll\"]\n",
      "Created sample:\n",
      "\tScan time: 746\n",
      "\tInput words: ['get', 'us', 'all', 'into']\n",
      "Created sample:\n",
      "\tScan time: 748\n",
      "\tInput words: ['trouble.\"', '+', 'Harry', 'ignored']\n",
      "Created sample:\n",
      "\tScan time: 750\n",
      "\tInput words: ['her.', 'Blood', 'was', 'pounding']\n",
      "Created sample:\n",
      "\tScan time: 752\n",
      "\tInput words: ['in', 'his', 'ears.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 754\n",
      "\tInput words: ['mounted', 'the', 'broom', 'and']\n",
      "Created sample:\n",
      "\tScan time: 756\n",
      "\tInput words: ['kicked', 'hard', 'against', 'the']\n",
      "Created sample:\n",
      "\tScan time: 758\n",
      "\tInput words: ['ground', 'and', 'up,', 'up']\n",
      "Created sample:\n",
      "\tScan time: 760\n",
      "\tInput words: ['he', 'soared;', 'air', 'rushed']\n",
      "Created sample:\n",
      "\tScan time: 762\n",
      "\tInput words: ['through', 'his', 'hair,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 764\n",
      "\tInput words: ['his', 'robes', 'whipped', 'out']\n",
      "Created sample:\n",
      "\tScan time: 766\n",
      "\tInput words: ['behind', 'him', '--', 'and']\n",
      "Created sample:\n",
      "\tScan time: 768\n",
      "\tInput words: ['in', 'a', 'rush', 'of']\n",
      "Created sample:\n",
      "\tScan time: 770\n",
      "\tInput words: ['fierce', 'joy', 'he', 'realized']\n",
      "Created sample:\n",
      "\tScan time: 772\n",
      "\tInput words: [\"he'd\", 'found', 'something', 'he']\n",
      "Created sample:\n",
      "\tScan time: 774\n",
      "\tInput words: ['could', 'do', 'without', 'being']\n",
      "Created sample:\n",
      "\tScan time: 776\n",
      "\tInput words: ['taught', '--', 'this', 'was']\n",
      "Created sample:\n",
      "\tScan time: 778\n",
      "\tInput words: ['easy,', 'this', 'was', '@wonderful.']\n",
      "Created sample:\n",
      "\tScan time: 780\n",
      "\tInput words: ['He', 'pulled', 'his', 'broomstick']\n",
      "Created sample:\n",
      "\tScan time: 782\n",
      "\tInput words: ['up', 'a', 'little', 'to']\n",
      "Created sample:\n",
      "\tScan time: 784\n",
      "\tInput words: ['take', 'it', 'even', 'higher,']\n",
      "Created sample:\n",
      "\tScan time: 786\n",
      "\tInput words: ['and', 'heard', 'screams', 'and']\n",
      "Created sample:\n",
      "\tScan time: 788\n",
      "\tInput words: ['gasps', 'of', 'girls', 'back']\n",
      "Created sample:\n",
      "\tScan time: 790\n",
      "\tInput words: ['on', 'the', 'ground', 'and']\n",
      "Created sample:\n",
      "\tScan time: 792\n",
      "\tInput words: ['an', 'admiring', 'whoop', 'from']\n",
      "Created sample:\n",
      "\tScan time: 794\n",
      "\tInput words: ['Ron.', '+', 'He', 'turned']\n",
      "Created sample:\n",
      "\tScan time: 796\n",
      "\tInput words: ['his', 'broomstick', 'sharply', 'to']\n",
      "Created sample:\n",
      "\tScan time: 798\n",
      "\tInput words: ['face', 'Malfoy', 'in', 'midair.']\n",
      "Created sample:\n",
      "\tScan time: 800\n",
      "\tInput words: ['+', 'Malfoy', 'looked', 'stunned.']\n",
      "Created sample:\n",
      "\tScan time: 802\n",
      "\tInput words: ['\"Give', 'it', 'here,\"', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 804\n",
      "\tInput words: ['called,', '\"or', \"I'll\", 'knock']\n",
      "Created sample:\n",
      "\tScan time: 806\n",
      "\tInput words: ['you', 'off', 'that', 'broom!\"']\n",
      "Created sample:\n",
      "\tScan time: 808\n",
      "\tInput words: ['+', '\"Oh,', 'yeah?\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 810\n",
      "\tInput words: ['Malfoy,', 'trying', 'to', 'sneer,']\n",
      "Created sample:\n",
      "\tScan time: 812\n",
      "\tInput words: ['but', 'looking', 'worried.', '+']\n",
      "Created sample:\n",
      "\tScan time: 814\n",
      "\tInput words: ['Harry', 'knew,', 'somehow,', 'what']\n",
      "Created sample:\n",
      "\tScan time: 816\n",
      "\tInput words: ['to', 'do.', 'He', 'leaned']\n",
      "Created sample:\n",
      "\tScan time: 818\n",
      "\tInput words: ['forward', 'and', 'grasped', 'the']\n",
      "Created sample:\n",
      "\tScan time: 820\n",
      "\tInput words: ['broom', 'tightly', 'in', 'both']\n",
      "Created sample:\n",
      "\tScan time: 822\n",
      "\tInput words: ['hands,', 'and', 'it', 'shot']\n",
      "Created sample:\n",
      "\tScan time: 824\n",
      "\tInput words: ['toward', 'Malfoy', 'like', 'a']\n",
      "Created sample:\n",
      "\tScan time: 826\n",
      "\tInput words: ['javelin.', 'Malfoy', 'only', 'just']\n",
      "Created sample:\n",
      "\tScan time: 828\n",
      "\tInput words: ['got', 'out', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 830\n",
      "\tInput words: ['way', 'in', 'time;', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 832\n",
      "\tInput words: ['made', 'a', 'sharp', 'about-face']\n",
      "Created sample:\n",
      "\tScan time: 834\n",
      "\tInput words: ['and', 'held', 'the', 'broom']\n",
      "Created sample:\n",
      "\tScan time: 836\n",
      "\tInput words: ['steady.', 'A', 'few', 'people']\n",
      "Created sample:\n",
      "\tScan time: 838\n",
      "\tInput words: ['below', 'were', 'clapping.', '+']\n",
      "Created sample:\n",
      "\tScan time: 840\n",
      "\tInput words: ['\"No', 'Crabbe', 'and', 'Goyle']\n",
      "Created sample:\n",
      "\tScan time: 842\n",
      "\tInput words: ['up', 'here', 'to', 'save']\n",
      "Created sample:\n",
      "\tScan time: 844\n",
      "\tInput words: ['your', 'neck,', 'Malfoy,\"', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 846\n",
      "\tInput words: ['called.', '+', 'The', 'same']\n",
      "Created sample:\n",
      "\tScan time: 848\n",
      "\tInput words: ['thought', 'seemed', 'to', 'have']\n",
      "Created sample:\n",
      "\tScan time: 850\n",
      "\tInput words: ['struck', 'Malfoy.', '+', '\"Catch']\n",
      "Created sample:\n",
      "\tScan time: 852\n",
      "\tInput words: ['it', 'if', 'you', 'can,']\n",
      "Created sample:\n",
      "\tScan time: 854\n",
      "\tInput words: ['then!\"', 'he', 'shouted,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 856\n",
      "\tInput words: ['he', 'threw', 'the', 'glass']\n",
      "Created sample:\n",
      "\tScan time: 858\n",
      "\tInput words: ['ball', 'high', 'into', 'the']\n",
      "Created sample:\n",
      "\tScan time: 860\n",
      "\tInput words: ['air', 'and', 'streaked', 'back']\n",
      "Created sample:\n",
      "\tScan time: 862\n",
      "\tInput words: ['toward', 'the', 'ground.', '+']\n",
      "Created sample:\n",
      "\tScan time: 864\n",
      "\tInput words: ['Harry', 'saw,', 'as', 'though']\n",
      "Created sample:\n",
      "\tScan time: 866\n",
      "\tInput words: ['in', 'slow', 'motion,', 'the']\n",
      "Created sample:\n",
      "\tScan time: 868\n",
      "\tInput words: ['ball', 'rise', 'up', 'in']\n",
      "Created sample:\n",
      "\tScan time: 870\n",
      "\tInput words: ['the', 'air', 'and', 'then']\n",
      "Created sample:\n",
      "\tScan time: 872\n",
      "\tInput words: ['start', 'to', 'fall.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 874\n",
      "\tInput words: ['leaned', 'forward', 'and', 'pointed']\n",
      "Created sample:\n",
      "\tScan time: 876\n",
      "\tInput words: ['his', 'broom', 'handle', 'down']\n",
      "Created sample:\n",
      "\tScan time: 878\n",
      "\tInput words: ['--', 'next', 'second', 'he']\n",
      "Created sample:\n",
      "\tScan time: 880\n",
      "\tInput words: ['was', 'gathering', 'speed', 'in']\n",
      "Created sample:\n",
      "\tScan time: 882\n",
      "\tInput words: ['a', 'steep', 'dive,', 'racing']\n",
      "Created sample:\n",
      "\tScan time: 884\n",
      "\tInput words: ['the', 'ball', '--', 'wind']\n",
      "Created sample:\n",
      "\tScan time: 886\n",
      "\tInput words: ['whistled', 'in', 'his', 'ears,']\n",
      "Created sample:\n",
      "\tScan time: 888\n",
      "\tInput words: ['mingled', 'with', 'the', 'screams']\n",
      "Created sample:\n",
      "\tScan time: 890\n",
      "\tInput words: ['of', 'people', 'watching', '--']\n",
      "Created sample:\n",
      "\tScan time: 892\n",
      "\tInput words: ['he', 'stretched', 'out', 'his']\n",
      "Created sample:\n",
      "\tScan time: 894\n",
      "\tInput words: ['hand', '--', 'a', 'foot']\n",
      "Created sample:\n",
      "\tScan time: 896\n",
      "\tInput words: ['from', 'the', 'ground', 'he']\n",
      "Created sample:\n",
      "\tScan time: 898\n",
      "\tInput words: ['caught', 'it,', 'just', 'in']\n",
      "Created sample:\n",
      "\tScan time: 900\n",
      "\tInput words: ['time', 'to', 'pull', 'his']\n",
      "Created sample:\n",
      "\tScan time: 902\n",
      "\tInput words: ['broom', 'straight,', 'and', 'he']\n",
      "Created sample:\n",
      "\tScan time: 904\n",
      "\tInput words: ['toppled', 'gently', 'onto', 'the']\n",
      "Created sample:\n",
      "\tScan time: 906\n",
      "\tInput words: ['grass', 'with', 'the', 'Remembrall']\n",
      "Created sample:\n",
      "\tScan time: 908\n",
      "\tInput words: ['clutched', 'safely', 'in', 'his']\n",
      "Created sample:\n",
      "\tScan time: 910\n",
      "\tInput words: ['fist.', '+', '\"HARRY', 'POTTER!\"']\n",
      "Created sample:\n",
      "\tScan time: 912\n",
      "\tInput words: ['+', 'His', 'heart', 'sank']\n",
      "Created sample:\n",
      "\tScan time: 914\n",
      "\tInput words: ['faster', 'than', \"he'd\", 'just']\n",
      "Created sample:\n",
      "\tScan time: 916\n",
      "\tInput words: ['dived.', 'Professor', 'McGonagall', 'was']\n",
      "Created sample:\n",
      "\tScan time: 918\n",
      "\tInput words: ['running', 'toward', 'them.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 920\n",
      "\tInput words: ['got', 'to', 'his', 'feet,']\n",
      "Created sample:\n",
      "\tScan time: 922\n",
      "\tInput words: ['trembling.', '+', '@\"Never', '--']\n",
      "Created sample:\n",
      "\tScan time: 924\n",
      "\tInput words: ['in', 'all', 'my', 'time']\n",
      "Created sample:\n",
      "\tScan time: 926\n",
      "\tInput words: ['at', 'Hogwarts', '—\"', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 928\n",
      "\tInput words: ['McGonagall', 'was', 'almost', 'speechless']\n",
      "Created sample:\n",
      "\tScan time: 930\n",
      "\tInput words: ['with', 'shock,', 'and', 'her']\n",
      "Created sample:\n",
      "\tScan time: 932\n",
      "\tInput words: ['glasses', 'flashed', 'furiously,', '\"—']\n",
      "Created sample:\n",
      "\tScan time: 934\n",
      "\tInput words: ['how', '@dare', 'you', '--']\n",
      "Created sample:\n",
      "\tScan time: 936\n",
      "\tInput words: ['might', 'have', 'broken', 'your']\n",
      "Created sample:\n",
      "\tScan time: 938\n",
      "\tInput words: ['neck', '—\"', '+', '\"It']\n",
      "Created sample:\n",
      "\tScan time: 940\n",
      "\tInput words: [\"wasn't\", 'his', 'fault,', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 942\n",
      "\tInput words: ['—\"', '+', '\"Be', 'quiet,']\n",
      "Created sample:\n",
      "\tScan time: 944\n",
      "\tInput words: ['Miss', 'Patil', '—\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 946\n",
      "\tInput words: ['\"But', 'Malfoy', '—\"', '\"That\\'s']\n",
      "Created sample:\n",
      "\tScan time: 948\n",
      "\tInput words: ['enough,', 'Mr.', 'Weasley.', 'Potter,']\n",
      "Created sample:\n",
      "\tScan time: 950\n",
      "\tInput words: ['follow', 'me,', 'now.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 952\n",
      "\tInput words: ['Harry', 'caught', 'sight', 'of']\n",
      "Created sample:\n",
      "\tScan time: 954\n",
      "\tInput words: ['Malfoy,', 'Crabbe,', 'and', \"Goyle's\"]\n",
      "Created sample:\n",
      "\tScan time: 956\n",
      "\tInput words: ['triumphant', 'faces', 'as', 'he']\n",
      "Created sample:\n",
      "\tScan time: 958\n",
      "\tInput words: ['left,', 'walking', 'numbly', 'in']\n",
      "Created sample:\n",
      "\tScan time: 960\n",
      "\tInput words: ['Professor', \"McGonagall's\", 'wake', 'as']\n",
      "Created sample:\n",
      "\tScan time: 962\n",
      "\tInput words: ['she', 'strode', 'toward', 'the']\n",
      "Created sample:\n",
      "\tScan time: 964\n",
      "\tInput words: ['castle.', 'He', 'was', 'going']\n",
      "Created sample:\n",
      "\tScan time: 966\n",
      "\tInput words: ['to', 'be', 'expelled,', 'he']\n",
      "Created sample:\n",
      "\tScan time: 968\n",
      "\tInput words: ['just', 'knew', 'it.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 970\n",
      "\tInput words: ['wanted', 'to', 'say', 'something']\n",
      "Created sample:\n",
      "\tScan time: 972\n",
      "\tInput words: ['to', 'defend', 'himself,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 974\n",
      "\tInput words: ['there', 'seemed', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 976\n",
      "\tInput words: ['something', 'wrong', 'with', 'his']\n",
      "Created sample:\n",
      "\tScan time: 978\n",
      "\tInput words: ['voice.', 'Professor', 'McGonagall', 'was']\n",
      "Created sample:\n",
      "\tScan time: 980\n",
      "\tInput words: ['sweeping', 'along', 'without', 'even']\n",
      "Created sample:\n",
      "\tScan time: 982\n",
      "\tInput words: ['looking', 'at', 'him;', 'he']\n",
      "Created sample:\n",
      "\tScan time: 984\n",
      "\tInput words: ['had', 'to', 'jog', 'to']\n",
      "Created sample:\n",
      "\tScan time: 986\n",
      "\tInput words: ['keep', 'up.', 'Now', \"he'd\"]\n",
      "Created sample:\n",
      "\tScan time: 988\n",
      "\tInput words: ['done', 'it.', 'He', \"hadn't\"]\n",
      "Created sample:\n",
      "\tScan time: 990\n",
      "\tInput words: ['even', 'lasted', 'two', 'weeks.']\n",
      "Created sample:\n",
      "\tScan time: 992\n",
      "\tInput words: [\"He'd\", 'be', 'packing', 'his']\n",
      "Created sample:\n",
      "\tScan time: 994\n",
      "\tInput words: ['bags', 'in', 'ten', 'minutes.']\n",
      "Created sample:\n",
      "\tScan time: 996\n",
      "\tInput words: ['What', 'would', 'the', 'Dursleys']\n",
      "Created sample:\n",
      "\tScan time: 998\n",
      "\tInput words: ['say', 'when', 'he', 'turned']\n",
      "Created sample:\n",
      "\tScan time: 1000\n",
      "\tInput words: ['up', 'on', 'the', 'doorstep?']\n",
      "Created sample:\n",
      "\tScan time: 1002\n",
      "\tInput words: ['+', 'Up', 'the', 'front']\n",
      "Created sample:\n",
      "\tScan time: 1004\n",
      "\tInput words: ['steps,', 'up', 'the', 'marble']\n",
      "Created sample:\n",
      "\tScan time: 1006\n",
      "\tInput words: ['staircase', 'inside,', 'and', 'still']\n",
      "Created sample:\n",
      "\tScan time: 1008\n",
      "\tInput words: ['Professor', 'McGonagall', \"didn't\", 'say']\n",
      "Created sample:\n",
      "\tScan time: 1010\n",
      "\tInput words: ['a', 'word', 'to', 'him.']\n",
      "Created sample:\n",
      "\tScan time: 1012\n",
      "\tInput words: ['She', 'wrenched', 'open', 'doors']\n",
      "Created sample:\n",
      "\tScan time: 1014\n",
      "\tInput words: ['and', 'marched', 'along', 'corridors']\n",
      "Created sample:\n",
      "\tScan time: 1016\n",
      "\tInput words: ['with', 'Harry', 'trotting', 'miserably']\n",
      "Created sample:\n",
      "\tScan time: 1018\n",
      "\tInput words: ['behind', 'her.', 'Maybe', 'she']\n",
      "Created sample:\n",
      "\tScan time: 1020\n",
      "\tInput words: ['was', 'taking', 'him', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1022\n",
      "\tInput words: ['Dumbledore.', 'He', 'thought', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1024\n",
      "\tInput words: ['Hagrid,', 'expelled', 'but', 'allowed']\n",
      "Created sample:\n",
      "\tScan time: 1026\n",
      "\tInput words: ['to', 'stay', 'on', 'as']\n",
      "Created sample:\n",
      "\tScan time: 1028\n",
      "\tInput words: ['gamekeeper.', 'Perhaps', 'he', 'could']\n",
      "Created sample:\n",
      "\tScan time: 1030\n",
      "\tInput words: ['be', \"Hagrid's\", 'assistant.', 'His']\n",
      "Created sample:\n",
      "\tScan time: 1032\n",
      "\tInput words: ['stomach', 'twisted', 'as', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1034\n",
      "\tInput words: ['imagined', 'it,', 'watching', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 1036\n",
      "\tInput words: ['and', 'the', 'others', 'becoming']\n",
      "Created sample:\n",
      "\tScan time: 1038\n",
      "\tInput words: ['wizards', 'while', 'he', 'stumped']\n",
      "Created sample:\n",
      "\tScan time: 1040\n",
      "\tInput words: ['around', 'the', 'grounds', 'carrying']\n",
      "Created sample:\n",
      "\tScan time: 1042\n",
      "\tInput words: [\"Hagrid's\", 'bag.', '+', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 1044\n",
      "\tInput words: ['McGonagall', 'stopped', 'outside', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1046\n",
      "\tInput words: ['classroom.', 'She', 'opened', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1048\n",
      "\tInput words: ['door', 'and', 'poked', 'her']\n",
      "Created sample:\n",
      "\tScan time: 1050\n",
      "\tInput words: ['head', 'inside.', '+', '\"Excuse']\n",
      "Created sample:\n",
      "\tScan time: 1052\n",
      "\tInput words: ['me,', 'Professor', 'Flitwick,', 'could']\n",
      "Created sample:\n",
      "\tScan time: 1054\n",
      "\tInput words: ['I', 'borrow', 'Wood', 'for']\n",
      "Created sample:\n",
      "\tScan time: 1056\n",
      "\tInput words: ['a', 'moment?\"', '+', 'Wood?']\n",
      "Created sample:\n",
      "\tScan time: 1058\n",
      "\tInput words: ['thought', 'Harry,', 'bewildered;', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1060\n",
      "\tInput words: ['Wood', 'a', 'cane', 'she']\n",
      "Created sample:\n",
      "\tScan time: 1062\n",
      "\tInput words: ['was', 'going', 'to', 'use']\n",
      "Created sample:\n",
      "\tScan time: 1064\n",
      "\tInput words: ['on', 'him?', 'But', 'Wood']\n",
      "Created sample:\n",
      "\tScan time: 1066\n",
      "\tInput words: ['turned', 'out', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1068\n",
      "\tInput words: ['a', 'person,', 'a', 'burly']\n",
      "Created sample:\n",
      "\tScan time: 1070\n",
      "\tInput words: ['fifth-year', 'boy', 'who', 'came']\n",
      "Created sample:\n",
      "\tScan time: 1072\n",
      "\tInput words: ['out', 'of', \"Flitwick's\", 'class']\n",
      "Created sample:\n",
      "\tScan time: 1074\n",
      "\tInput words: ['looking', 'confused.', '+', '\"Follow']\n",
      "Created sample:\n",
      "\tScan time: 1076\n",
      "\tInput words: ['me,', 'you', 'two,\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 1078\n",
      "\tInput words: ['Professor', 'McGonagall,', 'and', 'they']\n",
      "Created sample:\n",
      "\tScan time: 1080\n",
      "\tInput words: ['marched', 'on', 'up', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1082\n",
      "\tInput words: ['corridor,', 'Wood', 'looking', 'curiously']\n",
      "Created sample:\n",
      "\tScan time: 1084\n",
      "\tInput words: ['at', 'Harry.', '+', '\"In']\n",
      "Created sample:\n",
      "\tScan time: 1086\n",
      "\tInput words: ['here.\"', '+', 'Professor', 'McGonagall']\n",
      "Created sample:\n",
      "\tScan time: 1088\n",
      "\tInput words: ['pointed', 'them', 'into', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1090\n",
      "\tInput words: ['classroom', 'that', 'was', 'empty']\n",
      "Created sample:\n",
      "\tScan time: 1092\n",
      "\tInput words: ['except', 'for', 'Peeves,', 'who']\n",
      "Created sample:\n",
      "\tScan time: 1094\n",
      "\tInput words: ['was', 'busy', 'writing', 'rude']\n",
      "Created sample:\n",
      "\tScan time: 1096\n",
      "\tInput words: ['words', 'on', 'the', 'blackboard.']\n",
      "Created sample:\n",
      "\tScan time: 1098\n",
      "\tInput words: ['+', '\"Out,', 'Peeves!\"', 'she']\n",
      "Created sample:\n",
      "\tScan time: 1100\n",
      "\tInput words: ['barked.', 'Peeves', 'threw', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1102\n",
      "\tInput words: ['chalk', 'into', 'a', 'bin,']\n",
      "Created sample:\n",
      "\tScan time: 1104\n",
      "\tInput words: ['which', 'clanged', 'loudly,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1106\n",
      "\tInput words: ['he', 'swooped', 'out', 'cursing.']\n",
      "Created sample:\n",
      "\tScan time: 1108\n",
      "\tInput words: ['Professor', 'McGonagall', 'slammed', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1110\n",
      "\tInput words: ['door', 'behind', 'him', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1112\n",
      "\tInput words: ['turned', 'to', 'face', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1114\n",
      "\tInput words: ['two', 'boys.', '+', '\"Potter,']\n",
      "Created sample:\n",
      "\tScan time: 1116\n",
      "\tInput words: ['this', 'is', 'Oliver', 'Wood.']\n",
      "Created sample:\n",
      "\tScan time: 1118\n",
      "\tInput words: ['Wood', '--', \"I've\", 'found']\n",
      "Created sample:\n",
      "\tScan time: 1120\n",
      "\tInput words: ['you', 'a', 'Seeker.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1122\n",
      "\tInput words: [\"Wood's\", 'expression', 'changed', 'from']\n",
      "Created sample:\n",
      "\tScan time: 1124\n",
      "\tInput words: ['puzzlement', 'to', 'delight.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1126\n",
      "\tInput words: ['\"Are', 'you', 'serious,', 'Professor?\"']\n",
      "Created sample:\n",
      "\tScan time: 1128\n",
      "\tInput words: ['+', '\"Absolutely,\"', 'said', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 1130\n",
      "\tInput words: ['McGonagall', 'crisply.', '\"The', \"boy's\"]\n",
      "Created sample:\n",
      "\tScan time: 1132\n",
      "\tInput words: ['a', 'natural.', \"I've\", 'never']\n",
      "Created sample:\n",
      "\tScan time: 1134\n",
      "\tInput words: ['seen', 'anything', 'like', 'it.']\n",
      "Created sample:\n",
      "\tScan time: 1136\n",
      "\tInput words: ['Was', 'that', 'your', 'first']\n",
      "Created sample:\n",
      "\tScan time: 1138\n",
      "\tInput words: ['time', 'on', 'a', 'broomstick,']\n",
      "Created sample:\n",
      "\tScan time: 1140\n",
      "\tInput words: ['Potter?\"', '+', 'Harry', 'nodded']\n",
      "Created sample:\n",
      "\tScan time: 1142\n",
      "\tInput words: ['silently.', 'He', \"didn't\", 'have']\n",
      "Created sample:\n",
      "\tScan time: 1144\n",
      "\tInput words: ['a', 'clue', 'what', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1146\n",
      "\tInput words: ['going', 'on,', 'but', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1148\n",
      "\tInput words: [\"didn't\", 'seem', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1150\n",
      "\tInput words: ['being', 'expelled,', 'and', 'some']\n",
      "Created sample:\n",
      "\tScan time: 1152\n",
      "\tInput words: ['of', 'the', 'feeling', 'started']\n",
      "Created sample:\n",
      "\tScan time: 1154\n",
      "\tInput words: ['coming', 'back', 'to', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1156\n",
      "\tInput words: ['legs.', '+', '\"He', 'caught']\n",
      "Created sample:\n",
      "\tScan time: 1158\n",
      "\tInput words: ['that', 'thing', 'in', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1160\n",
      "\tInput words: ['hand', 'after', 'a', 'fifty-foot']\n",
      "Created sample:\n",
      "\tScan time: 1162\n",
      "\tInput words: ['dive,\"', 'Professor', 'McGonagall', 'told']\n",
      "Created sample:\n",
      "\tScan time: 1164\n",
      "\tInput words: ['Wood.', '\"Didn\\'t', 'even', 'scratch']\n",
      "Created sample:\n",
      "\tScan time: 1166\n",
      "\tInput words: ['himself.', 'Charlie', 'Weasley', \"couldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 1168\n",
      "\tInput words: ['have', 'done', 'it.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1170\n",
      "\tInput words: ['Wood', 'was', 'now', 'looking']\n",
      "Created sample:\n",
      "\tScan time: 1172\n",
      "\tInput words: ['as', 'though', 'all', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1174\n",
      "\tInput words: ['dreams', 'had', 'come', 'true']\n",
      "Created sample:\n",
      "\tScan time: 1176\n",
      "\tInput words: ['at', 'once.', '+', '\"Ever']\n",
      "Created sample:\n",
      "\tScan time: 1178\n",
      "\tInput words: ['seen', 'a', 'game', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1180\n",
      "\tInput words: ['Quidditch,', 'Potter?\"', 'he', 'asked']\n",
      "Created sample:\n",
      "\tScan time: 1182\n",
      "\tInput words: ['excitedly.', '+', '\"Wood\\'s', 'captain']\n",
      "Created sample:\n",
      "\tScan time: 1184\n",
      "\tInput words: ['of', 'the', 'Gryffindor', 'team,\"']\n",
      "Created sample:\n",
      "\tScan time: 1186\n",
      "\tInput words: ['Professor', 'McGonagall', 'explained.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1188\n",
      "\tInput words: ['\"He\\'s', 'just', 'the', 'build']\n",
      "Created sample:\n",
      "\tScan time: 1190\n",
      "\tInput words: ['for', 'a', 'Seeker,', 'too,\"']\n",
      "Created sample:\n",
      "\tScan time: 1192\n",
      "\tInput words: ['said', 'Wood,', 'now', 'walking']\n",
      "Created sample:\n",
      "\tScan time: 1194\n",
      "\tInput words: ['around', 'Harry', 'and', 'staring']\n",
      "Created sample:\n",
      "\tScan time: 1196\n",
      "\tInput words: ['at', 'him.', '\"Light', '--']\n",
      "Created sample:\n",
      "\tScan time: 1198\n",
      "\tInput words: ['speedy', '--', \"we'll\", 'have']\n",
      "Created sample:\n",
      "\tScan time: 1200\n",
      "\tInput words: ['to', 'get', 'him', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1202\n",
      "\tInput words: ['decent', 'broom,', 'Professor', '--']\n",
      "Created sample:\n",
      "\tScan time: 1204\n",
      "\tInput words: ['a', 'Nimbus', 'Two', 'Thousand']\n",
      "Created sample:\n",
      "\tScan time: 1206\n",
      "\tInput words: ['or', 'a', 'Cleansweep', 'Seven,']\n",
      "Created sample:\n",
      "\tScan time: 1208\n",
      "\tInput words: [\"I'd\", 'say.\"', '+', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 1210\n",
      "\tInput words: ['shall', 'speak', 'to', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 1212\n",
      "\tInput words: ['Dumbledore', 'and', 'see', 'if']\n",
      "Created sample:\n",
      "\tScan time: 1214\n",
      "\tInput words: ['we', \"can't\", 'bend', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1216\n",
      "\tInput words: ['first-year', 'rule.', 'Heaven', 'knows,']\n",
      "Created sample:\n",
      "\tScan time: 1218\n",
      "\tInput words: ['we', 'need', 'a', 'better']\n",
      "Created sample:\n",
      "\tScan time: 1220\n",
      "\tInput words: ['team', 'than', 'last', 'year.']\n",
      "Created sample:\n",
      "\tScan time: 1222\n",
      "\tInput words: ['Flattened', 'in', 'that', 'last']\n",
      "Created sample:\n",
      "\tScan time: 1224\n",
      "\tInput words: ['match', 'by', 'Slytherin,', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1226\n",
      "\tInput words: [\"couldn't\", 'look', 'Severus', 'Snape']\n",
      "Created sample:\n",
      "\tScan time: 1228\n",
      "\tInput words: ['in', 'the', 'face', 'for']\n",
      "Created sample:\n",
      "\tScan time: 1230\n",
      "\tInput words: ['weeks.', '….\"', '+', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 1232\n",
      "\tInput words: ['McGonagall', 'peered', 'sternly', 'over']\n",
      "Created sample:\n",
      "\tScan time: 1234\n",
      "\tInput words: ['her', 'glasses', 'at', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 1236\n",
      "\tInput words: ['+', '\"I', 'want', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1238\n",
      "\tInput words: ['hear', \"you're\", 'training', 'hard,']\n",
      "Created sample:\n",
      "\tScan time: 1240\n",
      "\tInput words: ['Potter,', 'or', 'I', 'may']\n",
      "Created sample:\n",
      "\tScan time: 1242\n",
      "\tInput words: ['change', 'my', 'mind', 'about']\n",
      "Created sample:\n",
      "\tScan time: 1244\n",
      "\tInput words: ['punishing', 'you.\"', '+', 'Then']\n",
      "Created sample:\n",
      "\tScan time: 1246\n",
      "\tInput words: ['she', 'suddenly', 'smiled.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1248\n",
      "\tInput words: ['\"Your', 'father', 'would', 'have']\n",
      "Created sample:\n",
      "\tScan time: 1250\n",
      "\tInput words: ['been', 'proud,\"', 'she', 'said.']\n",
      "Created sample:\n",
      "\tScan time: 1252\n",
      "\tInput words: ['\"He', 'was', 'an', 'excellent']\n",
      "Created sample:\n",
      "\tScan time: 1254\n",
      "\tInput words: ['Quidditch', 'player', 'himself.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1256\n",
      "\tInput words: ['+', '\"You\\'re', '@joking.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1258\n",
      "\tInput words: ['It', 'was', 'dinnertime.', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 1260\n",
      "\tInput words: ['had', 'just', 'finished', 'telling']\n",
      "Created sample:\n",
      "\tScan time: 1262\n",
      "\tInput words: ['Ron', 'what', 'had', 'happened']\n",
      "Created sample:\n",
      "\tScan time: 1264\n",
      "\tInput words: ['when', \"he'd\", 'left', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1266\n",
      "\tInput words: ['grounds', 'with', 'Professor', 'McGonagall.']\n",
      "Created sample:\n",
      "\tScan time: 1268\n",
      "\tInput words: ['Ron', 'had', 'a', 'piece']\n",
      "Created sample:\n",
      "\tScan time: 1270\n",
      "\tInput words: ['of', 'steak', 'and', 'kidney']\n",
      "Created sample:\n",
      "\tScan time: 1272\n",
      "\tInput words: ['pie', 'halfway', 'to', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1274\n",
      "\tInput words: ['mouth,', 'but', \"he'd\", 'forgotten']\n",
      "Created sample:\n",
      "\tScan time: 1276\n",
      "\tInput words: ['all', 'about', 'it.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1278\n",
      "\tInput words: ['@\"Seeker?\"', 'he', 'said.', '\"But']\n",
      "Created sample:\n",
      "\tScan time: 1280\n",
      "\tInput words: ['first', 'years', '@never', '--']\n",
      "Created sample:\n",
      "\tScan time: 1282\n",
      "\tInput words: ['you', 'must', 'be', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1284\n",
      "\tInput words: ['youngest', 'House', 'player', 'in']\n",
      "Created sample:\n",
      "\tScan time: 1286\n",
      "\tInput words: ['about', '—\"', '+', '\"—']\n",
      "Created sample:\n",
      "\tScan time: 1288\n",
      "\tInput words: ['a', 'century,\"', 'said', 'Harry,']\n",
      "Created sample:\n",
      "\tScan time: 1290\n",
      "\tInput words: ['shoveling', 'pie', 'into', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1292\n",
      "\tInput words: ['mouth.', 'He', 'felt', 'particularly']\n",
      "Created sample:\n",
      "\tScan time: 1294\n",
      "\tInput words: ['hungry', 'after', 'the', 'excitement']\n",
      "Created sample:\n",
      "\tScan time: 1296\n",
      "\tInput words: ['of', 'the', 'afternoon.', '\"Wood']\n",
      "Created sample:\n",
      "\tScan time: 1298\n",
      "\tInput words: ['told', 'me.\"', '+', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 1300\n",
      "\tInput words: ['was', 'so', 'amazed,', 'so']\n",
      "Created sample:\n",
      "\tScan time: 1302\n",
      "\tInput words: ['impressed,', 'he', 'just', 'sat']\n",
      "Created sample:\n",
      "\tScan time: 1304\n",
      "\tInput words: ['and', 'gaped', 'at', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 1306\n",
      "\tInput words: ['+', '\"I', 'start', 'training']\n",
      "Created sample:\n",
      "\tScan time: 1308\n",
      "\tInput words: ['next', 'week,\"', 'said', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 1310\n",
      "\tInput words: ['\"Only', \"don't\", 'tell', 'anyone,']\n",
      "Created sample:\n",
      "\tScan time: 1312\n",
      "\tInput words: ['Wood', 'wants', 'to', 'keep']\n",
      "Created sample:\n",
      "\tScan time: 1314\n",
      "\tInput words: ['it', 'a', 'secret.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1316\n",
      "\tInput words: ['Fred', 'and', 'George', 'Weasley']\n",
      "Created sample:\n",
      "\tScan time: 1318\n",
      "\tInput words: ['now', 'came', 'into', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1320\n",
      "\tInput words: ['hall,', 'spotted', 'Harry,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1322\n",
      "\tInput words: ['hurried', 'over.', '+', '\"Well']\n",
      "Created sample:\n",
      "\tScan time: 1324\n",
      "\tInput words: ['done,\"', 'said', 'George', 'in']\n",
      "Created sample:\n",
      "\tScan time: 1326\n",
      "\tInput words: ['a', 'low', 'voice.', '\"Wood']\n",
      "Created sample:\n",
      "\tScan time: 1328\n",
      "\tInput words: ['told', 'us.', \"We're\", 'on']\n",
      "Created sample:\n",
      "\tScan time: 1330\n",
      "\tInput words: ['the', 'team', 'too', '--']\n",
      "Created sample:\n",
      "\tScan time: 1332\n",
      "\tInput words: ['Beaters.\"', '+', '\"I', 'tell']\n",
      "Created sample:\n",
      "\tScan time: 1334\n",
      "\tInput words: ['you,', \"we're\", 'going', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1336\n",
      "\tInput words: ['win', 'that', 'Quidditch', 'Cup']\n",
      "Created sample:\n",
      "\tScan time: 1338\n",
      "\tInput words: ['for', 'sure', 'this', 'year,\"']\n",
      "Created sample:\n",
      "\tScan time: 1340\n",
      "\tInput words: ['said', 'Fred.', '\"We', \"haven't\"]\n",
      "Created sample:\n",
      "\tScan time: 1342\n",
      "\tInput words: ['won', 'since', 'Charlie', 'left,']\n",
      "Created sample:\n",
      "\tScan time: 1344\n",
      "\tInput words: ['but', 'this', \"year's\", 'team']\n",
      "Created sample:\n",
      "\tScan time: 1346\n",
      "\tInput words: ['is', 'going', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1348\n",
      "\tInput words: ['brilliant.', 'You', 'must', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1350\n",
      "\tInput words: ['good,', 'Harry,', 'Wood', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1352\n",
      "\tInput words: ['almost', 'skipping', 'when', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1354\n",
      "\tInput words: ['told', 'us.\"', '+', '\"Anyway,']\n",
      "Created sample:\n",
      "\tScan time: 1356\n",
      "\tInput words: [\"we've\", 'got', 'to', 'go,']\n",
      "Created sample:\n",
      "\tScan time: 1358\n",
      "\tInput words: ['Lee', 'Jordan', 'reckons', \"he's\"]\n",
      "Created sample:\n",
      "\tScan time: 1360\n",
      "\tInput words: ['found', 'a', 'new', 'secret']\n",
      "Created sample:\n",
      "\tScan time: 1362\n",
      "\tInput words: ['passageway', 'out', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1364\n",
      "\tInput words: ['school.\"', '+', '\"Bet', \"it's\"]\n",
      "Created sample:\n",
      "\tScan time: 1366\n",
      "\tInput words: ['that', 'one', 'behind', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1368\n",
      "\tInput words: ['statue', 'of', 'Gregory', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1370\n",
      "\tInput words: ['Smarmy', 'that', 'we', 'found']\n",
      "Created sample:\n",
      "\tScan time: 1404\n",
      "\tInput words: ['Fred', 'and', 'George', 'had']\n",
      "Created sample:\n",
      "\tScan time: 1406\n",
      "\tInput words: ['hardly', 'disappeared', 'when', 'someone']\n",
      "Created sample:\n",
      "\tScan time: 1408\n",
      "\tInput words: ['far', 'less', 'welcome', 'turned']\n",
      "Created sample:\n",
      "\tScan time: 1410\n",
      "\tInput words: ['up:', 'Malfoy,', 'flanked', 'by']\n",
      "Created sample:\n",
      "\tScan time: 1412\n",
      "\tInput words: ['Crabbe', 'and', 'Goyle.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1414\n",
      "\tInput words: ['\"Having', 'a', 'last', 'meal,']\n",
      "Created sample:\n",
      "\tScan time: 1416\n",
      "\tInput words: ['Potter?', 'When', 'are', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1418\n",
      "\tInput words: ['getting', 'the', 'train', 'back']\n",
      "Created sample:\n",
      "\tScan time: 1420\n",
      "\tInput words: ['to', 'the', 'Muggles?\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1422\n",
      "\tInput words: ['\"You\\'re', 'a', 'lot', 'braver']\n",
      "Created sample:\n",
      "\tScan time: 1424\n",
      "\tInput words: ['now', 'that', \"you're\", 'back']\n",
      "Created sample:\n",
      "\tScan time: 1426\n",
      "\tInput words: ['on', 'the', 'ground', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1428\n",
      "\tInput words: [\"you've\", 'got', 'your', 'little']\n",
      "Created sample:\n",
      "\tScan time: 1430\n",
      "\tInput words: ['friends', 'with', 'you,\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 1432\n",
      "\tInput words: ['Harry', 'coolly.', 'There', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1434\n",
      "\tInput words: ['of', 'course', 'nothing', 'at']\n",
      "Created sample:\n",
      "\tScan time: 1436\n",
      "\tInput words: ['all', 'little', 'about', 'Crabbe']\n",
      "Created sample:\n",
      "\tScan time: 1438\n",
      "\tInput words: ['and', 'Goyle,', 'but', 'as']\n",
      "Created sample:\n",
      "\tScan time: 1440\n",
      "\tInput words: ['the', 'High', 'Table', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1442\n",
      "\tInput words: ['full', 'of', 'teachers,', 'neither']\n",
      "Created sample:\n",
      "\tScan time: 1444\n",
      "\tInput words: ['of', 'them', 'could', 'do']\n",
      "Created sample:\n",
      "\tScan time: 1446\n",
      "\tInput words: ['more', 'than', 'crack', 'their']\n",
      "Created sample:\n",
      "\tScan time: 1448\n",
      "\tInput words: ['knuckles', 'and', 'scowl.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1450\n",
      "\tInput words: ['\"I\\'d', 'take', 'you', 'on']\n",
      "Created sample:\n",
      "\tScan time: 1452\n",
      "\tInput words: ['anytime', 'on', 'my', 'own,\"']\n",
      "Created sample:\n",
      "\tScan time: 1454\n",
      "\tInput words: ['said', 'Malfoy.', '\"Tonight,', 'if']\n",
      "Created sample:\n",
      "\tScan time: 1456\n",
      "\tInput words: ['you', 'want.', \"Wizard's\", 'duel.']\n",
      "Created sample:\n",
      "\tScan time: 1458\n",
      "\tInput words: ['Wands', 'only', '--', 'no']\n",
      "Created sample:\n",
      "\tScan time: 1460\n",
      "\tInput words: ['contact.', \"What's\", 'the', 'matter?']\n",
      "Created sample:\n",
      "\tScan time: 1462\n",
      "\tInput words: ['Never', 'heard', 'of', 'a']\n",
      "Created sample:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScan time: 1464\n",
      "\tInput words: [\"wizard's\", 'duel', 'before,', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1466\n",
      "\tInput words: ['suppose?\"', '+', '\"Of', 'course']\n",
      "Created sample:\n",
      "\tScan time: 1468\n",
      "\tInput words: ['he', 'has,\"', 'said', 'Ron,']\n",
      "Created sample:\n",
      "\tScan time: 1470\n",
      "\tInput words: ['wheeling', 'around.', '\"I\\'m', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1472\n",
      "\tInput words: ['second,', \"who's\", 'yours?\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1474\n",
      "\tInput words: ['Malfoy', 'looked', 'at', 'Crabbe']\n",
      "Created sample:\n",
      "\tScan time: 1476\n",
      "\tInput words: ['and', 'Goyle,', 'sizing', 'them']\n",
      "Created sample:\n",
      "\tScan time: 1478\n",
      "\tInput words: ['up.', '+', '\"Crabbe,\"', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1480\n",
      "\tInput words: ['said.', '\"Midnight', 'all', 'right?']\n",
      "Created sample:\n",
      "\tScan time: 1482\n",
      "\tInput words: [\"We'll\", 'meet', 'you', 'in']\n",
      "Created sample:\n",
      "\tScan time: 1484\n",
      "\tInput words: ['the', 'trophy', 'room;', \"that's\"]\n",
      "Created sample:\n",
      "\tScan time: 1486\n",
      "\tInput words: ['always', 'unlocked.\"', '+', 'When']\n",
      "Created sample:\n",
      "\tScan time: 1488\n",
      "\tInput words: ['Malfoy', 'had', 'gone,', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 1490\n",
      "\tInput words: ['and', 'Harry', 'looked', 'at']\n",
      "Created sample:\n",
      "\tScan time: 1492\n",
      "\tInput words: ['each', 'other.', '+', '\"What']\n",
      "Created sample:\n",
      "\tScan time: 1494\n",
      "\tInput words: ['@is', 'a', \"wizard's\", 'duel?\"']\n",
      "Created sample:\n",
      "\tScan time: 1496\n",
      "\tInput words: ['said', 'Harry.', '\"And', 'what']\n",
      "Created sample:\n",
      "\tScan time: 1498\n",
      "\tInput words: ['do', 'you', 'mean,', \"you're\"]\n",
      "Created sample:\n",
      "\tScan time: 1500\n",
      "\tInput words: ['my', 'second?\"', '+', '\"Well,']\n",
      "Created sample:\n",
      "\tScan time: 1502\n",
      "\tInput words: ['a', \"second's\", 'there', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1504\n",
      "\tInput words: ['take', 'over', 'if', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1506\n",
      "\tInput words: ['die,\"', 'said', 'Ron', 'casually,']\n",
      "Created sample:\n",
      "\tScan time: 1508\n",
      "\tInput words: ['getting', 'started', 'at', 'last']\n",
      "Created sample:\n",
      "\tScan time: 1510\n",
      "\tInput words: ['on', 'his', 'cold', 'pie.']\n",
      "Created sample:\n",
      "\tScan time: 1512\n",
      "\tInput words: ['Catching', 'the', 'look', 'on']\n",
      "Created sample:\n",
      "\tScan time: 1514\n",
      "\tInput words: [\"Harry's\", 'face,', 'he', 'added']\n",
      "Created sample:\n",
      "\tScan time: 1516\n",
      "\tInput words: ['quickly,', '\"But', 'people', 'only']\n",
      "Created sample:\n",
      "\tScan time: 1518\n",
      "\tInput words: ['die', 'in', 'proper', 'duels,']\n",
      "Created sample:\n",
      "\tScan time: 1520\n",
      "\tInput words: ['you', 'know,', 'with', 'real']\n",
      "Created sample:\n",
      "\tScan time: 1522\n",
      "\tInput words: ['wizards.', 'The', 'most', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1524\n",
      "\tInput words: ['and', \"Malfoy'll\", 'be', 'able']\n",
      "Created sample:\n",
      "\tScan time: 1526\n",
      "\tInput words: ['to', 'do', 'is', 'send']\n",
      "Created sample:\n",
      "\tScan time: 1528\n",
      "\tInput words: ['sparks', 'at', 'each', 'other.']\n",
      "Created sample:\n",
      "\tScan time: 1530\n",
      "\tInput words: ['Neither', 'of', 'you', 'knows']\n",
      "Created sample:\n",
      "\tScan time: 1532\n",
      "\tInput words: ['enough', 'magic', 'to', 'do']\n",
      "Created sample:\n",
      "\tScan time: 1534\n",
      "\tInput words: ['any', 'real', 'damage.', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1536\n",
      "\tInput words: ['bet', 'he', 'expected', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1538\n",
      "\tInput words: ['to', 'refuse,', 'anyway.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1540\n",
      "\tInput words: ['\"And', 'what', 'if', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1542\n",
      "\tInput words: ['wave', 'my', 'wand', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1544\n",
      "\tInput words: ['nothing', 'happens?\"', '+', '\"Throw']\n",
      "Created sample:\n",
      "\tScan time: 1546\n",
      "\tInput words: ['it', 'away', 'and', 'punch']\n",
      "Created sample:\n",
      "\tScan time: 1548\n",
      "\tInput words: ['him', 'on', 'the', 'nose,\"']\n",
      "Created sample:\n",
      "\tScan time: 1550\n",
      "\tInput words: ['Ron', 'suggested.', '+', '\"Excuse']\n",
      "Created sample:\n",
      "\tScan time: 1552\n",
      "\tInput words: ['me.\"', '+', 'They', 'both']\n",
      "Created sample:\n",
      "\tScan time: 1554\n",
      "\tInput words: ['looked', 'up.', 'It', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1556\n",
      "\tInput words: ['Hermione', 'Granger.', '+', '\"Can\\'t']\n",
      "Created sample:\n",
      "\tScan time: 1558\n",
      "\tInput words: ['a', 'person', 'eat', 'in']\n",
      "Created sample:\n",
      "\tScan time: 1560\n",
      "\tInput words: ['peace', 'in', 'this', 'place?\"']\n",
      "Created sample:\n",
      "\tScan time: 1562\n",
      "\tInput words: ['said', 'Ron.', '+', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1564\n",
      "\tInput words: ['ignored', 'him', 'and', 'spoke']\n",
      "Created sample:\n",
      "\tScan time: 1566\n",
      "\tInput words: ['to', 'Harry.', '\"I', \"couldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 1568\n",
      "\tInput words: ['help', 'overhearing', 'what', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1570\n",
      "\tInput words: ['and', 'Malfoy', 'were', 'saying']\n",
      "Created sample:\n",
      "\tScan time: 1572\n",
      "\tInput words: ['—\"', '+', '\"Bet', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1574\n",
      "\tInput words: ['could,\"', 'Ron', 'muttered.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1576\n",
      "\tInput words: ['\"—', 'and', 'you', \"@mustn't\"]\n",
      "Created sample:\n",
      "\tScan time: 1578\n",
      "\tInput words: ['go', 'wandering', 'around', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1580\n",
      "\tInput words: ['school', 'at', 'night,', 'think']\n",
      "Created sample:\n",
      "\tScan time: 1582\n",
      "\tInput words: ['of', 'the', 'points', \"you'll\"]\n",
      "Created sample:\n",
      "\tScan time: 1584\n",
      "\tInput words: ['lose', 'Gryffindor', 'if', \"you're\"]\n",
      "Created sample:\n",
      "\tScan time: 1586\n",
      "\tInput words: ['caught,', 'and', \"you're\", 'bound']\n",
      "Created sample:\n",
      "\tScan time: 1588\n",
      "\tInput words: ['to', 'be.', \"It's\", 'really']\n",
      "Created sample:\n",
      "\tScan time: 1590\n",
      "\tInput words: ['very', 'selfish', 'of', 'you.\"']\n",
      "Created sample:\n",
      "\tScan time: 1592\n",
      "\tInput words: ['+', '\"And', \"it's\", 'really']\n",
      "Created sample:\n",
      "\tScan time: 1594\n",
      "\tInput words: ['none', 'of', 'your', 'business,\"']\n",
      "Created sample:\n",
      "\tScan time: 1596\n",
      "\tInput words: ['said', 'Harry.', '+', '\"Good-bye,\"']\n",
      "Created sample:\n",
      "\tScan time: 1598\n",
      "\tInput words: ['said', 'Ron.', '+', '+']\n",
      "Created sample:\n",
      "\tScan time: 1600\n",
      "\tInput words: ['All', 'the', 'same,', 'it']\n",
      "Created sample:\n",
      "\tScan time: 1602\n",
      "\tInput words: [\"wasn't\", 'what', \"you'd\", 'call']\n",
      "Created sample:\n",
      "\tScan time: 1604\n",
      "\tInput words: ['the', 'perfect', 'end', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1606\n",
      "\tInput words: ['the', 'day,', 'Harry', 'thought,']\n",
      "Created sample:\n",
      "\tScan time: 1608\n",
      "\tInput words: ['as', 'he', 'lay', 'awake']\n",
      "Created sample:\n",
      "\tScan time: 1610\n",
      "\tInput words: ['much', 'later', 'listening', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1612\n",
      "\tInput words: ['Dean', 'and', 'Seamus', 'falling']\n",
      "Created sample:\n",
      "\tScan time: 1614\n",
      "\tInput words: ['asleep', '(Neville', \"wasn't\", 'back']\n",
      "Created sample:\n",
      "\tScan time: 1616\n",
      "\tInput words: ['from', 'the', 'hospital', 'wing).']\n",
      "Created sample:\n",
      "\tScan time: 1618\n",
      "\tInput words: ['Ron', 'had', 'spent', 'all']\n",
      "Created sample:\n",
      "\tScan time: 1620\n",
      "\tInput words: ['evening', 'giving', 'him', 'advice']\n",
      "Created sample:\n",
      "\tScan time: 1622\n",
      "\tInput words: ['such', 'as', '\"If', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1624\n",
      "\tInput words: ['tries', 'to', 'curse', 'you,']\n",
      "Created sample:\n",
      "\tScan time: 1626\n",
      "\tInput words: [\"you'd\", 'better', 'dodge', 'it,']\n",
      "Created sample:\n",
      "\tScan time: 1628\n",
      "\tInput words: ['because', 'I', \"can't\", 'remember']\n",
      "Created sample:\n",
      "\tScan time: 1630\n",
      "\tInput words: ['how', 'to', 'block', 'them.\"']\n",
      "Created sample:\n",
      "\tScan time: 1632\n",
      "\tInput words: ['There', 'was', 'a', 'very']\n",
      "Created sample:\n",
      "\tScan time: 1634\n",
      "\tInput words: ['good', 'chance', 'they', 'were']\n",
      "Created sample:\n",
      "\tScan time: 1636\n",
      "\tInput words: ['going', 'to', 'get', 'caught']\n",
      "Created sample:\n",
      "\tScan time: 1638\n",
      "\tInput words: ['by', 'Filch', 'or', 'Mrs.']\n",
      "Created sample:\n",
      "\tScan time: 1640\n",
      "\tInput words: ['Norris,', 'and', 'Harry', 'felt']\n",
      "Created sample:\n",
      "\tScan time: 1642\n",
      "\tInput words: ['he', 'was', 'pushing', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1644\n",
      "\tInput words: ['luck,', 'breaking', 'another', 'school']\n",
      "Created sample:\n",
      "\tScan time: 1646\n",
      "\tInput words: ['rule', 'today.', 'On', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1648\n",
      "\tInput words: ['other', 'hand,', \"Malfoy's\", 'sneering']\n",
      "Created sample:\n",
      "\tScan time: 1650\n",
      "\tInput words: ['face', 'kept', 'looming', 'up']\n",
      "Created sample:\n",
      "\tScan time: 1652\n",
      "\tInput words: ['out', 'of', 'the', 'darkness']\n",
      "Created sample:\n",
      "\tScan time: 1654\n",
      "\tInput words: ['--', 'this', 'was', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1656\n",
      "\tInput words: ['big', 'chance', 'to', 'beat']\n",
      "Created sample:\n",
      "\tScan time: 1658\n",
      "\tInput words: ['Malfoy', 'face-to-face.', 'He', \"couldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 1660\n",
      "\tInput words: ['miss', 'it.', '+', '\"Half-past']\n",
      "Created sample:\n",
      "\tScan time: 1662\n",
      "\tInput words: ['eleven,\"', 'Ron', 'muttered', 'at']\n",
      "Created sample:\n",
      "\tScan time: 1664\n",
      "\tInput words: ['last,', '\"we\\'d', 'better', 'go.\"']\n",
      "Created sample:\n",
      "\tScan time: 1666\n",
      "\tInput words: ['+', 'They', 'pulled', 'on']\n",
      "Created sample:\n",
      "\tScan time: 1668\n",
      "\tInput words: ['their', 'bathrobes,', 'picked', 'up']\n",
      "Created sample:\n",
      "\tScan time: 1670\n",
      "\tInput words: ['their', 'wands,', 'and', 'crept']\n",
      "Created sample:\n",
      "\tScan time: 1672\n",
      "\tInput words: ['across', 'the', 'tower', 'room,']\n",
      "Created sample:\n",
      "\tScan time: 1674\n",
      "\tInput words: ['down', 'the', 'spiral', 'staircase,']\n",
      "Created sample:\n",
      "\tScan time: 1676\n",
      "\tInput words: ['and', 'into', 'the', 'Gryffindor']\n",
      "Created sample:\n",
      "\tScan time: 1678\n",
      "\tInput words: ['common', 'room.', 'A', 'few']\n",
      "Created sample:\n",
      "\tScan time: 1680\n",
      "\tInput words: ['embers', 'were', 'still', 'glowing']\n",
      "Created sample:\n",
      "\tScan time: 1682\n",
      "\tInput words: ['in', 'the', 'fireplace,', 'turning']\n",
      "Created sample:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScan time: 1684\n",
      "\tInput words: ['all', 'the', 'armchairs', 'into']\n",
      "Created sample:\n",
      "\tScan time: 1686\n",
      "\tInput words: ['hunched', 'black', 'shadows.', 'They']\n",
      "Created sample:\n",
      "\tScan time: 1688\n",
      "\tInput words: ['had', 'almost', 'reached', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1690\n",
      "\tInput words: ['portrait', 'hole', 'when', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1692\n",
      "\tInput words: ['voice', 'spoke', 'from', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1694\n",
      "\tInput words: ['chair', 'nearest', 'them,', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 1696\n",
      "\tInput words: [\"can't\", 'believe', \"you're\", 'going']\n",
      "Created sample:\n",
      "\tScan time: 1698\n",
      "\tInput words: ['to', 'do', 'this,', 'Harry.\"']\n",
      "Created sample:\n",
      "\tScan time: 1700\n",
      "\tInput words: ['+', 'A', 'lamp', 'flickered']\n",
      "Created sample:\n",
      "\tScan time: 1702\n",
      "\tInput words: ['on.', 'It', 'was', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1704\n",
      "\tInput words: ['Granger,', 'wearing', 'a', 'pink']\n",
      "Created sample:\n",
      "\tScan time: 1706\n",
      "\tInput words: ['bathrobe', 'and', 'a', 'frown.']\n",
      "Created sample:\n",
      "\tScan time: 1708\n",
      "\tInput words: ['+', '@\"You!\"', 'said', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 1710\n",
      "\tInput words: ['furiously.', '\"Go', 'back', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1712\n",
      "\tInput words: ['bed!\"', '+', '\"I', 'almost']\n",
      "Created sample:\n",
      "\tScan time: 1714\n",
      "\tInput words: ['told', 'your', 'brother,\"', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1716\n",
      "\tInput words: ['snapped,', '\"Percy', '--', \"he's\"]\n",
      "Created sample:\n",
      "\tScan time: 1718\n",
      "\tInput words: ['a', 'prefect,', \"he'd\", 'put']\n",
      "Created sample:\n",
      "\tScan time: 1720\n",
      "\tInput words: ['a', 'stop', 'to', 'this.\"']\n",
      "Created sample:\n",
      "\tScan time: 1722\n",
      "\tInput words: ['+', 'Harry', \"couldn't\", 'believe']\n",
      "Created sample:\n",
      "\tScan time: 1724\n",
      "\tInput words: ['anyone', 'could', 'be', 'so']\n",
      "Created sample:\n",
      "\tScan time: 1726\n",
      "\tInput words: ['interfering.', '+', '\"Come', 'on,\"']\n",
      "Created sample:\n",
      "\tScan time: 1728\n",
      "\tInput words: ['he', 'said', 'to', 'Ron.']\n",
      "Created sample:\n",
      "\tScan time: 1730\n",
      "\tInput words: ['He', 'pushed', 'open', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1732\n",
      "\tInput words: ['portrait', 'of', 'the', 'Fat']\n",
      "Created sample:\n",
      "\tScan time: 1734\n",
      "\tInput words: ['Lady', 'and', 'climbed', 'through']\n",
      "Created sample:\n",
      "\tScan time: 1736\n",
      "\tInput words: ['the', 'hole.', '+', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1738\n",
      "\tInput words: [\"wasn't\", 'going', 'to', 'give']\n",
      "Created sample:\n",
      "\tScan time: 1740\n",
      "\tInput words: ['up', 'that', 'easily.', 'She']\n",
      "Created sample:\n",
      "\tScan time: 1742\n",
      "\tInput words: ['followed', 'Ron', 'through', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1744\n",
      "\tInput words: ['portrait', 'hole,', 'hissing', 'at']\n",
      "Created sample:\n",
      "\tScan time: 1746\n",
      "\tInput words: ['them', 'like', 'an', 'angry']\n",
      "Created sample:\n",
      "\tScan time: 1748\n",
      "\tInput words: ['goose.', '\"Don\\'t', 'you', '@care']\n",
      "Created sample:\n",
      "\tScan time: 1750\n",
      "\tInput words: ['about', 'Gryffindor,', 'do', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1752\n",
      "\tInput words: ['@only', 'care', 'about', 'yourselves,']\n",
      "Created sample:\n",
      "\tScan time: 1754\n",
      "\tInput words: ['I', \"don't\", 'want', 'Slytherin']\n",
      "Created sample:\n",
      "\tScan time: 1756\n",
      "\tInput words: ['to', 'win', 'the', 'House']\n",
      "Created sample:\n",
      "\tScan time: 1758\n",
      "\tInput words: ['Cup,', 'and', \"you'll\", 'lose']\n",
      "Created sample:\n",
      "\tScan time: 1760\n",
      "\tInput words: ['all', 'the', 'points', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1762\n",
      "\tInput words: ['got', 'from', 'Professor', 'McGonagall']\n",
      "Created sample:\n",
      "\tScan time: 1764\n",
      "\tInput words: ['for', 'knowing', 'about', 'Switching']\n",
      "Created sample:\n",
      "\tScan time: 1766\n",
      "\tInput words: ['Spells.\"', '+', '\"Go', 'away.\"']\n",
      "Created sample:\n",
      "\tScan time: 1768\n",
      "\tInput words: ['+', '\"All', 'right,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 1770\n",
      "\tInput words: ['I', 'warned', 'you,', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1772\n",
      "\tInput words: ['just', 'remember', 'what', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1774\n",
      "\tInput words: ['said', 'when', \"you're\", 'on']\n",
      "Created sample:\n",
      "\tScan time: 1776\n",
      "\tInput words: ['the', 'train', 'home', 'tomorrow,']\n",
      "Created sample:\n",
      "\tScan time: 1778\n",
      "\tInput words: [\"you're\", 'so', '—\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1780\n",
      "\tInput words: ['But', 'what', 'they', 'were,']\n",
      "Created sample:\n",
      "\tScan time: 1782\n",
      "\tInput words: ['they', \"didn't\", 'find', 'out.']\n",
      "Created sample:\n",
      "\tScan time: 1784\n",
      "\tInput words: ['Hermione', 'had', 'turned', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1786\n",
      "\tInput words: ['the', 'portrait', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1788\n",
      "\tInput words: ['Fat', 'Lady', 'to', 'get']\n",
      "Created sample:\n",
      "\tScan time: 1790\n",
      "\tInput words: ['back', 'inside', 'and', 'found']\n",
      "Created sample:\n",
      "\tScan time: 1792\n",
      "\tInput words: ['herself', 'facing', 'an', 'empty']\n",
      "Created sample:\n",
      "\tScan time: 1794\n",
      "\tInput words: ['painting.', 'The', 'Fat', 'Lady']\n",
      "Created sample:\n",
      "\tScan time: 1796\n",
      "\tInput words: ['had', 'gone', 'on', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1798\n",
      "\tInput words: ['nighttime', 'visit', 'and', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1800\n",
      "\tInput words: ['was', 'locked', 'out', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1802\n",
      "\tInput words: ['Gryffindor', 'Tower.', '+', '\"Now']\n",
      "Created sample:\n",
      "\tScan time: 1804\n",
      "\tInput words: ['what', 'am', 'I', 'going']\n",
      "Created sample:\n",
      "\tScan time: 1806\n",
      "\tInput words: ['to', 'do?\"', 'she', 'asked']\n",
      "Created sample:\n",
      "\tScan time: 1808\n",
      "\tInput words: ['shrilly.', '+', '\"That\\'s', 'your']\n",
      "Created sample:\n",
      "\tScan time: 1810\n",
      "\tInput words: ['problem,\"', 'said', 'Ron.', '\"We\\'ve']\n",
      "Created sample:\n",
      "\tScan time: 1812\n",
      "\tInput words: ['got', 'to', 'go,', \"we're\"]\n",
      "Created sample:\n",
      "\tScan time: 1814\n",
      "\tInput words: ['going', 'to', 'be', 'late.\"']\n",
      "Created sample:\n",
      "\tScan time: 1816\n",
      "\tInput words: ['+', 'They', \"hadn't\", 'even']\n",
      "Created sample:\n",
      "\tScan time: 1818\n",
      "\tInput words: ['reached', 'the', 'end', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1820\n",
      "\tInput words: ['the', 'corridor', 'when', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1822\n",
      "\tInput words: ['caught', 'up', 'with', 'them.']\n",
      "Created sample:\n",
      "\tScan time: 1824\n",
      "\tInput words: ['+', '\"I\\'m', 'coming', 'with']\n",
      "Created sample:\n",
      "\tScan time: 1826\n",
      "\tInput words: ['you,\"', 'she', 'said.', '\"You']\n",
      "Created sample:\n",
      "\tScan time: 1828\n",
      "\tInput words: ['are', '@not.\"', '+', '\"D\\'you']\n",
      "Created sample:\n",
      "\tScan time: 1830\n",
      "\tInput words: ['think', \"I'm\", 'going', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1832\n",
      "\tInput words: ['stand', 'out', 'here', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1834\n",
      "\tInput words: ['wait', 'for', 'Filch', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1836\n",
      "\tInput words: ['catch', 'me?', 'If', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1838\n",
      "\tInput words: ['finds', 'all', 'three', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1840\n",
      "\tInput words: ['us', \"I'll\", 'tell', 'him']\n",
      "Created sample:\n",
      "\tScan time: 1842\n",
      "\tInput words: ['the', 'truth,', 'that', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1844\n",
      "\tInput words: ['was', 'trying', 'to', 'stop']\n",
      "Created sample:\n",
      "\tScan time: 1846\n",
      "\tInput words: ['you,', 'and', 'you', 'can']\n",
      "Created sample:\n",
      "\tScan time: 1848\n",
      "\tInput words: ['back', 'me', 'up.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1850\n",
      "\tInput words: ['\"You\\'ve', 'got', 'some', 'nerve']\n",
      "Created sample:\n",
      "\tScan time: 1852\n",
      "\tInput words: ['—\"', 'said', 'Ron', 'loudly.']\n",
      "Created sample:\n",
      "\tScan time: 1854\n",
      "\tInput words: ['+', '\"Shut', 'up,', 'both']\n",
      "Created sample:\n",
      "\tScan time: 1856\n",
      "\tInput words: ['of', 'you!\"', 'said', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 1858\n",
      "\tInput words: ['sharply.', '\"I', 'heard', 'something.\"']\n",
      "Created sample:\n",
      "\tScan time: 1860\n",
      "\tInput words: ['+', 'It', 'was', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1862\n",
      "\tInput words: ['sort', 'of', 'snuffling.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1864\n",
      "\tInput words: ['\"Mrs.', 'Norris?\"', 'breathed', 'Ron,']\n",
      "Created sample:\n",
      "\tScan time: 1866\n",
      "\tInput words: ['squinting', 'through', 'the', 'dark.']\n",
      "Created sample:\n",
      "\tScan time: 1868\n",
      "\tInput words: ['+', 'It', \"wasn't\", 'Mrs.']\n",
      "Created sample:\n",
      "\tScan time: 1870\n",
      "\tInput words: ['Norris.', 'It', 'was', 'Neville.']\n",
      "Created sample:\n",
      "\tScan time: 1872\n",
      "\tInput words: ['He', 'was', 'curled', 'up']\n",
      "Created sample:\n",
      "\tScan time: 1874\n",
      "\tInput words: ['on', 'the', 'floor,', 'fast']\n",
      "Created sample:\n",
      "\tScan time: 1876\n",
      "\tInput words: ['asleep,', 'but', 'jerked', 'suddenly']\n",
      "Created sample:\n",
      "\tScan time: 1878\n",
      "\tInput words: ['awake', 'as', 'they', 'crept']\n",
      "Created sample:\n",
      "\tScan time: 1880\n",
      "\tInput words: ['nearer.', '+', '\"Thank', 'goodness']\n",
      "Created sample:\n",
      "\tScan time: 1882\n",
      "\tInput words: ['you', 'found', 'me!', \"I've\"]\n",
      "Created sample:\n",
      "\tScan time: 1884\n",
      "\tInput words: ['been', 'out', 'here', 'for']\n",
      "Created sample:\n",
      "\tScan time: 1886\n",
      "\tInput words: ['hours,', 'I', \"couldn't\", 'remember']\n",
      "Created sample:\n",
      "\tScan time: 1888\n",
      "\tInput words: ['the', 'new', 'password', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1890\n",
      "\tInput words: ['get', 'in', 'to', 'bed.\"']\n",
      "Created sample:\n",
      "\tScan time: 1892\n",
      "\tInput words: ['+', '\"Keep', 'your', 'voice']\n",
      "Created sample:\n",
      "\tScan time: 1894\n",
      "\tInput words: ['down,', 'Neville.', 'The', \"password's\"]\n",
      "Created sample:\n",
      "\tScan time: 1896\n",
      "\tInput words: ['‘Pig', \"snout'\", 'but', 'it']\n",
      "Created sample:\n",
      "\tScan time: 1898\n",
      "\tInput words: [\"won't\", 'help', 'you', 'now,']\n",
      "Created sample:\n",
      "\tScan time: 1900\n",
      "\tInput words: ['the', 'Fat', \"Lady's\", 'gone']\n",
      "Created sample:\n",
      "\tScan time: 1902\n",
      "\tInput words: ['off', 'somewhere.\"', '+', '\"How\\'s']\n",
      "Created sample:\n",
      "\tScan time: 1904\n",
      "\tInput words: ['your', 'arm?\"', 'said', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 1906\n",
      "\tInput words: ['+', '\"Fine,\"', 'said', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 1908\n",
      "\tInput words: ['showing', 'them.', '\"Madam', 'Pomfrey']\n",
      "Created sample:\n",
      "\tScan time: 1910\n",
      "\tInput words: ['mended', 'it', 'in', 'about']\n",
      "Created sample:\n",
      "\tScan time: 1912\n",
      "\tInput words: ['a', 'minute.\"', '+', '\"Good']\n",
      "Created sample:\n",
      "\tScan time: 1914\n",
      "\tInput words: ['--', 'well,', 'look,', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 1916\n",
      "\tInput words: [\"we've\", 'got', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1918\n",
      "\tInput words: ['somewhere,', \"we'll\", 'see', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1920\n",
      "\tInput words: ['later', '—\"', '+', '\"Don\\'t']\n",
      "Created sample:\n",
      "\tScan time: 1922\n",
      "\tInput words: ['leave', 'me!\"', 'said', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 1924\n",
      "\tInput words: ['scrambling', 'to', 'his', 'feet,']\n",
      "Created sample:\n",
      "\tScan time: 1926\n",
      "\tInput words: ['\"I', \"don't\", 'want', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1928\n",
      "\tInput words: ['stay', 'here', 'alone,', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1962\n",
      "\tInput words: ['Ron', 'looked', 'at', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1964\n",
      "\tInput words: ['watch', 'and', 'then', 'glared']\n",
      "Created sample:\n",
      "\tScan time: 1966\n",
      "\tInput words: ['furiously', 'at', 'Hermione', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1968\n",
      "\tInput words: ['Neville.', '+', '\"If', 'either']\n",
      "Created sample:\n",
      "\tScan time: 1970\n",
      "\tInput words: ['of', 'you', 'get', 'us']\n",
      "Created sample:\n",
      "\tScan time: 1972\n",
      "\tInput words: ['caught,', \"I'll\", 'never', 'rest']\n",
      "Created sample:\n",
      "\tScan time: 1974\n",
      "\tInput words: ['until', \"I've\", 'learned', 'that']\n",
      "Created sample:\n",
      "\tScan time: 1976\n",
      "\tInput words: ['Curse', 'of', 'the', 'Bogies']\n",
      "Created sample:\n",
      "\tScan time: 1978\n",
      "\tInput words: ['Quirrell', 'told', 'us', 'about,']\n",
      "Created sample:\n",
      "\tScan time: 1980\n",
      "\tInput words: ['and', 'used', 'it', 'on']\n",
      "Created sample:\n",
      "\tScan time: 1982\n",
      "\tInput words: ['you.\"', '+', 'Hermione', 'opened']\n",
      "Created sample:\n",
      "\tScan time: 1984\n",
      "\tInput words: ['her', 'mouth,', 'perhaps', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1986\n",
      "\tInput words: ['tell', 'Ron', 'exactly', 'how']\n",
      "Created sample:\n",
      "\tScan time: 1988\n",
      "\tInput words: ['to', 'use', 'the', 'Curse']\n",
      "Created sample:\n",
      "\tScan time: 1990\n",
      "\tInput words: ['of', 'the', 'Bogies,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 1992\n",
      "\tInput words: ['Harry', 'hissed', 'at', 'her']\n",
      "Created sample:\n",
      "\tScan time: 1994\n",
      "\tInput words: ['to', 'be', 'quiet', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1996\n",
      "\tInput words: ['beckoned', 'them', 'all', 'forward.']\n",
      "Created sample:\n",
      "\tScan time: 1998\n",
      "\tInput words: ['+', 'They', 'flitted', 'along']\n",
      "Created sample:\n",
      "\tScan time: 2000\n",
      "\tInput words: ['corridors', 'striped', 'with', 'bars']\n",
      "Created sample:\n",
      "\tScan time: 2002\n",
      "\tInput words: ['of', 'moonlight', 'from', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2004\n",
      "\tInput words: ['high', 'windows.', 'At', 'every']\n",
      "Created sample:\n",
      "\tScan time: 2006\n",
      "\tInput words: ['turn', 'Harry', 'expected', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2008\n",
      "\tInput words: ['run', 'into', 'Filch', 'or']\n",
      "Created sample:\n",
      "\tScan time: 2010\n",
      "\tInput words: ['Mrs.', 'Norris,', 'but', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2012\n",
      "\tInput words: ['were', 'lucky.', 'They', 'sped']\n",
      "Created sample:\n",
      "\tScan time: 2014\n",
      "\tInput words: ['up', 'a', 'staircase', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2016\n",
      "\tInput words: ['the', 'third', 'floor', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2018\n",
      "\tInput words: ['tiptoed', 'toward', 'the', 'trophy']\n",
      "Created sample:\n",
      "\tScan time: 2020\n",
      "\tInput words: ['room.', '+', 'Malfoy', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2022\n",
      "\tInput words: ['Crabbe', \"weren't\", 'there', 'yet.']\n",
      "Created sample:\n",
      "\tScan time: 2024\n",
      "\tInput words: ['The', 'crystal', 'trophy', 'cases']\n",
      "Created sample:\n",
      "\tScan time: 2026\n",
      "\tInput words: ['glimmered', 'where', 'the', 'moonlight']\n",
      "Created sample:\n",
      "\tScan time: 2028\n",
      "\tInput words: ['caught', 'them.', 'Cups,', 'shields,']\n",
      "Created sample:\n",
      "\tScan time: 2030\n",
      "\tInput words: ['plates,', 'and', 'statues', 'winked']\n",
      "Created sample:\n",
      "\tScan time: 2032\n",
      "\tInput words: ['silver', 'and', 'gold', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2034\n",
      "\tInput words: ['the', 'darkness.', 'They', 'edged']\n",
      "Created sample:\n",
      "\tScan time: 2036\n",
      "\tInput words: ['along', 'the', 'walls,', 'keeping']\n",
      "Created sample:\n",
      "\tScan time: 2038\n",
      "\tInput words: ['their', 'eyes', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2040\n",
      "\tInput words: ['doors', 'at', 'either', 'end']\n",
      "Created sample:\n",
      "\tScan time: 2042\n",
      "\tInput words: ['of', 'the', 'room.', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2044\n",
      "\tInput words: ['took', 'out', 'his', 'wand']\n",
      "Created sample:\n",
      "\tScan time: 2046\n",
      "\tInput words: ['in', 'case', 'Malfoy', 'leapt']\n",
      "Created sample:\n",
      "\tScan time: 2048\n",
      "\tInput words: ['in', 'and', 'started', 'at']\n",
      "Created sample:\n",
      "\tScan time: 2050\n",
      "\tInput words: ['once.', 'The', 'minutes', 'crept']\n",
      "Created sample:\n",
      "\tScan time: 2052\n",
      "\tInput words: ['by.', '+', '\"He\\'s', 'late,']\n",
      "Created sample:\n",
      "\tScan time: 2054\n",
      "\tInput words: ['maybe', \"he's\", 'chickened', 'out,\"']\n",
      "Created sample:\n",
      "\tScan time: 2056\n",
      "\tInput words: ['Ron', 'whispered.', '+', 'Then']\n",
      "Created sample:\n",
      "\tScan time: 2058\n",
      "\tInput words: ['a', 'noise', 'in', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2060\n",
      "\tInput words: ['next', 'room', 'made', 'them']\n",
      "Created sample:\n",
      "\tScan time: 2062\n",
      "\tInput words: ['jump.', 'Harry', 'had', 'only']\n",
      "Created sample:\n",
      "\tScan time: 2064\n",
      "\tInput words: ['just', 'raised', 'his', 'wand']\n",
      "Created sample:\n",
      "\tScan time: 2066\n",
      "\tInput words: ['when', 'they', 'heard', 'someone']\n",
      "Created sample:\n",
      "\tScan time: 2068\n",
      "\tInput words: ['speak', '--', 'and', 'it']\n",
      "Created sample:\n",
      "\tScan time: 2070\n",
      "\tInput words: [\"wasn't\", 'Malfoy.', '+', '\"Sniff']\n",
      "Created sample:\n",
      "\tScan time: 2072\n",
      "\tInput words: ['around,', 'my', 'sweet,', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2074\n",
      "\tInput words: ['might', 'be', 'lurking', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2076\n",
      "\tInput words: ['a', 'corner.\"', '+', 'It']\n",
      "Created sample:\n",
      "\tScan time: 2078\n",
      "\tInput words: ['was', 'Filch', 'speaking', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2080\n",
      "\tInput words: ['Mrs.', 'Norris.', 'Horror-struck,', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2082\n",
      "\tInput words: ['waved', 'madly', 'at', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2084\n",
      "\tInput words: ['other', 'three', 'to', 'follow']\n",
      "Created sample:\n",
      "\tScan time: 2086\n",
      "\tInput words: ['him', 'as', 'quickly', 'as']\n",
      "Created sample:\n",
      "\tScan time: 2088\n",
      "\tInput words: ['possible;', 'they', 'scurried', 'silently']\n",
      "Created sample:\n",
      "\tScan time: 2090\n",
      "\tInput words: ['toward', 'the', 'door,', 'away']\n",
      "Created sample:\n",
      "\tScan time: 2092\n",
      "\tInput words: ['from', \"Filch's\", 'voice.', \"Neville's\"]\n",
      "Created sample:\n",
      "\tScan time: 2094\n",
      "\tInput words: ['robes', 'had', 'barely', 'whipped']\n",
      "Created sample:\n",
      "\tScan time: 2096\n",
      "\tInput words: ['round', 'the', 'corner', 'when']\n",
      "Created sample:\n",
      "\tScan time: 2098\n",
      "\tInput words: ['they', 'heard', 'Filch', 'enter']\n",
      "Created sample:\n",
      "\tScan time: 2100\n",
      "\tInput words: ['the', 'trophy', 'room.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2102\n",
      "\tInput words: ['\"They\\'re', 'in', 'here', 'somewhere,\"']\n",
      "Created sample:\n",
      "\tScan time: 2104\n",
      "\tInput words: ['they', 'heard', 'him', 'mutter,']\n",
      "Created sample:\n",
      "\tScan time: 2106\n",
      "\tInput words: ['\"probably', 'hiding.\"', '+', '\"This']\n",
      "Created sample:\n",
      "\tScan time: 2108\n",
      "\tInput words: ['way!\"', 'Harry', 'mouthed', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2110\n",
      "\tInput words: ['the', 'others', 'and,', 'petrified,']\n",
      "Created sample:\n",
      "\tScan time: 2112\n",
      "\tInput words: ['they', 'began', 'to', 'creep']\n",
      "Created sample:\n",
      "\tScan time: 2114\n",
      "\tInput words: ['down', 'a', 'long', 'gallery']\n",
      "Created sample:\n",
      "\tScan time: 2116\n",
      "\tInput words: ['full', 'of', 'suits', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2118\n",
      "\tInput words: ['armor.', '+', 'They', 'could']\n",
      "Created sample:\n",
      "\tScan time: 2120\n",
      "\tInput words: ['hear', 'Filch', 'getting', 'nearer.']\n",
      "Created sample:\n",
      "\tScan time: 2122\n",
      "\tInput words: ['Neville', 'suddenly', 'let', 'out']\n",
      "Created sample:\n",
      "\tScan time: 2124\n",
      "\tInput words: ['a', 'frightened', 'squeak', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2126\n",
      "\tInput words: ['broke', 'into', 'a', 'run']\n",
      "Created sample:\n",
      "\tScan time: 2128\n",
      "\tInput words: ['--', 'he', 'tripped,', 'grabbed']\n",
      "Created sample:\n",
      "\tScan time: 2130\n",
      "\tInput words: ['Ron', 'around', 'the', 'waist,']\n",
      "Created sample:\n",
      "\tScan time: 2132\n",
      "\tInput words: ['and', 'the', 'pair', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2134\n",
      "\tInput words: ['them', 'toppled', 'right', 'into']\n",
      "Created sample:\n",
      "\tScan time: 2136\n",
      "\tInput words: ['a', 'suit', 'of', 'armor.']\n",
      "Created sample:\n",
      "\tScan time: 2138\n",
      "\tInput words: ['+', 'The', 'clanging', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2140\n",
      "\tInput words: ['crashing', 'were', 'enough', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2142\n",
      "\tInput words: ['wake', 'the', 'whole', 'castle.']\n",
      "Created sample:\n",
      "\tScan time: 2144\n",
      "\tInput words: ['+', '\"RUN!\"', 'Harry', 'yelled,']\n",
      "Created sample:\n",
      "\tScan time: 2146\n",
      "\tInput words: ['and', 'the', 'four', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2148\n",
      "\tInput words: ['them', 'sprinted', 'down', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2150\n",
      "\tInput words: ['gallery,', 'not', 'looking', 'back']\n",
      "Created sample:\n",
      "\tScan time: 2152\n",
      "\tInput words: ['to', 'see', 'whether', 'Filch']\n",
      "Created sample:\n",
      "\tScan time: 2154\n",
      "\tInput words: ['was', 'following', '--', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2156\n",
      "\tInput words: ['swung', 'around', 'the', 'doorpost']\n",
      "Created sample:\n",
      "\tScan time: 2158\n",
      "\tInput words: ['and', 'galloped', 'down', 'one']\n",
      "Created sample:\n",
      "\tScan time: 2160\n",
      "\tInput words: ['corridor', 'then', 'another,', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2162\n",
      "\tInput words: ['in', 'the', 'lead,', 'without']\n",
      "Created sample:\n",
      "\tScan time: 2164\n",
      "\tInput words: ['any', 'idea', 'where', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2166\n",
      "\tInput words: ['were', 'or', 'where', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2168\n",
      "\tInput words: ['were', 'going', '--', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2170\n",
      "\tInput words: ['ripped', 'through', 'a', 'tapestry']\n",
      "Created sample:\n",
      "\tScan time: 2172\n",
      "\tInput words: ['and', 'found', 'themselves', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2174\n",
      "\tInput words: ['a', 'hidden', 'passageway,', 'hurtled']\n",
      "Created sample:\n",
      "\tScan time: 2176\n",
      "\tInput words: ['along', 'it', 'and', 'came']\n",
      "Created sample:\n",
      "\tScan time: 2178\n",
      "\tInput words: ['out', 'near', 'their', 'Charms']\n",
      "Created sample:\n",
      "\tScan time: 2180\n",
      "\tInput words: ['classroom,', 'which', 'they', 'knew']\n",
      "Created sample:\n",
      "\tScan time: 2182\n",
      "\tInput words: ['was', 'miles', 'from', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2184\n",
      "\tInput words: ['trophy', 'room.', '+', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 2186\n",
      "\tInput words: ['think', \"we've\", 'lost', 'him,\"']\n",
      "Created sample:\n",
      "\tScan time: 2188\n",
      "\tInput words: ['Harry', 'panted,', 'leaning', 'against']\n",
      "Created sample:\n",
      "\tScan time: 2190\n",
      "\tInput words: ['the', 'cold', 'wall', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2192\n",
      "\tInput words: ['wiping', 'his', 'forehead.', 'Neville']\n",
      "Created sample:\n",
      "\tScan time: 2194\n",
      "\tInput words: ['was', 'bent', 'double,', 'wheezing']\n",
      "Created sample:\n",
      "\tScan time: 2196\n",
      "\tInput words: ['and', 'spluttering.', '+', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 2198\n",
      "\tInput words: ['--', '@told', '--', 'you,\"']\n",
      "Created sample:\n",
      "\tScan time: 2200\n",
      "\tInput words: ['Hermione', 'gasped,', 'clutching', 'at']\n",
      "Created sample:\n",
      "\tScan time: 2202\n",
      "\tInput words: ['the', 'stitch', 'in', 'her']\n",
      "Created sample:\n",
      "\tScan time: 2204\n",
      "\tInput words: ['chest,', '\"I', '--', 'told']\n",
      "Created sample:\n",
      "\tScan time: 2206\n",
      "\tInput words: ['--', 'you.\"', '+', '\"We\\'ve']\n",
      "Created sample:\n",
      "\tScan time: 2208\n",
      "\tInput words: ['got', 'to', 'get', 'back']\n",
      "Created sample:\n",
      "\tScan time: 2210\n",
      "\tInput words: ['to', 'Gryffindor', 'Tower,\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 2212\n",
      "\tInput words: ['Ron,', '\"quickly', 'as', 'possible.\"']\n",
      "Created sample:\n",
      "\tScan time: 2214\n",
      "\tInput words: ['+', '\"Malfoy', 'tricked', 'you,\"']\n",
      "Created sample:\n",
      "\tScan time: 2216\n",
      "\tInput words: ['Hermione', 'said', 'to', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 2218\n",
      "\tInput words: ['\"You', 'realize', 'that,', \"don't\"]\n",
      "Created sample:\n",
      "\tScan time: 2220\n",
      "\tInput words: ['you?', 'He', 'was', 'never']\n",
      "Created sample:\n",
      "\tScan time: 2222\n",
      "\tInput words: ['going', 'to', 'meet', 'you']\n",
      "Created sample:\n",
      "\tScan time: 2224\n",
      "\tInput words: ['--', 'Filch', 'knew', 'someone']\n",
      "Created sample:\n",
      "\tScan time: 2226\n",
      "\tInput words: ['was', 'going', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 2228\n",
      "\tInput words: ['in', 'the', 'trophy', 'room,']\n",
      "Created sample:\n",
      "\tScan time: 2230\n",
      "\tInput words: ['Malfoy', 'must', 'have', 'tipped']\n",
      "Created sample:\n",
      "\tScan time: 2232\n",
      "\tInput words: ['him', 'off.\"', '+', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2234\n",
      "\tInput words: ['thought', 'she', 'was', 'probably']\n",
      "Created sample:\n",
      "\tScan time: 2236\n",
      "\tInput words: ['right,', 'but', 'he', \"wasn't\"]\n",
      "Created sample:\n",
      "\tScan time: 2238\n",
      "\tInput words: ['going', 'to', 'tell', 'her']\n",
      "Created sample:\n",
      "\tScan time: 2240\n",
      "\tInput words: ['that.', '+', '\"Let\\'s', 'go.\"']\n",
      "Created sample:\n",
      "\tScan time: 2242\n",
      "\tInput words: ['+', 'It', \"wasn't\", 'going']\n",
      "Created sample:\n",
      "\tScan time: 2244\n",
      "\tInput words: ['to', 'be', 'that', 'simple.']\n",
      "Created sample:\n",
      "\tScan time: 2246\n",
      "\tInput words: ['They', \"hadn't\", 'gone', 'more']\n",
      "Created sample:\n",
      "\tScan time: 2248\n",
      "\tInput words: ['than', 'a', 'dozen', 'paces']\n",
      "Created sample:\n",
      "\tScan time: 2250\n",
      "\tInput words: ['when', 'a', 'doorknob', 'rattled']\n",
      "Created sample:\n",
      "\tScan time: 2252\n",
      "\tInput words: ['and', 'something', 'came', 'shooting']\n",
      "Created sample:\n",
      "\tScan time: 2254\n",
      "\tInput words: ['out', 'of', 'a', 'classroom']\n",
      "Created sample:\n",
      "\tScan time: 2256\n",
      "\tInput words: ['in', 'front', 'of', 'them.']\n",
      "Created sample:\n",
      "\tScan time: 2258\n",
      "\tInput words: ['+', 'It', 'was', 'Peeves.']\n",
      "Created sample:\n",
      "\tScan time: 2260\n",
      "\tInput words: ['He', 'caught', 'sight', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2262\n",
      "\tInput words: ['them', 'and', 'gave', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2264\n",
      "\tInput words: ['squeal', 'of', 'delight.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2266\n",
      "\tInput words: ['\"Shut', 'up,', 'Peeves', '--']\n",
      "Created sample:\n",
      "\tScan time: 2268\n",
      "\tInput words: ['please', '--', \"you'll\", 'get']\n",
      "Created sample:\n",
      "\tScan time: 2270\n",
      "\tInput words: ['us', 'thrown', 'out.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2272\n",
      "\tInput words: ['Peeves', 'cackled.', '+', '\"Wandering']\n",
      "Created sample:\n",
      "\tScan time: 2274\n",
      "\tInput words: ['around', 'at', 'midnight,', 'Ickle']\n",
      "Created sample:\n",
      "\tScan time: 2276\n",
      "\tInput words: ['Firsties?', 'Tut,', 'tut,', 'tut.']\n",
      "Created sample:\n",
      "\tScan time: 2278\n",
      "\tInput words: ['Naughty,', 'naughty,', \"you'll\", 'get']\n",
      "Created sample:\n",
      "\tScan time: 2280\n",
      "\tInput words: ['caughty.\"', '+', '\"Not', 'if']\n",
      "Created sample:\n",
      "\tScan time: 2282\n",
      "\tInput words: ['you', \"don't\", 'give', 'us']\n",
      "Created sample:\n",
      "\tScan time: 2284\n",
      "\tInput words: ['away,', 'Peeves,', 'please.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2286\n",
      "\tInput words: ['\"Should', 'tell', 'Filch,', 'I']\n",
      "Created sample:\n",
      "\tScan time: 2288\n",
      "\tInput words: ['should,\"', 'said', 'Peeves', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2290\n",
      "\tInput words: ['a', 'saintly', 'voice,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 2292\n",
      "\tInput words: ['his', 'eyes', 'glittered', 'wickedly.']\n",
      "Created sample:\n",
      "\tScan time: 2294\n",
      "\tInput words: ['\"It\\'s', 'for', 'your', 'own']\n",
      "Created sample:\n",
      "\tScan time: 2296\n",
      "\tInput words: ['good,', 'you', 'know.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2298\n",
      "\tInput words: ['\"Get', 'out', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2300\n",
      "\tInput words: ['way,\"', 'snapped', 'Ron,', 'taking']\n",
      "Created sample:\n",
      "\tScan time: 2302\n",
      "\tInput words: ['a', 'swipe', 'at', 'Peeves']\n",
      "Created sample:\n",
      "\tScan time: 2304\n",
      "\tInput words: ['--', 'this', 'was', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2306\n",
      "\tInput words: ['big', 'mistake.', '+', '\"STUDENTS']\n",
      "Created sample:\n",
      "\tScan time: 2308\n",
      "\tInput words: ['OUT', 'OF', 'BED!\"', 'Peeves']\n",
      "Created sample:\n",
      "\tScan time: 2310\n",
      "\tInput words: ['bellowed,', '\"STUDENTS', 'OUT', 'OF']\n",
      "Created sample:\n",
      "\tScan time: 2312\n",
      "\tInput words: ['BED', 'DOWN', 'THE', 'CHARMS']\n",
      "Created sample:\n",
      "\tScan time: 2314\n",
      "\tInput words: ['CORRIDOR!\"', '+', 'Ducking', 'under']\n",
      "Created sample:\n",
      "\tScan time: 2316\n",
      "\tInput words: ['Peeves,', 'they', 'ran', 'for']\n",
      "Created sample:\n",
      "\tScan time: 2318\n",
      "\tInput words: ['their', 'lives,', 'right', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2320\n",
      "\tInput words: ['the', 'end', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2322\n",
      "\tInput words: ['corridor', 'where', 'they', 'slammed']\n",
      "Created sample:\n",
      "\tScan time: 2324\n",
      "\tInput words: ['into', 'a', 'door', '--']\n",
      "Created sample:\n",
      "\tScan time: 2326\n",
      "\tInput words: ['and', 'it', 'was', 'locked.']\n",
      "Created sample:\n",
      "\tScan time: 2328\n",
      "\tInput words: ['+', '\"This', 'is', 'it!\"']\n",
      "Created sample:\n",
      "\tScan time: 2330\n",
      "\tInput words: ['Ron', 'moaned,', 'as', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2332\n",
      "\tInput words: ['pushed', 'helplessly', 'at', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2334\n",
      "\tInput words: ['door,', '\"We\\'re', 'done', 'for!']\n",
      "Created sample:\n",
      "\tScan time: 2336\n",
      "\tInput words: ['This', 'is', 'the', 'end!\"']\n",
      "Created sample:\n",
      "\tScan time: 2338\n",
      "\tInput words: ['+', 'They', 'could', 'hear']\n",
      "Created sample:\n",
      "\tScan time: 2340\n",
      "\tInput words: ['footsteps,', 'Filch', 'running', 'as']\n",
      "Created sample:\n",
      "\tScan time: 2342\n",
      "\tInput words: ['fast', 'as', 'he', 'could']\n",
      "Created sample:\n",
      "\tScan time: 2344\n",
      "\tInput words: ['toward', \"Peeves's\", 'shouts.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2346\n",
      "\tInput words: ['\"Oh,', 'move', 'over,\"', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 2348\n",
      "\tInput words: ['snarled.', 'She', 'grabbed', \"Harry's\"]\n",
      "Created sample:\n",
      "\tScan time: 2350\n",
      "\tInput words: ['wand,', 'tapped', 'the', 'lock,']\n",
      "Created sample:\n",
      "\tScan time: 2352\n",
      "\tInput words: ['and', 'whispered,', '@\"Alohomora!\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2354\n",
      "\tInput words: ['The', 'lock', 'clicked', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2356\n",
      "\tInput words: ['the', 'door', 'swung', 'open']\n",
      "Created sample:\n",
      "\tScan time: 2358\n",
      "\tInput words: ['--', 'they', 'piled', 'through']\n",
      "Created sample:\n",
      "\tScan time: 2360\n",
      "\tInput words: ['it,', 'shut', 'it', 'quickly,']\n",
      "Created sample:\n",
      "\tScan time: 2362\n",
      "\tInput words: ['and', 'pressed', 'their', 'ears']\n",
      "Created sample:\n",
      "\tScan time: 2364\n",
      "\tInput words: ['against', 'it,', 'listening.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2366\n",
      "\tInput words: ['\"Which', 'way', 'did', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2368\n",
      "\tInput words: ['go,', 'Peeves?\"', 'Filch', 'was']\n",
      "Created sample:\n",
      "\tScan time: 2370\n",
      "\tInput words: ['saying.', '\"Quick,', 'tell', 'me.\"']\n",
      "Created sample:\n",
      "\tScan time: 2372\n",
      "\tInput words: ['\"Say', '‘please.\\'\"', '+', '\"Don\\'t']\n",
      "Created sample:\n",
      "\tScan time: 2374\n",
      "\tInput words: ['mess', 'with', 'me,', 'Peeves,']\n",
      "Created sample:\n",
      "\tScan time: 2376\n",
      "\tInput words: ['now', '@where', '@did', '@they']\n",
      "Created sample:\n",
      "\tScan time: 2378\n",
      "\tInput words: ['@go?\"', '\"Shan\\'t', 'say', 'nothing']\n",
      "Created sample:\n",
      "\tScan time: 2380\n",
      "\tInput words: ['if', 'you', \"don't\", 'say']\n",
      "Created sample:\n",
      "\tScan time: 2382\n",
      "\tInput words: ['please,\"', 'said', 'Peeves', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2384\n",
      "\tInput words: ['his', 'annoying', 'singsong', 'voice.']\n",
      "Created sample:\n",
      "\tScan time: 2386\n",
      "\tInput words: ['\"All', 'right', '--', '@please.\"']\n",
      "Created sample:\n",
      "\tScan time: 2388\n",
      "\tInput words: ['+', '\"NOTHING!', 'Ha', 'haaa!']\n",
      "Created sample:\n",
      "\tScan time: 2390\n",
      "\tInput words: ['Told', 'you', 'I', \"wouldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 2392\n",
      "\tInput words: ['say', 'nothing', 'if', 'you']\n",
      "Created sample:\n",
      "\tScan time: 2394\n",
      "\tInput words: [\"didn't\", 'say', 'please!', 'Ha']\n",
      "Created sample:\n",
      "\tScan time: 2396\n",
      "\tInput words: ['ha!', 'Haaaaaa!\"', 'And', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2398\n",
      "\tInput words: ['heard', 'the', 'sound', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2400\n",
      "\tInput words: ['Peeves', 'whooshing', 'away', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2402\n",
      "\tInput words: ['Filch', 'cursing', 'in', 'rage.']\n",
      "Created sample:\n",
      "\tScan time: 2404\n",
      "\tInput words: ['+', '\"He', 'thinks', 'this']\n",
      "Created sample:\n",
      "\tScan time: 2406\n",
      "\tInput words: ['door', 'is', 'locked,\"', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2408\n",
      "\tInput words: ['whispered.', '\"I', 'think', \"we'll\"]\n",
      "Created sample:\n",
      "\tScan time: 2410\n",
      "\tInput words: ['be', 'okay', '--', 'get']\n",
      "Created sample:\n",
      "\tScan time: 2412\n",
      "\tInput words: ['@off,', 'Neville!\"', 'For', 'Neville']\n",
      "Created sample:\n",
      "\tScan time: 2414\n",
      "\tInput words: ['had', 'been', 'tugging', 'on']\n",
      "Created sample:\n",
      "\tScan time: 2416\n",
      "\tInput words: ['the', 'sleeve', 'of', \"Harry's\"]\n",
      "Created sample:\n",
      "\tScan time: 2418\n",
      "\tInput words: ['bathrobe', 'for', 'the', 'last']\n",
      "Created sample:\n",
      "\tScan time: 2420\n",
      "\tInput words: ['minute.', '@\"What?\"', '+', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2422\n",
      "\tInput words: ['turned', 'around', '--', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2424\n",
      "\tInput words: ['saw,', 'quite', 'clearly,', 'what.']\n",
      "Created sample:\n",
      "\tScan time: 2426\n",
      "\tInput words: ['For', 'a', 'moment,', 'he']\n",
      "Created sample:\n",
      "\tScan time: 2428\n",
      "\tInput words: ['was', 'sure', \"he'd\", 'walked']\n",
      "Created sample:\n",
      "\tScan time: 2430\n",
      "\tInput words: ['into', 'a', 'nightmare', '--']\n",
      "Created sample:\n",
      "\tScan time: 2432\n",
      "\tInput words: ['this', 'was', 'too', 'much,']\n",
      "Created sample:\n",
      "\tScan time: 2434\n",
      "\tInput words: ['on', 'top', 'of', 'everything']\n",
      "Created sample:\n",
      "\tScan time: 2436\n",
      "\tInput words: ['that', 'had', 'happened', 'so']\n",
      "Created sample:\n",
      "\tScan time: 2438\n",
      "\tInput words: ['far.', '+', 'They', \"weren't\"]\n",
      "Created sample:\n",
      "\tScan time: 2440\n",
      "\tInput words: ['in', 'a', 'room,', 'as']\n",
      "Created sample:\n",
      "\tScan time: 2442\n",
      "\tInput words: ['he', 'had', 'supposed.', 'They']\n",
      "Created sample:\n",
      "\tScan time: 2444\n",
      "\tInput words: ['were', 'in', 'a', 'corridor.']\n",
      "Created sample:\n",
      "\tScan time: 2446\n",
      "\tInput words: ['The', 'forbidden', 'corridor', 'on']\n",
      "Created sample:\n",
      "\tScan time: 2448\n",
      "\tInput words: ['the', 'third', 'floor.', 'And']\n",
      "Created sample:\n",
      "\tScan time: 2450\n",
      "\tInput words: ['now', 'they', 'knew', 'why']\n",
      "Created sample:\n",
      "\tScan time: 2452\n",
      "\tInput words: ['it', 'was', 'forbidden.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2454\n",
      "\tInput words: ['They', 'were', 'looking', 'straight']\n",
      "Created sample:\n",
      "\tScan time: 2456\n",
      "\tInput words: ['into', 'the', 'eyes', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2458\n",
      "\tInput words: ['a', 'monstrous', 'dog,', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2460\n",
      "\tInput words: ['dog', 'that', 'filled', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2462\n",
      "\tInput words: ['whole', 'space', 'between', 'ceiling']\n",
      "Created sample:\n",
      "\tScan time: 2464\n",
      "\tInput words: ['and', 'floor.', 'It', 'had']\n",
      "Created sample:\n",
      "\tScan time: 2466\n",
      "\tInput words: ['three', 'heads.', 'Three', 'pairs']\n",
      "Created sample:\n",
      "\tScan time: 2468\n",
      "\tInput words: ['of', 'rolling,', 'mad', 'eyes;']\n",
      "Created sample:\n",
      "\tScan time: 2470\n",
      "\tInput words: ['three', 'noses,', 'twitching', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2472\n",
      "\tInput words: ['quivering', 'in', 'their', 'direction;']\n",
      "Created sample:\n",
      "\tScan time: 2474\n",
      "\tInput words: ['three', 'drooling', 'mouths,', 'saliva']\n",
      "Created sample:\n",
      "\tScan time: 2476\n",
      "\tInput words: ['hanging', 'in', 'slippery', 'ropes']\n",
      "Created sample:\n",
      "\tScan time: 2478\n",
      "\tInput words: ['from', 'yellowish', 'fangs.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2480\n",
      "\tInput words: ['It', 'was', 'standing', 'quite']\n",
      "Created sample:\n",
      "\tScan time: 2482\n",
      "\tInput words: ['still,', 'all', 'six', 'eyes']\n",
      "Created sample:\n",
      "\tScan time: 2484\n",
      "\tInput words: ['staring', 'at', 'them,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2486\n",
      "\tInput words: ['Harry', 'knew', 'that', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2488\n",
      "\tInput words: ['only', 'reason', 'they', \"weren't\"]\n",
      "Created sample:\n",
      "\tScan time: 2490\n",
      "\tInput words: ['already', 'dead', 'was', 'that']\n",
      "Created sample:\n",
      "\tScan time: 2492\n",
      "\tInput words: ['their', 'sudden', 'appearance', 'had']\n",
      "Created sample:\n",
      "\tScan time: 2494\n",
      "\tInput words: ['taken', 'it', 'by', 'surprise,']\n",
      "Created sample:\n",
      "\tScan time: 2496\n",
      "\tInput words: ['but', 'it', 'was', 'quickly']\n",
      "Created sample:\n",
      "\tScan time: 2498\n",
      "\tInput words: ['getting', 'over', 'that,', 'there']\n",
      "Created sample:\n",
      "\tScan time: 2500\n",
      "\tInput words: ['was', 'no', 'mistaking', 'what']\n",
      "Created sample:\n",
      "\tScan time: 2502\n",
      "\tInput words: ['those', 'thunderous', 'growls', 'meant.']\n",
      "Created sample:\n",
      "\tScan time: 2504\n",
      "\tInput words: ['+', 'Harry', 'groped', 'for']\n",
      "Created sample:\n",
      "\tScan time: 2506\n",
      "\tInput words: ['the', 'doorknob', '--', 'between']\n",
      "Created sample:\n",
      "\tScan time: 2508\n",
      "\tInput words: ['Filch', 'and', 'death,', \"he'd\"]\n",
      "Created sample:\n",
      "\tScan time: 2510\n",
      "\tInput words: ['take', 'Filch.', '+', 'They']\n",
      "Created sample:\n",
      "\tScan time: 2512\n",
      "\tInput words: ['fell', 'backward', '--', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2514\n",
      "\tInput words: ['slammed', 'the', 'door', 'shut,']\n",
      "Created sample:\n",
      "\tScan time: 2516\n",
      "\tInput words: ['and', 'they', 'ran,', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2518\n",
      "\tInput words: ['almost', 'flew,', 'back', 'down']\n",
      "Created sample:\n",
      "\tScan time: 2520\n",
      "\tInput words: ['the', 'corridor.', 'Filch', 'must']\n",
      "Created sample:\n",
      "\tScan time: 2522\n",
      "\tInput words: ['have', 'hurried', 'off', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2524\n",
      "\tInput words: ['look', 'for', 'them', 'somewhere']\n",
      "Created sample:\n",
      "\tScan time: 2526\n",
      "\tInput words: ['else,', 'because', 'they', \"didn't\"]\n",
      "Created sample:\n",
      "\tScan time: 2528\n",
      "\tInput words: ['see', 'him', 'anywhere,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 2530\n",
      "\tInput words: ['they', 'hardly', 'cared', '--']\n",
      "Created sample:\n",
      "\tScan time: 2532\n",
      "\tInput words: ['all', 'they', 'wanted', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2534\n",
      "\tInput words: ['do', 'was', 'put', 'as']\n",
      "Created sample:\n",
      "\tScan time: 2536\n",
      "\tInput words: ['much', 'space', 'as', 'possible']\n",
      "Created sample:\n",
      "\tScan time: 2538\n",
      "\tInput words: ['between', 'them', 'and', 'that']\n",
      "Created sample:\n",
      "\tScan time: 2540\n",
      "\tInput words: ['monster.', 'They', \"didn't\", 'stop']\n",
      "Created sample:\n",
      "\tScan time: 2542\n",
      "\tInput words: ['running', 'until', 'they', 'reached']\n",
      "Created sample:\n",
      "\tScan time: 2544\n",
      "\tInput words: ['the', 'portrait', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2546\n",
      "\tInput words: ['Fat', 'Lady', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2548\n",
      "\tInput words: ['seventh', 'floor.', '+', '\"Where']\n",
      "Created sample:\n",
      "\tScan time: 2550\n",
      "\tInput words: ['on', 'earth', 'have', 'you']\n",
      "Created sample:\n",
      "\tScan time: 2552\n",
      "\tInput words: ['all', 'been?\"', 'she', 'asked,']\n",
      "Created sample:\n",
      "\tScan time: 2554\n",
      "\tInput words: ['looking', 'at', 'their', 'bathrobes']\n",
      "Created sample:\n",
      "\tScan time: 2556\n",
      "\tInput words: ['hanging', 'off', 'their', 'shoulders']\n",
      "Created sample:\n",
      "\tScan time: 2558\n",
      "\tInput words: ['and', 'their', 'flushed,', 'sweaty']\n",
      "Created sample:\n",
      "\tScan time: 2560\n",
      "\tInput words: ['faces.', '+', '\"Never', 'mind']\n",
      "Created sample:\n",
      "\tScan time: 2562\n",
      "\tInput words: ['that', '--', 'pig', 'snout,']\n",
      "Created sample:\n",
      "\tScan time: 2564\n",
      "\tInput words: ['pig', 'snout,\"', 'panted', 'Harry,']\n",
      "Created sample:\n",
      "\tScan time: 2566\n",
      "\tInput words: ['and', 'the', 'portrait', 'swung']\n",
      "Created sample:\n",
      "\tScan time: 2568\n",
      "\tInput words: ['forward.', 'They', 'scrambled', 'into']\n",
      "Created sample:\n",
      "\tScan time: 2570\n",
      "\tInput words: ['the', 'common', 'room', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2572\n",
      "\tInput words: ['collapsed,', 'trembling,', 'into', 'armchairs.']\n",
      "Created sample:\n",
      "\tScan time: 2574\n",
      "\tInput words: ['+', 'It', 'was', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2576\n",
      "\tInput words: ['while', 'before', 'any', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2578\n",
      "\tInput words: ['them', 'said', 'anything.', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 2580\n",
      "\tInput words: ['indeed,', 'looked', 'as', 'if']\n",
      "Created sample:\n",
      "\tScan time: 2582\n",
      "\tInput words: [\"he'd\", 'never', 'speak', 'again.']\n",
      "Created sample:\n",
      "\tScan time: 2584\n",
      "\tInput words: ['+', '\"What', 'do', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2586\n",
      "\tInput words: ['think', \"they're\", 'doing,', 'keeping']\n",
      "Created sample:\n",
      "\tScan time: 2588\n",
      "\tInput words: ['a', 'thing', 'like', 'that']\n",
      "Created sample:\n",
      "\tScan time: 2590\n",
      "\tInput words: ['locked', 'up', 'in', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2592\n",
      "\tInput words: ['school?\"', 'said', 'Ron', 'finally.']\n",
      "Created sample:\n",
      "\tScan time: 2594\n",
      "\tInput words: ['\"If', 'any', 'dog', 'needs']\n",
      "Created sample:\n",
      "\tScan time: 2596\n",
      "\tInput words: ['exercise,', 'that', 'one', 'does.\"']\n",
      "Created sample:\n",
      "\tScan time: 2598\n",
      "\tInput words: ['+', 'Hermione', 'had', 'got']\n",
      "Created sample:\n",
      "\tScan time: 2600\n",
      "\tInput words: ['both', 'her', 'breath', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2602\n",
      "\tInput words: ['her', 'bad', 'temper', 'back']\n",
      "Created sample:\n",
      "\tScan time: 2604\n",
      "\tInput words: ['again.', '+', '\"You', \"don't\"]\n",
      "Created sample:\n",
      "\tScan time: 2606\n",
      "\tInput words: ['use', 'your', 'eyes,', 'any']\n",
      "Created sample:\n",
      "\tScan time: 2608\n",
      "\tInput words: ['of', 'you,', 'do', 'you?\"']\n",
      "Created sample:\n",
      "\tScan time: 2610\n",
      "\tInput words: ['she', 'snapped.', '\"Didn\\'t', 'you']\n",
      "Created sample:\n",
      "\tScan time: 2612\n",
      "\tInput words: ['see', 'what', 'it', 'was']\n",
      "Created sample:\n",
      "\tScan time: 2614\n",
      "\tInput words: ['standing', 'on?\"', '+', '\"The']\n",
      "Created sample:\n",
      "\tScan time: 2616\n",
      "\tInput words: ['floor?\"', 'Harry', 'suggested.', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 2618\n",
      "\tInput words: [\"wasn't\", 'looking', 'at', 'its']\n",
      "Created sample:\n",
      "\tScan time: 2620\n",
      "\tInput words: ['feet,', 'I', 'was', 'too']\n",
      "Created sample:\n",
      "\tScan time: 2622\n",
      "\tInput words: ['busy', 'with', 'its', 'heads.\"']\n",
      "Created sample:\n",
      "\tScan time: 2624\n",
      "\tInput words: ['+', '\"No,', '@not', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2626\n",
      "\tInput words: ['floor.', 'It', 'was', 'standing']\n",
      "Created sample:\n",
      "\tScan time: 2628\n",
      "\tInput words: ['on', 'a', 'trapdoor.', \"It's\"]\n",
      "Created sample:\n",
      "\tScan time: 2630\n",
      "\tInput words: ['obviously', 'guarding', 'something.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2632\n",
      "\tInput words: ['She', 'stood', 'up,', 'glaring']\n",
      "Created sample:\n",
      "\tScan time: 2634\n",
      "\tInput words: ['at', 'them.', '+', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 2636\n",
      "\tInput words: ['hope', \"you're\", 'pleased', 'with']\n",
      "Created sample:\n",
      "\tScan time: 2638\n",
      "\tInput words: ['yourselves.', 'We', 'could', 'all']\n",
      "Created sample:\n",
      "\tScan time: 2640\n",
      "\tInput words: ['have', 'been', 'killed', '--']\n",
      "Created sample:\n",
      "\tScan time: 2642\n",
      "\tInput words: ['or', 'worse,', 'expelled.', 'Now,']\n",
      "Created sample:\n",
      "\tScan time: 2644\n",
      "\tInput words: ['if', 'you', \"don't\", 'mind,']\n",
      "Created sample:\n",
      "\tScan time: 2646\n",
      "\tInput words: [\"I'm\", 'going', 'to', 'bed.\"']\n",
      "Created sample:\n",
      "\tScan time: 2648\n",
      "\tInput words: ['+', 'Ron', 'stared', 'after']\n",
      "Created sample:\n",
      "\tScan time: 2650\n",
      "\tInput words: ['her,', 'his', 'mouth', 'open.']\n",
      "Created sample:\n",
      "\tScan time: 2652\n",
      "\tInput words: ['\"No,', 'we', \"don't\", 'mind,\"']\n",
      "Created sample:\n",
      "\tScan time: 2654\n",
      "\tInput words: ['he', 'said.', '\"You\\'d', 'think']\n",
      "Created sample:\n",
      "\tScan time: 2656\n",
      "\tInput words: ['we', 'dragged', 'her', 'along,']\n",
      "Created sample:\n",
      "\tScan time: 2658\n",
      "\tInput words: [\"wouldn't\", 'you?\"', '+', 'But']\n",
      "Created sample:\n",
      "\tScan time: 2660\n",
      "\tInput words: ['Hermione', 'had', 'given', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2662\n",
      "\tInput words: ['something', 'else', 'to', 'think']\n",
      "Created sample:\n",
      "\tScan time: 2664\n",
      "\tInput words: ['about', 'as', 'he', 'climbed']\n",
      "Created sample:\n",
      "\tScan time: 2666\n",
      "\tInput words: ['back', 'into', 'bed.', 'The']\n",
      "Created sample:\n",
      "\tScan time: 2668\n",
      "\tInput words: ['dog', 'was', 'guarding', 'something.']\n",
      "Created sample:\n",
      "\tScan time: 2670\n",
      "\tInput words: ['.', '.', '.', 'What']\n",
      "Created sample:\n",
      "\tScan time: 2672\n",
      "\tInput words: ['had', 'Hagrid', 'said?', 'Gringotts']\n",
      "Created sample:\n",
      "\tScan time: 2674\n",
      "\tInput words: ['was', 'the', 'safest', 'place']\n",
      "Created sample:\n",
      "\tScan time: 2676\n",
      "\tInput words: ['in', 'the', 'world', 'for']\n",
      "Created sample:\n",
      "\tScan time: 2678\n",
      "\tInput words: ['something', 'you', 'wanted', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2680\n",
      "\tInput words: ['hide', '--', 'except', 'perhaps']\n",
      "Created sample:\n",
      "\tScan time: 2682\n",
      "\tInput words: ['Hogwarts.', '+', 'It', 'looked']\n",
      "Created sample:\n",
      "\tScan time: 2684\n",
      "\tInput words: ['as', 'though', 'Harry', 'had']\n",
      "Created sample:\n",
      "\tScan time: 2686\n",
      "\tInput words: ['found', 'out', 'where', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2688\n",
      "\tInput words: ['grubby', 'little', 'package', 'from']\n",
      "Total number of samples: 1287\n"
     ]
    }
   ],
   "source": [
    "subjects_samples = [[] for i in range(NUM_SUBJS)] #stores lists of all the samples for each subject\n",
    "\n",
    "word_count = 0\n",
    "while word_count < len(words_info) - 8:\n",
    "    #gets the 4 input words, and the 4 consecutive words while verifying they were read in sequence\n",
    "    scan_words = []\n",
    "    start_time = words_info[word_count][1]\n",
    "    in_sequence = True #tracks if the words are in sequence or not\n",
    "    for i in range(8):\n",
    "        word_info = words_info[word_count + i]\n",
    "        if word_info[1] != start_time + 0.5*i:\n",
    "            #if some of the words are not in sequence, skip forward 1 word after innter loop\n",
    "            in_sequence = False\n",
    "        scan_words.append(word_info[0])\n",
    "    if not in_sequence:\n",
    "        word_count +=1\n",
    "        continue\n",
    "    fmri_time = start_time + 2 #effect of reading words is assumed to start 2 seconds after and end 8 seconds after\n",
    "    fmri_index = fmri_time//2 #since a scan happens every two seconds, the index is the time divided by 2\n",
    "    if not isinstance(fmri_index, np.int32):\n",
    "        #if the first word is not aligned with the fmri scan (i.e. its not the first word in a TR)\n",
    "        word_count += 1\n",
    "        continue\n",
    "    for count, subject in enumerate(subjects_fmri):\n",
    "        #adds tuple of (fmri_scan, four words)\n",
    "        subjects_samples[count].append((subject[:,:,:,fmri_index+2], scan_words[0:4]))\n",
    "    print(\"Created sample:\")\n",
    "    print(\"\\tScan time:\", str(start_time))\n",
    "    print(\"\\tInput words:\", str(scan_words[0:4]))\n",
    "    #if successful, skip forward to the next set of 4 words\n",
    "    word_count += 4\n",
    "\n",
    "print(\"Total number of samples:\", str(len(subjects_samples[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import html\n",
    "import os\n",
    "from functools import lru_cache\n",
    "\n",
    "import ftfy\n",
    "import regex as re\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def default_bpe():\n",
    "    return os.path.join(os.path.dirname(os.path.abspath(\"./doi_10.5061_dryad.gt413__v1\")), \"bpe_simple_vocab_16e6.txt.gz\")\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def bytes_to_unicode():\n",
    "    \"\"\"\n",
    "    Returns list of utf-8 byte and a corresponding list of unicode strings.\n",
    "    The reversible bpe codes work on unicode strings.\n",
    "    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n",
    "    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n",
    "    This is a signficant percentage of your normal, say, 32K bpe vocab.\n",
    "    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n",
    "    And avoids mapping to whitespace/control characters the bpe code barfs on.\n",
    "    \"\"\"\n",
    "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
    "    cs = bs[:]\n",
    "    n = 0\n",
    "    for b in range(2**8):\n",
    "        if b not in bs:\n",
    "            bs.append(b)\n",
    "            cs.append(2**8+n)\n",
    "            n += 1\n",
    "    cs = [chr(n) for n in cs]\n",
    "    return dict(zip(bs, cs))\n",
    "\n",
    "\n",
    "def get_pairs(word):\n",
    "    \"\"\"Return set of symbol pairs in a word.\n",
    "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def basic_clean(text):\n",
    "    text = ftfy.fix_text(text)\n",
    "    text = html.unescape(html.unescape(text))\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def whitespace_clean(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "class SimpleTokenizer(object):\n",
    "    def __init__(self, bpe_path: str = default_bpe()):\n",
    "        self.byte_encoder = bytes_to_unicode()\n",
    "        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\n",
    "        merges = gzip.open(bpe_path).read().decode(\"utf-8\").split('\\n')\n",
    "        merges = merges[1:49152-256-2+1]\n",
    "        merges = [tuple(merge.split()) for merge in merges]\n",
    "        vocab = list(bytes_to_unicode().values())\n",
    "        vocab = vocab + [v+'</w>' for v in vocab]\n",
    "        for merge in merges:\n",
    "            vocab.append(''.join(merge))\n",
    "        vocab.extend(['<|startoftext|>', '<|endoftext|>'])\n",
    "        self.encoder = dict(zip(vocab, range(len(vocab))))\n",
    "        self.decoder = {v: k for k, v in self.encoder.items()}\n",
    "        self.bpe_ranks = dict(zip(merges, range(len(merges))))\n",
    "        self.cache = {'<|startoftext|>': '<|startoftext|>', '<|endoftext|>': '<|endoftext|>'}\n",
    "        self.pat = re.compile(r\"\"\"<\\|startoftext\\|>|<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\", re.IGNORECASE)\n",
    "\n",
    "    def bpe(self, token):\n",
    "        if token in self.cache:\n",
    "            return self.cache[token]\n",
    "        word = tuple(token[:-1]) + ( token[-1] + '</w>',)\n",
    "        pairs = get_pairs(word)\n",
    "\n",
    "        if not pairs:\n",
    "            return token+'</w>'\n",
    "\n",
    "        while True:\n",
    "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
    "            if bigram not in self.bpe_ranks:\n",
    "                break\n",
    "            first, second = bigram\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                try:\n",
    "                    j = word.index(first, i)\n",
    "                    new_word.extend(word[i:j])\n",
    "                    i = j\n",
    "                except:\n",
    "                    new_word.extend(word[i:])\n",
    "                    break\n",
    "\n",
    "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                    new_word.append(first+second)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            new_word = tuple(new_word)\n",
    "            word = new_word\n",
    "            if len(word) == 1:\n",
    "                break\n",
    "            else:\n",
    "                pairs = get_pairs(word)\n",
    "        word = ' '.join(word)\n",
    "        self.cache[token] = word\n",
    "        return word\n",
    "\n",
    "    def encode(self, text):\n",
    "        bpe_tokens = []\n",
    "        text = whitespace_clean(basic_clean(text)).lower()\n",
    "        for token in re.findall(self.pat, text):\n",
    "            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n",
    "            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n",
    "        return bpe_tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        text = ''.join([self.decoder[token] for token in tokens])\n",
    "        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=\"replace\").replace('</w>', ' ')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import urllib\n",
    "import warnings\n",
    "from typing import Any, Union, List\n",
    "from pkg_resources import packaging\n",
    "\n",
    "_tokenizer = SimpleTokenizer()\n",
    "\n",
    "def tokenize(texts: Union[str, List[str]], context_length: int = 16, truncate: bool = False) -> Union[torch.IntTensor, torch.LongTensor]:\n",
    "    \"\"\"\n",
    "    Returns the tokenized representation of given input string(s)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : Union[str, List[str]]\n",
    "        An input string or a list of input strings to tokenize\n",
    "\n",
    "    context_length : int\n",
    "        The context length to use; all CLIP models use 77 as the context length\n",
    "\n",
    "    truncate: bool\n",
    "        Whether to truncate the text in case its encoding is longer than the context length\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A two-dimensional tensor containing the resulting tokens, shape = [number of input strings, context_length].\n",
    "    We return LongTensor when torch version is <1.8.0, since older index_select requires indices to be long.\n",
    "    \"\"\"\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    sot_token = _tokenizer.encoder[\"<|startoftext|>\"]\n",
    "    eot_token = _tokenizer.encoder[\"<|endoftext|>\"]\n",
    "    all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]\n",
    "    if packaging.version.parse(torch.__version__) < packaging.version.parse(\"1.8.0\"):\n",
    "        result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)\n",
    "    else:\n",
    "        result = torch.zeros(len(all_tokens), context_length, dtype=torch.int)\n",
    "\n",
    "    for i, tokens in enumerate(all_tokens):\n",
    "        if len(tokens) > context_length:\n",
    "            if truncate:\n",
    "                tokens = tokens[:context_length]\n",
    "                tokens[-1] = eot_token\n",
    "            else:\n",
    "                raise RuntimeError(f\"Input {texts[i]} is too long for context length {context_length}\")\n",
    "        result[i, :len(tokens)] = torch.tensor(tokens)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # all conv layers have stride 1. an avgpool is performed after the second convolution when stride > 1\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(planes, planes, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.avgpool = nn.AvgPool3d(stride) if stride > 1 else nn.Identity()\n",
    "\n",
    "        self.conv3 = nn.Conv3d(planes, planes * self.expansion, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = None\n",
    "        self.stride = stride\n",
    "\n",
    "        if stride > 1 or inplanes != planes * Bottleneck.expansion:\n",
    "            # downsampling layer is prepended with an avgpool, and the subsequent convolution has stride 1\n",
    "            self.downsample = nn.Sequential(OrderedDict([\n",
    "                (\"-1\", nn.AvgPool3d(stride)),\n",
    "                (\"0\", nn.Conv3d(inplanes, planes * self.expansion, 1, stride=1, bias=False)),\n",
    "                (\"1\", nn.BatchNorm3d(planes * self.expansion))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        identity = x\n",
    "\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\n",
    "        out = self.relu2(self.bn2(self.conv2(out)))\n",
    "        out = self.avgpool(out)\n",
    "        out = self.bn3(self.conv3(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# class AttentionPool2d(nn.Module):\n",
    "#     def __init__(self, spacial_dim: int, embed_dim: int, num_heads: int, output_dim: int = None):\n",
    "#         super().__init__()\n",
    "#         self.positional_embedding = nn.Parameter(torch.randn(spacial_dim ** 2 + 1, embed_dim) / embed_dim ** 0.5)\n",
    "#         self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.c_proj = nn.Linear(embed_dim, output_dim or embed_dim)\n",
    "#         self.num_heads = num_heads\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.flatten(start_dim=2).permute(2, 0, 1)  # NCHW -> (HW)NC\n",
    "#         x = torch.cat([x.mean(dim=0, keepdim=True), x], dim=0)  # (HW+1)NC\n",
    "#         x = x + self.positional_embedding[:, None, :].to(x.dtype)  # (HW+1)NC\n",
    "#         x, _ = F.multi_head_attention_forward(\n",
    "#             query=x[:1], key=x, value=x,\n",
    "#             embed_dim_to_check=x.shape[-1],\n",
    "#             num_heads=self.num_heads,\n",
    "#             q_proj_weight=self.q_proj.weight,\n",
    "#             k_proj_weight=self.k_proj.weight,\n",
    "#             v_proj_weight=self.v_proj.weight,\n",
    "#             in_proj_weight=None,\n",
    "#             in_proj_bias=torch.cat([self.q_proj.bias, self.k_proj.bias, self.v_proj.bias]),\n",
    "#             bias_k=None,\n",
    "#             bias_v=None,\n",
    "#             add_zero_attn=False,\n",
    "#             dropout_p=0,\n",
    "#             out_proj_weight=self.c_proj.weight,\n",
    "#             out_proj_bias=self.c_proj.bias,\n",
    "#             use_separate_proj_weight=True,\n",
    "#             training=self.training,\n",
    "#             need_weights=False\n",
    "#         )\n",
    "#         return x.squeeze(0)\n",
    "\n",
    "\n",
    "class ModifiedResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet class that is similar to torchvision's but contains the following changes:\n",
    "    - There are now 3 \"stem\" convolutions as opposed to 1, with an average pool instead of a max pool.\n",
    "    - Performs anti-aliasing strided convolutions, where an avgpool is prepended to convolutions with stride > 1\n",
    "    - The final pooling layer is a QKV attention instead of an average pool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, output_dim, heads, input_resolution=224, width=64):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.input_resolution = input_resolution\n",
    "\n",
    "        # the 3-layer stem\n",
    "        self.conv1 = nn.Conv3d(1, width // 2, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(width // 2)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(width // 2, width // 2, kernel_size=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(width // 2)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv3d(width // 2, width, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(width)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AvgPool3d(2)\n",
    "        self.linear = nn.Linear(2048, 1024)\n",
    "\n",
    "        # residual layers\n",
    "        self._inplanes = width  # this is a *mutable* variable used during construction\n",
    "        self.layer1 = self._make_layer(width, layers[0])\n",
    "        self.layer2 = self._make_layer(width * 2, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(width * 4, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(width * 8, layers[3], stride=2)\n",
    "\n",
    "        embed_dim = width * 32  # the ResNet feature dimension\n",
    "#         self.attnpool = AttentionPool2d(input_resolution // 32, embed_dim, heads, output_dim)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1):\n",
    "        layers = [Bottleneck(self._inplanes, planes, stride)]\n",
    "\n",
    "        self._inplanes = planes * Bottleneck.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(Bottleneck(self._inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        def stem(x):\n",
    "            x = self.relu1(self.bn1(self.conv1(x)))\n",
    "            x = self.relu2(self.bn2(self.conv2(x)))\n",
    "            x = self.relu3(self.bn3(self.conv3(x)))\n",
    "            x = self.avgpool(x)\n",
    "            return x\n",
    "\n",
    "        x = x.type(self.conv1.weight.dtype)\n",
    "        x = stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "#         x = self.avgpool(x) #changed final attentionpool to avgpool\n",
    "        #x = self.attnpool(x)\n",
    "        x = x.view(-1,2048) #will have to change this if different layer/kernel sizes used\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNorm(nn.LayerNorm):\n",
    "    \"\"\"Subclass torch's LayerNorm to handle fp16.\"\"\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        orig_type = x.dtype\n",
    "        ret = super().forward(x.type(torch.float32))\n",
    "        return ret.type(orig_type)\n",
    "\n",
    "\n",
    "class QuickGELU(nn.Module):\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x * torch.sigmoid(1.702 * x)\n",
    "\n",
    "\n",
    "class ResidualAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int, attn_mask: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_head)\n",
    "        self.ln_1 = LayerNorm(d_model)\n",
    "        self.mlp = nn.Sequential(OrderedDict([\n",
    "            (\"c_fc\", nn.Linear(d_model, d_model * 4)),\n",
    "            (\"gelu\", QuickGELU()),\n",
    "            (\"c_proj\", nn.Linear(d_model * 4, d_model))\n",
    "        ]))\n",
    "        self.ln_2 = LayerNorm(d_model)\n",
    "        self.attn_mask = attn_mask\n",
    "\n",
    "    def attention(self, x: torch.Tensor):\n",
    "        self.attn_mask = self.attn_mask.to(dtype=x.dtype, device=x.device) if self.attn_mask is not None else None\n",
    "        return self.attn(x, x, x, need_weights=False, attn_mask=self.attn_mask)[0]\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + self.attention(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, width: int, layers: int, heads: int, attn_mask: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "        self.layers = layers\n",
    "        self.resblocks = nn.Sequential(*[ResidualAttentionBlock(width, heads, attn_mask) for _ in range(layers)])\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.resblocks(x)\n",
    "\n",
    "\n",
    "class CLIP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 # vision\n",
    "                 image_resolution: int,\n",
    "                 vision_layers: Union[Tuple[int, int, int, int], int],\n",
    "                 vision_width: int,\n",
    "                 # text\n",
    "                 context_length: int,\n",
    "                 vocab_size: int,\n",
    "                 transformer_width: int,\n",
    "                 transformer_heads: int,\n",
    "                 transformer_layers: int\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.context_length = context_length\n",
    "\n",
    "        #initializes resnet (removed option for vision transformer)\n",
    "        vision_heads = vision_width * 32 // 64\n",
    "        self.visual = ModifiedResNet(\n",
    "            layers=vision_layers,\n",
    "            output_dim=embed_dim,\n",
    "            heads=vision_heads,\n",
    "            input_resolution=image_resolution,\n",
    "            width=vision_width\n",
    "        )\n",
    "\n",
    "        #initializes text transformer\n",
    "        self.transformer = Transformer(\n",
    "            width=transformer_width,\n",
    "            layers=transformer_layers,\n",
    "            heads=transformer_heads,\n",
    "            attn_mask=self.build_attention_mask()\n",
    "        )\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_embedding = nn.Embedding(vocab_size, transformer_width)\n",
    "        self.positional_embedding = nn.Parameter(torch.empty(self.context_length, transformer_width))\n",
    "        self.ln_final = LayerNorm(transformer_width)\n",
    "\n",
    "        self.text_projection = nn.Parameter(torch.empty(transformer_width, embed_dim))\n",
    "        #self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "        self.logit_scale = torch.ones([]) * np.log(1 / 0.07)\n",
    "\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        nn.init.normal_(self.token_embedding.weight, std=0.02)\n",
    "        nn.init.normal_(self.positional_embedding, std=0.01)\n",
    "\n",
    "        if isinstance(self.visual, ModifiedResNet):\n",
    "#             if self.visual.attnpool is not None:\n",
    "#                 std = self.visual.attnpool.c_proj.in_features ** -0.5\n",
    "#                 nn.init.normal_(self.visual.attnpool.q_proj.weight, std=std)\n",
    "#                 nn.init.normal_(self.visual.attnpool.k_proj.weight, std=std)\n",
    "#                 nn.init.normal_(self.visual.attnpool.v_proj.weight, std=std)\n",
    "#                 nn.init.normal_(self.visual.attnpool.c_proj.weight, std=std)\n",
    "\n",
    "            for resnet_block in [self.visual.layer1, self.visual.layer2, self.visual.layer3, self.visual.layer4]:\n",
    "                for name, param in resnet_block.named_parameters():\n",
    "                    if name.endswith(\"bn3.weight\"):\n",
    "                        nn.init.zeros_(param)\n",
    "\n",
    "        proj_std = (self.transformer.width ** -0.5) * ((2 * self.transformer.layers) ** -0.5)\n",
    "        attn_std = self.transformer.width ** -0.5\n",
    "        fc_std = (2 * self.transformer.width) ** -0.5\n",
    "        for block in self.transformer.resblocks:\n",
    "            nn.init.normal_(block.attn.in_proj_weight, std=attn_std)\n",
    "            nn.init.normal_(block.attn.out_proj.weight, std=proj_std)\n",
    "            nn.init.normal_(block.mlp.c_fc.weight, std=fc_std)\n",
    "            nn.init.normal_(block.mlp.c_proj.weight, std=proj_std)\n",
    "\n",
    "        if self.text_projection is not None:\n",
    "            nn.init.normal_(self.text_projection, std=self.transformer.width ** -0.5)\n",
    "\n",
    "    def build_attention_mask(self):\n",
    "        # lazily create causal attention mask, with full attention between the vision tokens\n",
    "        # pytorch uses additive attention mask; fill with -inf\n",
    "        mask = torch.empty(self.context_length, self.context_length)\n",
    "        mask.fill_(float(\"-inf\"))\n",
    "        mask.triu_(1)  # zero out the lower diagonal\n",
    "        return mask\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.visual.conv1.weight.dtype\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.visual(image.type(self.dtype))\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        x = self.token_embedding(text).type(self.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "        x = x + self.positional_embedding.type(self.dtype)\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.ln_final(x).type(self.dtype)\n",
    "\n",
    "        # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ self.text_projection\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        image_features = self.encode_image(image)\n",
    "        text_features = self.encode_text(text)\n",
    "\n",
    "        # normalized features\n",
    "        image_features = image_features / image_features.norm(dim=1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "\n",
    "        # shape = [global_batch_size, global_batch_size]\n",
    "        return logits_per_image, logits_per_text\n",
    "\n",
    "\n",
    "def convert_weights(model: nn.Module):\n",
    "    \"\"\"Convert applicable model parameters to fp16\"\"\"\n",
    "\n",
    "    def _convert_weights_to_fp16(l):\n",
    "        if isinstance(l, (nn.Conv1d, nn.Conv3d, nn.Linear)):\n",
    "            l.weight.data = l.weight.data.half()\n",
    "            if l.bias is not None:\n",
    "                l.bias.data = l.bias.data.half()\n",
    "\n",
    "        if isinstance(l, nn.MultiheadAttention):\n",
    "            for attr in [*[f\"{s}_proj_weight\" for s in [\"in\", \"q\", \"k\", \"v\"]], \"in_proj_bias\", \"bias_k\", \"bias_v\"]:\n",
    "                tensor = getattr(l, attr)\n",
    "                if tensor is not None:\n",
    "                    tensor.data = tensor.data.half()\n",
    "\n",
    "        for name in [\"text_projection\", \"proj\"]:\n",
    "            if hasattr(l, name):\n",
    "                attr = getattr(l, name)\n",
    "                if attr is not None:\n",
    "                    attr.data = attr.data.half()\n",
    "\n",
    "    model.apply(_convert_weights_to_fp16)\n",
    "\n",
    "\n",
    "def build_model(state_dict: dict):\n",
    "    vit = \"visual.proj\" in state_dict\n",
    "\n",
    "    if vit:\n",
    "        vision_width = state_dict[\"visual.conv1.weight\"].shape[0]\n",
    "        vision_layers = len([k for k in state_dict.keys() if k.startswith(\"visual.\") and k.endswith(\".attn.in_proj_weight\")])\n",
    "        vision_patch_size = state_dict[\"visual.conv1.weight\"].shape[-1]\n",
    "        grid_size = round((state_dict[\"visual.positional_embedding\"].shape[0] - 1) ** 0.5)\n",
    "        image_resolution = vision_patch_size * grid_size\n",
    "    else:\n",
    "        counts: list = [len(set(k.split(\".\")[2] for k in state_dict if k.startswith(f\"visual.layer{b}\"))) for b in [1, 2, 3, 4]]\n",
    "        vision_layers = tuple(counts)\n",
    "        vision_width = state_dict[\"visual.layer1.0.conv1.weight\"].shape[0]\n",
    "        output_width = round((state_dict[\"visual.attnpool.positional_embedding\"].shape[0] - 1) ** 0.5)\n",
    "        vision_patch_size = None\n",
    "        assert output_width ** 2 + 1 == state_dict[\"visual.attnpool.positional_embedding\"].shape[0]\n",
    "        image_resolution = output_width * 32\n",
    "\n",
    "    embed_dim = state_dict[\"text_projection\"].shape[1]\n",
    "    context_length = state_dict[\"positional_embedding\"].shape[0]\n",
    "    vocab_size = state_dict[\"token_embedding.weight\"].shape[0]\n",
    "    transformer_width = state_dict[\"ln_final.weight\"].shape[0]\n",
    "    transformer_heads = transformer_width // 64\n",
    "    transformer_layers = len(set(k.split(\".\")[2] for k in state_dict if k.startswith(\"transformer.resblocks\")))\n",
    "\n",
    "    model = CLIP(\n",
    "        embed_dim,\n",
    "        image_resolution, vision_layers, vision_width, vision_patch_size,\n",
    "        context_length, vocab_size, transformer_width, transformer_heads, transformer_layers\n",
    "    )\n",
    "\n",
    "    for key in [\"input_resolution\", \"context_length\", \"vocab_size\"]:\n",
    "        if key in state_dict:\n",
    "            del state_dict[key]\n",
    "\n",
    "    convert_weights(model)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MODELS = {\n",
    "    \"RN50\": \"https://openaipublic.azureedge.net/clip/models/afeb0e10f9e5a86da6080e35cf09123aca3b358a0c3e3b6c78a7b63bc04b6762/RN50.pt\",\n",
    "    \"RN101\": \"https://openaipublic.azureedge.net/clip/models/8fa8567bab74a42d41c5915025a8e4538c3bdbe8804a470a72f30b0d94fab599/RN101.pt\",\n",
    "    \"RN50x4\": \"https://openaipublic.azureedge.net/clip/models/7e526bd135e493cef0776de27d5f42653e6b4c8bf9e0f653bb11773263205fdd/RN50x4.pt\",\n",
    "    \"RN50x16\": \"https://openaipublic.azureedge.net/clip/models/52378b407f34354e150460fe41077663dd5b39c54cd0bfd2b27167a4a06ec9aa/RN50x16.pt\",\n",
    "    \"RN50x64\": \"https://openaipublic.azureedge.net/clip/models/be1cfb55d75a9666199fb2206c106743da0f6468c9d327f3e0d0a543a9919d9c/RN50x64.pt\",\n",
    "    \"ViT-B/32\": \"https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\",\n",
    "    \"ViT-B/16\": \"https://openaipublic.azureedge.net/clip/models/5806e77cd80f8b59890b7e101eabd078d9fb84e6937f9e85e4ecb61988df416f/ViT-B-16.pt\",\n",
    "    \"ViT-L/14\": \"https://openaipublic.azureedge.net/clip/models/b8cca3fd41ae0c99ba7e8951adf17d267cdb84cd88be6f7c2e0eca1737a03836/ViT-L-14.pt\",\n",
    "    \"ViT-L/14@336px\": \"https://openaipublic.azureedge.net/clip/models/3035c92b350959924f9f00213499208652fc7ea050643e8b385c2dac08641f02/ViT-L-14-336px.pt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _download(url: str, root: str):\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "    filename = os.path.basename(url)\n",
    "\n",
    "    expected_sha256 = url.split(\"/\")[-2]\n",
    "    download_target = os.path.join(root, filename)\n",
    "\n",
    "    if os.path.exists(download_target) and not os.path.isfile(download_target):\n",
    "        raise RuntimeError(f\"{download_target} exists and is not a regular file\")\n",
    "\n",
    "    if os.path.isfile(download_target):\n",
    "        if hashlib.sha256(open(download_target, \"rb\").read()).hexdigest() == expected_sha256:\n",
    "            return download_target\n",
    "        else:\n",
    "            warnings.warn(f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\")\n",
    "\n",
    "    with urllib.request.urlopen(url) as source, open(download_target, \"wb\") as output:\n",
    "        with tqdm(total=int(source.info().get(\"Content-Length\")), ncols=80, unit='iB', unit_scale=True, unit_divisor=1024) as loop:\n",
    "            while True:\n",
    "                buffer = source.read(8192)\n",
    "                if not buffer:\n",
    "                    break\n",
    "\n",
    "                output.write(buffer)\n",
    "                loop.update(len(buffer))\n",
    "\n",
    "    if hashlib.sha256(open(download_target, \"rb\").read()).hexdigest() != expected_sha256:\n",
    "        raise RuntimeError(\"Model has been downloaded but the SHA256 checksum does not not match\")\n",
    "\n",
    "    return download_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"RN50\"\n",
    "if name in _MODELS:\n",
    "    model_path = _download(_MODELS[name], os.path.expanduser(\"~/.cache/clip\"))\n",
    "else:\n",
    "    raise RuntimeError(f\"Model {name} not found; available models = {available_models()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit=True\n",
    "with open(model_path, 'rb') as opened_file:\n",
    "    try:\n",
    "        # loading JIT archive\n",
    "        model = torch.jit.load(opened_file, map_location=device if jit else \"cpu\").eval()\n",
    "        state_dict = model.state_dict()\n",
    "    except RuntimeError:\n",
    "        # loading saved state dict\n",
    "        if jit:\n",
    "            warnings.warn(f\"File {model_path} is not a JIT archive. Loading as a state dict instead\")\n",
    "            jit = False\n",
    "        state_dict = torch.load(opened_file, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 6, 3)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#vision\n",
    "counts: list = [len(set(k.split(\".\")[2] for k in state_dict if k.startswith(f\"visual.layer{b}\"))) for b in [1, 2, 3, 4]]\n",
    "vision_layers = tuple(counts)\n",
    "print(vision_layers)\n",
    "vision_width = state_dict[\"visual.layer1.0.conv1.weight\"].shape[0]\n",
    "output_width = round((state_dict[\"visual.attnpool.positional_embedding\"].shape[0] - 1) ** 0.5)\n",
    "print(output_width)\n",
    "assert output_width ** 2 + 1 == state_dict[\"visual.attnpool.positional_embedding\"].shape[0]\n",
    "image_resolution = output_width * 32\n",
    "\n",
    "#transformer\n",
    "embed_dim = state_dict[\"text_projection\"].shape[1]\n",
    "context_length = state_dict[\"positional_embedding\"].shape[0]\n",
    "vocab_size = state_dict[\"token_embedding.weight\"].shape[0]\n",
    "transformer_width = state_dict[\"ln_final.weight\"].shape[0]\n",
    "transformer_heads = transformer_width // 64\n",
    "transformer_layers = len(set(k.split(\".\")[2] for k in state_dict if k.startswith(\"transformer.resblocks\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CLIP(\n",
    "#     embed_dim=state_dict[\"text_projection\"].shape[1],\n",
    "#     image_resolution=None, \n",
    "#     vision_layers=[3, 4, 6, 3], \n",
    "#     vision_width=64,\n",
    "#     context_length=state_dict[\"positional_embedding\"].shape[0], \n",
    "#     vocab_size=state_dict[\"token_embedding.weight\"].shape[0], \n",
    "#     transformer_width=state_dict[\"ln_final.weight\"].shape[0], \n",
    "#     transformer_heads=state_dict[\"ln_final.weight\"].shape[0]//64, \n",
    "#     transformer_layers=len(set(k.split(\".\")[2] for k in state_dict if k.startswith(\"transformer.resblocks\")))\n",
    "# )\n",
    "\n",
    "model = CLIP(\n",
    "    embed_dim,\n",
    "    image_resolution, vision_layers, vision_width,\n",
    "    context_length, vocab_size, transformer_width, transformer_heads, transformer_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trains the clip model from scratch\n",
    "def train_clip(model, text_samples, image_samples, batch_size=10, num_epochs=100, lr=1e-3, temp=0.07, clip_value=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.2)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        image_epoch_correct = 0\n",
    "        text_epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        text_samples, image_samples = unison_shuffled_copies(text_samples, image_samples)\n",
    "        for batch in range(math.floor(image_samples.shape[0]/batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #gets embeddings for text and image batches\n",
    "            start_idx = batch*batch_size\n",
    "            end_idx = (batch+1)*batch_size\n",
    "            text_batch, image_batch = text_samples[start_idx:end_idx], image_samples[start_idx:end_idx]\n",
    "            \n",
    "            logits_per_image, logits_per_text = model(torch.unsqueeze(image_batch, dim=1), text_batch)\n",
    "#             print(logits_per_image.shape)\n",
    "#             print(logits_per_image)\n",
    "            \n",
    "            #symmetric loss function\n",
    "            labels = torch.arange(batch_size).to(device)\n",
    "            loss_text = loss_fn(logits_per_text, labels)\n",
    "            loss_image = loss_fn(logits_per_image, labels)\n",
    "            loss = (loss_text + loss_image)/2\n",
    "            print(\"\\tBatch:\", batch, \"/\", math.floor(image_samples.shape[0]/batch_size), \", Loss:\", loss)\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #compute accuracy\n",
    "            image_winners = torch.argmax(logits_per_image, dim=0)\n",
    "            text_winners = torch.argmax(logits_per_text, dim=0)\n",
    "            #print(winners)\n",
    "            #print(labels)\n",
    "            image_corrects = (image_winners == labels)\n",
    "            text_corrects = (text_winners == labels)\n",
    "            total_image_correct = image_corrects.sum().float().item()\n",
    "            total_text_correct = text_corrects.sum().float().item()\n",
    "            image_epoch_correct += total_image_correct\n",
    "            text_epoch_correct += total_text_correct\n",
    "            epoch_total += batch_size\n",
    "#             for param in model.parameters():\n",
    "#                 print(torch.absolute(param.grad.data).sum())\n",
    "# #                 print(param.grad.data)\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Epoch:\", epoch, \"Training Loss:\", epoch_loss, \"Training Image Accuracy:\", image_epoch_correct/epoch_total, \"Training Text Accuracy:\", text_epoch_correct/epoch_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using real fMRI and text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49406,  3600,  9026,   739,   320, 49407,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [49406, 14295,   537,   797,  1466, 49407,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
      "torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "print(tokenize([\"Harry potter was a\", \"wizard and he always\"]))\n",
    "print(tokenize([\"Harry potter was a\", \"wizard and he always\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_samples(samples):\n",
    "    images = torch.zeros([len(samples)] + list(samples[0][0].shape))\n",
    "    text = torch.zeros((len(samples), 16), dtype=int)\n",
    "    for idx, sample in enumerate(samples):\n",
    "        images[idx] = torch.tensor(sample[0])\n",
    "        text[idx] = tokenize([\" \".join(sample[1])])\n",
    "    images = (images - images.min())/(images.max() - images.min())\n",
    "    return images.to(device), text.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "torch.Size([1287, 16])\n",
      "torch.Size([1287, 53, 60, 50])\n"
     ]
    }
   ],
   "source": [
    "train_split = 1.0\n",
    "\n",
    "train_samples = subjects_samples[0][:int(len(subjects_samples[0])*train_split)]\n",
    "train_images, train_text = split_samples(train_samples)\n",
    "print(\"Train:\")\n",
    "print(train_text.shape)\n",
    "print(train_images.shape)\n",
    "if torch.isnan(torch.sum(train_text)) or torch.isinf(torch.sum(train_text)):\n",
    "    print('invalid input detected in text.')\n",
    "if torch.isnan(torch.sum(train_images)) or torch.isinf(torch.sum(train_images)):\n",
    "    print('invalid input detected in images.')\n",
    "\n",
    "# test_samples = subjects_samples[0][int(len(subjects_samples[0])*train_split):]\n",
    "# test_images, test_text = split_samples(test_samples)\n",
    "# print(\"Test:\")\n",
    "# print(len(test_text))\n",
    "# print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model = CLIP(\n",
    "    embed_dim,\n",
    "    image_resolution, (2,2,2,2), 64,\n",
    "    16, vocab_size, transformer_width, transformer_heads, transformer_layers\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 0 / 20 , Loss: tensor(4.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.8290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(5.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.3817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(4.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(4.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 0 Training Loss: 85.79557275772095 Training Image Accuracy: 0.0171875 Training Text Accuracy: 0.021875\n",
      "\tBatch: 0 / 20 , Loss: tensor(4.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(4.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(4.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(4.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Training Loss: 82.50481653213501 Training Image Accuracy: 0.01875 Training Text Accuracy: 0.0359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(4.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(4.0123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.9416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.7950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.9711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.0123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.0426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.0404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.1998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.9578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Training Loss: 81.13617157936096 Training Image Accuracy: 0.0421875 Training Text Accuracy: 0.0390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.7657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.7888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(4.0108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.9095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.9331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.8017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.8174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.7640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.8712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.0203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.8865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.8599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.7962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.8466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.8009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.8859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.7083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.0425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Training Loss: 77.10231018066406 Training Image Accuracy: 0.05859375 Training Text Accuracy: 0.07421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.7128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.5272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.5561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.6566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.5515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.5521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.5373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.5351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.5466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.6507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.4819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.4253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.5289, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 18 / 20 , Loss: tensor(3.6282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Training Loss: 70.51367282867432 Training Image Accuracy: 0.08984375 Training Text Accuracy: 0.1015625\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.8975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.2784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.1973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.3657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Training Loss: 64.86231017112732 Training Image Accuracy: 0.11015625 Training Text Accuracy: 0.1265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.8418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.7427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.9634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.8814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.8752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.7248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.0189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.9918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.7514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.9833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.3368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.9822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.2834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.0285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Training Loss: 60.03501510620117 Training Image Accuracy: 0.14765625 Training Text Accuracy: 0.15859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.7740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.9272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.7599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.5116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.8368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.5856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.7436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.7572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.6372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.0382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.6898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.8591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.8871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.7561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.8306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.9872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Training Loss: 55.13221788406372 Training Image Accuracy: 0.1859375 Training Text Accuracy: 0.18671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.5281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.5042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.8583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.7381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.8147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.6454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.5333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.6532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.7762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.9407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.7002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.7923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.6662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.9204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Training Loss: 52.22615957260132 Training Image Accuracy: 0.21171875 Training Text Accuracy: 0.2203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.6407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.5937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.5150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.4100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.4791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.4746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.5124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.2999, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(2.5790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.6592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.5348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.7632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Training Loss: 49.16825079917908 Training Image Accuracy: 0.24296875 Training Text Accuracy: 0.2359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.9997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.0402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.0575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.0103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.3841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.2776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Training Loss: 43.246243715286255 Training Image Accuracy: 0.3078125 Training Text Accuracy: 0.2984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.9264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.9825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.9930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.9620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.9958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.9428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.9575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.9032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.4316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.0275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Training Loss: 42.379660844802856 Training Image Accuracy: 0.3046875 Training Text Accuracy: 0.31171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.9621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.8427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.9856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.7977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.8772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.0338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.8729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Training Loss: 41.18114101886749 Training Image Accuracy: 0.33359375 Training Text Accuracy: 0.3109375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.7799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.5821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.9583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.7621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.8737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.7638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.6594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.6975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.9277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.7960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.6558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.7795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.6525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.7473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.9187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Training Loss: 36.40448868274689 Training Image Accuracy: 0.39921875 Training Text Accuracy: 0.4015625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.8546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.6030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.7233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.6472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.9644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.8521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.9485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.9626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.8677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.7251, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 11 / 20 , Loss: tensor(2.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.9501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.7364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.0579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.9649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.0297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Training Loss: 38.319405913352966 Training Image Accuracy: 0.384375 Training Text Accuracy: 0.365625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.7763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.8607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.7033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.9159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.6446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.8946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.9225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.5803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.6556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.8498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.6823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.6663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.8857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.7447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.5764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Training Loss: 36.10843217372894 Training Image Accuracy: 0.4046875 Training Text Accuracy: 0.39140625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.6581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.5380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.7060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.7391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.5892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.6349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.6586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.4911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.6904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.5533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.5284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.5674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.8862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.6932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.9487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.8006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Training Loss: 32.57222390174866 Training Image Accuracy: 0.4671875 Training Text Accuracy: 0.43203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.7784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.8689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.7540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.4700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.7710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.7052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.7518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.7764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.6793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.7714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.4582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.7048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.5305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Training Loss: 33.31865954399109 Training Image Accuracy: 0.4375 Training Text Accuracy: 0.42265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.4744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.2085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.4257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.3680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.6965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.3907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Training Loss: 27.55555748939514 Training Image Accuracy: 0.53828125 Training Text Accuracy: 0.52578125\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.7682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.4565, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 7 / 20 , Loss: tensor(1.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.6144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.3405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.5439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.4587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Training Loss: 27.946170449256897 Training Image Accuracy: 0.52265625 Training Text Accuracy: 0.5265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.2706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.2456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.4691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.4917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Training Loss: 25.93335473537445 Training Image Accuracy: 0.5671875 Training Text Accuracy: 0.5375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.9632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.5467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Training Loss: 24.730577290058136 Training Image Accuracy: 0.5859375 Training Text Accuracy: 0.55625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.9257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.9880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.9326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.8802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.9267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Training Loss: 21.342093348503113 Training Image Accuracy: 0.6609375 Training Text Accuracy: 0.621875\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.9492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.5005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.0559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.6589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.5327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.4199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.7267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.3975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.7818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Training Loss: 26.245633959770203 Training Image Accuracy: 0.575 Training Text Accuracy: 0.54296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.9645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.2065, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 4 / 20 , Loss: tensor(1.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.4470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.4455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.4802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.4168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Training Loss: 24.543788611888885 Training Image Accuracy: 0.615625 Training Text Accuracy: 0.584375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.0230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.9860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.9878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.2502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.4179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Training Loss: 22.549220860004425 Training Image Accuracy: 0.61484375 Training Text Accuracy: 0.615625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.2056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.9431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.9718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.0266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.5397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.4289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.4269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.0098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Training Loss: 24.30868351459503 Training Image Accuracy: 0.584375 Training Text Accuracy: 0.571875\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.0307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.0262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.9329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Training Loss: 19.872670769691467 Training Image Accuracy: 0.6703125 Training Text Accuracy: 0.66328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.9620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.3717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.9970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.2071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.9373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Training Loss: 20.564057290554047 Training Image Accuracy: 0.67421875 Training Text Accuracy: 0.62421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(0.8078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.9960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.0126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.9548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.9724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Training Loss: 19.626762092113495 Training Image Accuracy: 0.6703125 Training Text Accuracy: 0.66640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.8924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.9308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.8111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Training Loss: 17.012531340122223 Training Image Accuracy: 0.7265625 Training Text Accuracy: 0.7109375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.8672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.0078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Training Loss: 15.826253950595856 Training Image Accuracy: 0.75078125 Training Text Accuracy: 0.740625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.8343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.9752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.0308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.0302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.9263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Training Loss: 17.727091073989868 Training Image Accuracy: 0.6953125 Training Text Accuracy: 0.68984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8934, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Training Loss: 15.71764761209488 Training Image Accuracy: 0.7625 Training Text Accuracy: 0.746875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.8899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.8632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Training Loss: 15.673408448696136 Training Image Accuracy: 0.73125 Training Text Accuracy: 0.7265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.9255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.8307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.9872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.9285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Training Loss: 16.341577172279358 Training Image Accuracy: 0.72734375 Training Text Accuracy: 0.73203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.8805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Training Loss: 16.36756306886673 Training Image Accuracy: 0.725 Training Text Accuracy: 0.725\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.9163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.9245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.9022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Training Loss: 15.644852697849274 Training Image Accuracy: 0.7609375 Training Text Accuracy: 0.75\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8978, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 16 / 20 , Loss: tensor(0.6828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Training Loss: 14.575884878635406 Training Image Accuracy: 0.76328125 Training Text Accuracy: 0.75234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Training Loss: 12.551152646541595 Training Image Accuracy: 0.82578125 Training Text Accuracy: 0.80703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.8704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Training Loss: 12.404715329408646 Training Image Accuracy: 0.82265625 Training Text Accuracy: 0.8109375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Training Loss: 13.940089404582977 Training Image Accuracy: 0.790625 Training Text Accuracy: 0.765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.9324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Training Loss: 15.14011001586914 Training Image Accuracy: 0.75703125 Training Text Accuracy: 0.7640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 12 / 20 , Loss: tensor(1.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Training Loss: 13.341532766819 Training Image Accuracy: 0.790625 Training Text Accuracy: 0.7984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.9386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.8129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Training Loss: 14.759393453598022 Training Image Accuracy: 0.74921875 Training Text Accuracy: 0.7609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.0366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.9637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Training Loss: 14.151414811611176 Training Image Accuracy: 0.759375 Training Text Accuracy: 0.7609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Training Loss: 12.673474967479706 Training Image Accuracy: 0.81171875 Training Text Accuracy: 0.79765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Training Loss: 13.04464966058731 Training Image Accuracy: 0.790625 Training Text Accuracy: 0.79453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5537, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 8 / 20 , Loss: tensor(0.5456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Training Loss: 12.873430728912354 Training Image Accuracy: 0.8109375 Training Text Accuracy: 0.7984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.8004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Training Loss: 14.222853243350983 Training Image Accuracy: 0.78359375 Training Text Accuracy: 0.76640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Training Loss: 13.424350142478943 Training Image Accuracy: 0.796875 Training Text Accuracy: 0.78359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Training Loss: 11.343082249164581 Training Image Accuracy: 0.8328125 Training Text Accuracy: 0.840625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Training Loss: 11.18298152089119 Training Image Accuracy: 0.85859375 Training Text Accuracy: 0.846875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6158, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 4 / 20 , Loss: tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Training Loss: 10.362672865390778 Training Image Accuracy: 0.87265625 Training Text Accuracy: 0.859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Training Loss: 11.374559074640274 Training Image Accuracy: 0.815625 Training Text Accuracy: 0.84453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Training Loss: 12.343165278434753 Training Image Accuracy: 0.82109375 Training Text Accuracy: 0.82265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Training Loss: 12.450634717941284 Training Image Accuracy: 0.79765625 Training Text Accuracy: 0.81328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Training Loss: 12.489810526371002 Training Image Accuracy: 0.8046875 Training Text Accuracy: 0.81796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 0 / 20 , Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Training Loss: 11.966533482074738 Training Image Accuracy: 0.825 Training Text Accuracy: 0.82421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Training Loss: 11.47016754746437 Training Image Accuracy: 0.8359375 Training Text Accuracy: 0.82890625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Training Loss: 10.777456432580948 Training Image Accuracy: 0.83046875 Training Text Accuracy: 0.8546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Training Loss: 9.979994595050812 Training Image Accuracy: 0.86953125 Training Text Accuracy: 0.865625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 18 / 20 , Loss: tensor(0.4930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Training Loss: 9.20815885066986 Training Image Accuracy: 0.8984375 Training Text Accuracy: 0.88203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Training Loss: 8.435854583978653 Training Image Accuracy: 0.91484375 Training Text Accuracy: 0.9046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Training Loss: 7.695187747478485 Training Image Accuracy: 0.91875 Training Text Accuracy: 0.90703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Training Loss: 8.151126861572266 Training Image Accuracy: 0.9171875 Training Text Accuracy: 0.9078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Training Loss: 9.344518959522247 Training Image Accuracy: 0.87421875 Training Text Accuracy: 0.88671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6005, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(0.4250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Training Loss: 11.09088408946991 Training Image Accuracy: 0.828125 Training Text Accuracy: 0.8375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.9321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Training Loss: 12.703205704689026 Training Image Accuracy: 0.803125 Training Text Accuracy: 0.83046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Training Loss: 11.772065162658691 Training Image Accuracy: 0.8390625 Training Text Accuracy: 0.81796875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Training Loss: 10.711852878332138 Training Image Accuracy: 0.8734375 Training Text Accuracy: 0.84609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Training Loss: 9.430395662784576 Training Image Accuracy: 0.884375 Training Text Accuracy: 0.87265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 12 / 20 , Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Training Loss: 8.337689012289047 Training Image Accuracy: 0.90703125 Training Text Accuracy: 0.91171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Training Loss: 10.363544315099716 Training Image Accuracy: 0.8421875 Training Text Accuracy: 0.859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Training Loss: 10.338766187429428 Training Image Accuracy: 0.8390625 Training Text Accuracy: 0.86328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Training Loss: 10.031276017427444 Training Image Accuracy: 0.86640625 Training Text Accuracy: 0.8609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Training Loss: 10.785412758588791 Training Image Accuracy: 0.85546875 Training Text Accuracy: 0.84296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 8 / 20 , Loss: tensor(0.8441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Training Loss: 10.805682629346848 Training Image Accuracy: 0.83515625 Training Text Accuracy: 0.84453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Training Loss: 10.085445046424866 Training Image Accuracy: 0.86953125 Training Text Accuracy: 0.85234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Training Loss: 9.118038803339005 Training Image Accuracy: 0.88203125 Training Text Accuracy: 0.88125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Training Loss: 8.741308808326721 Training Image Accuracy: 0.89140625 Training Text Accuracy: 0.89453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Training Loss: 8.66979256272316 Training Image Accuracy: 0.9015625 Training Text Accuracy: 0.88671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 4 / 20 , Loss: tensor(0.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Training Loss: 8.04825747013092 Training Image Accuracy: 0.9 Training Text Accuracy: 0.91796875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Training Loss: 7.020761996507645 Training Image Accuracy: 0.92734375 Training Text Accuracy: 0.925\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Training Loss: 8.135888695716858 Training Image Accuracy: 0.9015625 Training Text Accuracy: 0.9\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Training Loss: 8.522399246692657 Training Image Accuracy: 0.8953125 Training Text Accuracy: 0.8953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Training Loss: 9.265363216400146 Training Image Accuracy: 0.87578125 Training Text Accuracy: 0.87890625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4821, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.9162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Training Loss: 12.008556842803955 Training Image Accuracy: 0.8203125 Training Text Accuracy: 0.83046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Training Loss: 11.260180830955505 Training Image Accuracy: 0.83828125 Training Text Accuracy: 0.828125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Training Loss: 11.255521059036255 Training Image Accuracy: 0.83515625 Training Text Accuracy: 0.8375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Training Loss: 9.284099996089935 Training Image Accuracy: 0.878125 Training Text Accuracy: 0.875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Training Loss: 8.915916502475739 Training Image Accuracy: 0.88359375 Training Text Accuracy: 0.8875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Training Loss: 7.726303368806839 Training Image Accuracy: 0.9171875 Training Text Accuracy: 0.91875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Training Loss: 7.892736464738846 Training Image Accuracy: 0.90859375 Training Text Accuracy: 0.903125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Training Loss: 9.07957237958908 Training Image Accuracy: 0.87890625 Training Text Accuracy: 0.88984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Training Loss: 7.787190228700638 Training Image Accuracy: 0.91796875 Training Text Accuracy: 0.91875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3449, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 16 / 20 , Loss: tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Training Loss: 7.555694550275803 Training Image Accuracy: 0.9140625 Training Text Accuracy: 0.90390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Training Loss: 7.86100235581398 Training Image Accuracy: 0.915625 Training Text Accuracy: 0.90546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Training Loss: 7.1848354190588 Training Image Accuracy: 0.9234375 Training Text Accuracy: 0.93125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Training Loss: 8.249094158411026 Training Image Accuracy: 0.8984375 Training Text Accuracy: 0.89921875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Training Loss: 7.802944004535675 Training Image Accuracy: 0.9 Training Text Accuracy: 0.90859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4053, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 13 / 20 , Loss: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 101 Training Loss: 7.715092211961746 Training Image Accuracy: 0.9171875 Training Text Accuracy: 0.9125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.1827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 102 Training Loss: 7.390768945217133 Training Image Accuracy: 0.9234375 Training Text Accuracy: 0.9109375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 103 Training Loss: 7.438090115785599 Training Image Accuracy: 0.9203125 Training Text Accuracy: 0.9140625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 104 Training Loss: 6.886301606893539 Training Image Accuracy: 0.92890625 Training Text Accuracy: 0.92421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 105 Training Loss: 7.070210501551628 Training Image Accuracy: 0.92265625 Training Text Accuracy: 0.928125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4714, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 9 / 20 , Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 106 Training Loss: 7.891047716140747 Training Image Accuracy: 0.90390625 Training Text Accuracy: 0.90390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 107 Training Loss: 7.8193046897649765 Training Image Accuracy: 0.90859375 Training Text Accuracy: 0.91171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 108 Training Loss: 8.4418985247612 Training Image Accuracy: 0.89375 Training Text Accuracy: 0.896875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 109 Training Loss: 7.79837366938591 Training Image Accuracy: 0.8984375 Training Text Accuracy: 0.9046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 110 Training Loss: 8.598440617322922 Training Image Accuracy: 0.89765625 Training Text Accuracy: 0.89609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 5 / 20 , Loss: tensor(0.4295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 111 Training Loss: 9.637403815984726 Training Image Accuracy: 0.85234375 Training Text Accuracy: 0.87734375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 112 Training Loss: 9.254564821720123 Training Image Accuracy: 0.8890625 Training Text Accuracy: 0.8875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 113 Training Loss: 9.497584760189056 Training Image Accuracy: 0.88125 Training Text Accuracy: 0.86796875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 114 Training Loss: 8.564354807138443 Training Image Accuracy: 0.89140625 Training Text Accuracy: 0.88828125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 115 Training Loss: 7.411763966083527 Training Image Accuracy: 0.91796875 Training Text Accuracy: 0.92109375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4396, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 116 Training Loss: 6.95920866727829 Training Image Accuracy: 0.92734375 Training Text Accuracy: 0.93046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 117 Training Loss: 7.132260859012604 Training Image Accuracy: 0.91640625 Training Text Accuracy: 0.925\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 118 Training Loss: 6.682280361652374 Training Image Accuracy: 0.93828125 Training Text Accuracy: 0.93984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 119 Training Loss: 7.4019069373607635 Training Image Accuracy: 0.9234375 Training Text Accuracy: 0.91875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4922, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 120 Training Loss: 8.040475487709045 Training Image Accuracy: 0.9078125 Training Text Accuracy: 0.903125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 121 Training Loss: 7.5705247819423676 Training Image Accuracy: 0.91015625 Training Text Accuracy: 0.9140625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 122 Training Loss: 8.559612184762955 Training Image Accuracy: 0.88671875 Training Text Accuracy: 0.89375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 123 Training Loss: 8.613063484430313 Training Image Accuracy: 0.89375 Training Text Accuracy: 0.8953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 124 Training Loss: 7.883964270353317 Training Image Accuracy: 0.9046875 Training Text Accuracy: 0.9140625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(0.4708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 125 Training Loss: 7.0454427897930145 Training Image Accuracy: 0.92734375 Training Text Accuracy: 0.91875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 126 Training Loss: 6.590640753507614 Training Image Accuracy: 0.93046875 Training Text Accuracy: 0.9390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 127 Training Loss: 5.946263551712036 Training Image Accuracy: 0.95859375 Training Text Accuracy: 0.9484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 128 Training Loss: 5.616400644183159 Training Image Accuracy: 0.96171875 Training Text Accuracy: 0.95\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 129 Training Loss: 5.8152066469192505 Training Image Accuracy: 0.959375 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 11 / 20 , Loss: tensor(0.5640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 130 Training Loss: 6.764251708984375 Training Image Accuracy: 0.9390625 Training Text Accuracy: 0.9421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 131 Training Loss: 7.480132043361664 Training Image Accuracy: 0.921875 Training Text Accuracy: 0.91328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 132 Training Loss: 7.774495333433151 Training Image Accuracy: 0.9078125 Training Text Accuracy: 0.91484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 133 Training Loss: 6.976044058799744 Training Image Accuracy: 0.92890625 Training Text Accuracy: 0.93515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 134 Training Loss: 8.095469385385513 Training Image Accuracy: 0.90859375 Training Text Accuracy: 0.88515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 7 / 20 , Loss: tensor(0.3465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 135 Training Loss: 7.849574089050293 Training Image Accuracy: 0.90234375 Training Text Accuracy: 0.9046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 136 Training Loss: 7.831725865602493 Training Image Accuracy: 0.9109375 Training Text Accuracy: 0.9\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 137 Training Loss: 7.1487641632556915 Training Image Accuracy: 0.92890625 Training Text Accuracy: 0.91796875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 138 Training Loss: 7.137416869401932 Training Image Accuracy: 0.9234375 Training Text Accuracy: 0.91875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 139 Training Loss: 7.582029849290848 Training Image Accuracy: 0.91171875 Training Text Accuracy: 0.9078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 3 / 20 , Loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 140 Training Loss: 6.97087487578392 Training Image Accuracy: 0.93125 Training Text Accuracy: 0.93125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 141 Training Loss: 7.308287888765335 Training Image Accuracy: 0.9125 Training Text Accuracy: 0.91484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 142 Training Loss: 7.597181558609009 Training Image Accuracy: 0.91953125 Training Text Accuracy: 0.9171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 143 Training Loss: 6.83781972527504 Training Image Accuracy: 0.93359375 Training Text Accuracy: 0.9296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 144 Training Loss: 6.9545126259326935 Training Image Accuracy: 0.92734375 Training Text Accuracy: 0.928125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 0 / 20 , Loss: tensor(0.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 145 Training Loss: 6.42474240064621 Training Image Accuracy: 0.94453125 Training Text Accuracy: 0.9375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 146 Training Loss: 6.000786632299423 Training Image Accuracy: 0.953125 Training Text Accuracy: 0.940625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 147 Training Loss: 6.230012863874435 Training Image Accuracy: 0.95 Training Text Accuracy: 0.940625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 148 Training Loss: 5.920455187559128 Training Image Accuracy: 0.95625 Training Text Accuracy: 0.95546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 18 / 20 , Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 149 Training Loss: 5.53597891330719 Training Image Accuracy: 0.959375 Training Text Accuracy: 0.9578125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 150 Training Loss: 5.273895889520645 Training Image Accuracy: 0.9671875 Training Text Accuracy: 0.959375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 151 Training Loss: 5.275139704346657 Training Image Accuracy: 0.96640625 Training Text Accuracy: 0.96171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 152 Training Loss: 7.041777238249779 Training Image Accuracy: 0.928125 Training Text Accuracy: 0.91953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 153 Training Loss: 8.197788178920746 Training Image Accuracy: 0.915625 Training Text Accuracy: 0.91171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2751, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 14 / 20 , Loss: tensor(0.4906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 154 Training Loss: 7.729954078793526 Training Image Accuracy: 0.91875 Training Text Accuracy: 0.9046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 155 Training Loss: 8.064703166484833 Training Image Accuracy: 0.8953125 Training Text Accuracy: 0.9046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 156 Training Loss: 7.448697656393051 Training Image Accuracy: 0.9171875 Training Text Accuracy: 0.9140625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 157 Training Loss: 7.4199003875255585 Training Image Accuracy: 0.92265625 Training Text Accuracy: 0.9234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 158 Training Loss: 6.985699146986008 Training Image Accuracy: 0.92734375 Training Text Accuracy: 0.93203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 10 / 20 , Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 159 Training Loss: 6.9561241418123245 Training Image Accuracy: 0.93125 Training Text Accuracy: 0.9234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 160 Training Loss: 6.896181404590607 Training Image Accuracy: 0.925 Training Text Accuracy: 0.91484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 161 Training Loss: 7.65509369969368 Training Image Accuracy: 0.909375 Training Text Accuracy: 0.9125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 162 Training Loss: 7.3972668051719666 Training Image Accuracy: 0.9265625 Training Text Accuracy: 0.92265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 163 Training Loss: 6.994050711393356 Training Image Accuracy: 0.9203125 Training Text Accuracy: 0.91796875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4184, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 6 / 20 , Loss: tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 164 Training Loss: 6.427640736103058 Training Image Accuracy: 0.93671875 Training Text Accuracy: 0.94375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 165 Training Loss: 6.357657343149185 Training Image Accuracy: 0.95078125 Training Text Accuracy: 0.94140625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 166 Training Loss: 6.351870492100716 Training Image Accuracy: 0.93984375 Training Text Accuracy: 0.92890625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 167 Training Loss: 5.9260080605745316 Training Image Accuracy: 0.9625 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 168 Training Loss: 5.678215280175209 Training Image Accuracy: 0.9546875 Training Text Accuracy: 0.9515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2246, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 2 / 20 , Loss: tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 169 Training Loss: 5.234369099140167 Training Image Accuracy: 0.96875 Training Text Accuracy: 0.9625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 170 Training Loss: 5.651178687810898 Training Image Accuracy: 0.94921875 Training Text Accuracy: 0.953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 171 Training Loss: 5.913329437375069 Training Image Accuracy: 0.95078125 Training Text Accuracy: 0.94296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 172 Training Loss: 7.107566088438034 Training Image Accuracy: 0.921875 Training Text Accuracy: 0.928125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 173 Training Loss: 7.675330609083176 Training Image Accuracy: 0.9078125 Training Text Accuracy: 0.91484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 174 Training Loss: 8.574270337820053 Training Image Accuracy: 0.89140625 Training Text Accuracy: 0.90234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 175 Training Loss: 8.216748833656311 Training Image Accuracy: 0.9 Training Text Accuracy: 0.89609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 176 Training Loss: 7.582324951887131 Training Image Accuracy: 0.9265625 Training Text Accuracy: 0.9171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 177 Training Loss: 6.840456575155258 Training Image Accuracy: 0.9359375 Training Text Accuracy: 0.934375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 17 / 20 , Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 178 Training Loss: 6.507686540484428 Training Image Accuracy: 0.94296875 Training Text Accuracy: 0.93515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 179 Training Loss: 8.513188004493713 Training Image Accuracy: 0.89140625 Training Text Accuracy: 0.8796875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 180 Training Loss: 8.021110981702805 Training Image Accuracy: 0.9078125 Training Text Accuracy: 0.9\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 181 Training Loss: 8.248488426208496 Training Image Accuracy: 0.896875 Training Text Accuracy: 0.89921875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 182 Training Loss: 7.9185143411159515 Training Image Accuracy: 0.90078125 Training Text Accuracy: 0.915625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 13 / 20 , Loss: tensor(0.3364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 183 Training Loss: 7.196863412857056 Training Image Accuracy: 0.9265625 Training Text Accuracy: 0.91953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 184 Training Loss: 6.801475137472153 Training Image Accuracy: 0.9390625 Training Text Accuracy: 0.928125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 185 Training Loss: 6.174927860498428 Training Image Accuracy: 0.940625 Training Text Accuracy: 0.94140625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 186 Training Loss: 5.786231890320778 Training Image Accuracy: 0.95390625 Training Text Accuracy: 0.940625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 187 Training Loss: 5.627827912569046 Training Image Accuracy: 0.9515625 Training Text Accuracy: 0.96640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 9 / 20 , Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 188 Training Loss: 5.670689582824707 Training Image Accuracy: 0.965625 Training Text Accuracy: 0.95078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 189 Training Loss: 5.698879063129425 Training Image Accuracy: 0.946875 Training Text Accuracy: 0.95\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 190 Training Loss: 6.580320104956627 Training Image Accuracy: 0.94296875 Training Text Accuracy: 0.93359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 191 Training Loss: 6.441608980298042 Training Image Accuracy: 0.94140625 Training Text Accuracy: 0.94375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 192 Training Loss: 6.044397100806236 Training Image Accuracy: 0.94921875 Training Text Accuracy: 0.9421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 5 / 20 , Loss: tensor(0.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 193 Training Loss: 6.504407435655594 Training Image Accuracy: 0.93046875 Training Text Accuracy: 0.925\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 194 Training Loss: 6.911913961172104 Training Image Accuracy: 0.9265625 Training Text Accuracy: 0.93671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 195 Training Loss: 6.881629914045334 Training Image Accuracy: 0.93515625 Training Text Accuracy: 0.93671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 196 Training Loss: 7.922683954238892 Training Image Accuracy: 0.91484375 Training Text Accuracy: 0.91015625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 197 Training Loss: 8.26278755068779 Training Image Accuracy: 0.9015625 Training Text Accuracy: 0.8984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(0.4029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 198 Training Loss: 7.0985448360443115 Training Image Accuracy: 0.93359375 Training Text Accuracy: 0.93203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 199 Training Loss: 6.460725739598274 Training Image Accuracy: 0.9359375 Training Text Accuracy: 0.9328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 200 Training Loss: 6.396704509854317 Training Image Accuracy: 0.93828125 Training Text Accuracy: 0.94296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 201 Training Loss: 5.657070636749268 Training Image Accuracy: 0.96171875 Training Text Accuracy: 0.959375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 202 Training Loss: 5.110813558101654 Training Image Accuracy: 0.96328125 Training Text Accuracy: 0.96328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.1914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 203 Training Loss: 5.418055832386017 Training Image Accuracy: 0.96640625 Training Text Accuracy: 0.95859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.1933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.1574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 204 Training Loss: 5.253872871398926 Training Image Accuracy: 0.96640625 Training Text Accuracy: 0.95859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.1833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 205 Training Loss: 4.984462305903435 Training Image Accuracy: 0.97109375 Training Text Accuracy: 0.96875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 206 Training Loss: 5.049774661660194 Training Image Accuracy: 0.97109375 Training Text Accuracy: 0.96015625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.1820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 207 Training Loss: 5.017581596970558 Training Image Accuracy: 0.97109375 Training Text Accuracy: 0.96640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 208 Training Loss: 5.756288900971413 Training Image Accuracy: 0.95703125 Training Text Accuracy: 0.9578125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 209 Training Loss: 5.8826591819524765 Training Image Accuracy: 0.95703125 Training Text Accuracy: 0.94296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 210 Training Loss: 6.349985480308533 Training Image Accuracy: 0.94375 Training Text Accuracy: 0.94296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 211 Training Loss: 7.063656702637672 Training Image Accuracy: 0.9234375 Training Text Accuracy: 0.93359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.1787, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 11 / 20 , Loss: tensor(2.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.7195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.5685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(8.9288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.1640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.9892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.8825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 212 Training Loss: 48.27712117135525 Training Image Accuracy: 0.48046875 Training Text Accuracy: 0.5609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(4.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(4.1972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.2815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(4.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.2243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.1718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(4.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.1765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.1828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.1609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.1598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.1604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 213 Training Loss: 83.82240581512451 Training Image Accuracy: 0.015625 Training Text Accuracy: 0.02265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(4.1523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.1521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(4.1551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.1456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(4.1392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.1467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.1486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(4.1132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.1408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.1206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.1005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.9896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 214 Training Loss: 82.53087139129639 Training Image Accuracy: 0.028125 Training Text Accuracy: 0.0375\n",
      "\tBatch: 0 / 20 , Loss: tensor(4.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.9853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.8797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(4.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.0595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.0417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.0073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.9469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.9745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.0238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.8537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.9599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.8766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.9233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.7420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.6410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 215 Training Loss: 79.26927876472473 Training Image Accuracy: 0.03203125 Training Text Accuracy: 0.05859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.8160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.9787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.5334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.6220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.6373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.4918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.6461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.5929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.6486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.5332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.7053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.7092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.1760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.3960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.2218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 216 Training Loss: 70.265780210495 Training Image Accuracy: 0.07890625 Training Text Accuracy: 0.09453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.9051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.9344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.8213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.4808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.9181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.9219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.8153, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 7 / 20 , Loss: tensor(3.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.6825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.9352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.8329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.7800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.8672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.7010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.6497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.5956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.7475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.3136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.7683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 217 Training Loss: 56.446017026901245 Training Image Accuracy: 0.1734375 Training Text Accuracy: 0.1859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.0003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.0438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.8933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.7019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.0679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.6254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.9461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.9350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.0062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.2409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.5742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.0322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 218 Training Loss: 40.88827097415924 Training Image Accuracy: 0.353125 Training Text Accuracy: 0.35625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.8396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.9822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.7721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.4941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.8724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.7128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.6687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.4330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.4608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.6149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.8361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.6753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.6440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.6533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.3988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 219 Training Loss: 31.230421900749207 Training Image Accuracy: 0.4875 Training Text Accuracy: 0.5015625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.9303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.1964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.0075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.9611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.0973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.9805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.0022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.0614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.1507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.9183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.2751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.4907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.9923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 220 Training Loss: 22.417936265468597 Training Image Accuracy: 0.62421875 Training Text Accuracy: 0.61328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.9907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.0041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.1705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.0028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 221 Training Loss: 17.432224571704865 Training Image Accuracy: 0.734375 Training Text Accuracy: 0.71875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8409, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 3 / 20 , Loss: tensor(0.7265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 222 Training Loss: 14.536067545413971 Training Image Accuracy: 0.7890625 Training Text Accuracy: 0.76953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.9015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 223 Training Loss: 12.506125688552856 Training Image Accuracy: 0.8203125 Training Text Accuracy: 0.825\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.9264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 224 Training Loss: 10.717293590307236 Training Image Accuracy: 0.87578125 Training Text Accuracy: 0.85859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 225 Training Loss: 8.521493077278137 Training Image Accuracy: 0.91328125 Training Text Accuracy: 0.91484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 226 Training Loss: 8.797222524881363 Training Image Accuracy: 0.9109375 Training Text Accuracy: 0.896875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 0 / 20 , Loss: tensor(0.3834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 227 Training Loss: 8.698912858963013 Training Image Accuracy: 0.9109375 Training Text Accuracy: 0.90859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 228 Training Loss: 9.031611382961273 Training Image Accuracy: 0.88828125 Training Text Accuracy: 0.8875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 229 Training Loss: 7.970955193042755 Training Image Accuracy: 0.9109375 Training Text Accuracy: 0.91640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 230 Training Loss: 6.296143516898155 Training Image Accuracy: 0.9515625 Training Text Accuracy: 0.946875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 18 / 20 , Loss: tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 231 Training Loss: 5.92060612142086 Training Image Accuracy: 0.9609375 Training Text Accuracy: 0.95625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 232 Training Loss: 5.700624942779541 Training Image Accuracy: 0.95703125 Training Text Accuracy: 0.95078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 233 Training Loss: 5.650655210018158 Training Image Accuracy: 0.9625 Training Text Accuracy: 0.95234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.1909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 234 Training Loss: 5.4611943662166595 Training Image Accuracy: 0.965625 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 235 Training Loss: 5.889995977282524 Training Image Accuracy: 0.95546875 Training Text Accuracy: 0.95234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 14 / 20 , Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.1698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 236 Training Loss: 5.243027314543724 Training Image Accuracy: 0.9671875 Training Text Accuracy: 0.96484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 237 Training Loss: 5.802104115486145 Training Image Accuracy: 0.94609375 Training Text Accuracy: 0.95703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.1944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.1883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 238 Training Loss: 5.475503638386726 Training Image Accuracy: 0.96171875 Training Text Accuracy: 0.95234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 239 Training Loss: 6.0403231382369995 Training Image Accuracy: 0.95 Training Text Accuracy: 0.95078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 240 Training Loss: 6.155581578612328 Training Image Accuracy: 0.95390625 Training Text Accuracy: 0.94375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 10 / 20 , Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 241 Training Loss: 5.899934649467468 Training Image Accuracy: 0.95703125 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 242 Training Loss: 6.138523623347282 Training Image Accuracy: 0.94375 Training Text Accuracy: 0.946875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 243 Training Loss: 6.830526769161224 Training Image Accuracy: 0.93203125 Training Text Accuracy: 0.93203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 244 Training Loss: 6.1581700295209885 Training Image Accuracy: 0.93984375 Training Text Accuracy: 0.95546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 245 Training Loss: 5.817418664693832 Training Image Accuracy: 0.953125 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 6 / 20 , Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 246 Training Loss: 5.90971602499485 Training Image Accuracy: 0.94140625 Training Text Accuracy: 0.94375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 247 Training Loss: 6.455378219485283 Training Image Accuracy: 0.9375 Training Text Accuracy: 0.94609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 248 Training Loss: 6.357629418373108 Training Image Accuracy: 0.9421875 Training Text Accuracy: 0.9359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 249 Training Loss: 6.3322650492191315 Training Image Accuracy: 0.94140625 Training Text Accuracy: 0.946875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.9032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.2265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.9741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.4065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.6837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(5.4904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.9498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 250 Training Loss: 22.78774981200695 Training Image Accuracy: 0.69375 Training Text Accuracy: 0.7734375\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.4344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.5329, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 2 / 20 , Loss: tensor(4.5205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.0244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(4.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.0368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.9199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.9780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.8589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.7102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.6509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.9971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.8201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.6670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.2217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.9762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.0046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 251 Training Loss: 80.46384143829346 Training Image Accuracy: 0.040625 Training Text Accuracy: 0.090625\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.8259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.9048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.6387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.6071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.7307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.4577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.5016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.3831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.4763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.5485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.0983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.8933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.3980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.0459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 252 Training Loss: 68.75758337974548 Training Image Accuracy: 0.07578125 Training Text Accuracy: 0.1203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.7639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.7375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.6150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.4691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.9201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.4875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.7123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.3712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.2457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.1326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.8874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.1583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.7318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.6607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.9866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 253 Training Loss: 48.30977666378021 Training Image Accuracy: 0.25078125 Training Text Accuracy: 0.31953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.0455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.9172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.0409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.8853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.8452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.8373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.6251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.6884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.4971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.9968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.0512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.4456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.7040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.7720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.8922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.6092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.5233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 254 Training Loss: 35.214967012405396 Training Image Accuracy: 0.440625 Training Text Accuracy: 0.4609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.1508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.4076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.4682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.9492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.0913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.8952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.2307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.5294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3522, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 255 Training Loss: 24.582185685634613 Training Image Accuracy: 0.59453125 Training Text Accuracy: 0.61640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.8492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.8226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.9054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 256 Training Loss: 17.33273947238922 Training Image Accuracy: 0.740625 Training Text Accuracy: 0.73671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6334, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 257 Training Loss: 12.716968446969986 Training Image Accuracy: 0.82265625 Training Text Accuracy: 0.8234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 258 Training Loss: 9.08710178732872 Training Image Accuracy: 0.8875 Training Text Accuracy: 0.8859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 259 Training Loss: 7.082450866699219 Training Image Accuracy: 0.92890625 Training Text Accuracy: 0.940625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5036, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 16 / 20 , Loss: tensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 260 Training Loss: 6.6929143369197845 Training Image Accuracy: 0.93515625 Training Text Accuracy: 0.94375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 261 Training Loss: 6.809238836169243 Training Image Accuracy: 0.93671875 Training Text Accuracy: 0.928125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 262 Training Loss: 6.280656069517136 Training Image Accuracy: 0.94609375 Training Text Accuracy: 0.94609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.1789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 263 Training Loss: 5.114010810852051 Training Image Accuracy: 0.96875 Training Text Accuracy: 0.96640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.1620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 264 Training Loss: 5.2217482924461365 Training Image Accuracy: 0.96953125 Training Text Accuracy: 0.96484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 12 / 20 , Loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 265 Training Loss: 4.917585492134094 Training Image Accuracy: 0.97421875 Training Text Accuracy: 0.97265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.1814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 266 Training Loss: 4.482448145747185 Training Image Accuracy: 0.9671875 Training Text Accuracy: 0.975\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.1986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.1893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.1769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.1609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 267 Training Loss: 4.239370748400688 Training Image Accuracy: 0.984375 Training Text Accuracy: 0.98359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 268 Training Loss: 5.077400773763657 Training Image Accuracy: 0.96328125 Training Text Accuracy: 0.95703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 269 Training Loss: 4.920115247368813 Training Image Accuracy: 0.96796875 Training Text Accuracy: 0.96875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 8 / 20 , Loss: tensor(0.2064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 270 Training Loss: 5.410077288746834 Training Image Accuracy: 0.96171875 Training Text Accuracy: 0.9671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 271 Training Loss: 5.2667622566223145 Training Image Accuracy: 0.96640625 Training Text Accuracy: 0.95859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 272 Training Loss: 5.552633762359619 Training Image Accuracy: 0.9546875 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 273 Training Loss: 5.322703838348389 Training Image Accuracy: 0.96171875 Training Text Accuracy: 0.9578125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 274 Training Loss: 5.418655127286911 Training Image Accuracy: 0.9625 Training Text Accuracy: 0.95859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3655, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 4 / 20 , Loss: tensor(0.3416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 275 Training Loss: 5.506629645824432 Training Image Accuracy: 0.9578125 Training Text Accuracy: 0.9609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2972, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 276 Training Loss: 5.8676324635744095 Training Image Accuracy: 0.95234375 Training Text Accuracy: 0.9546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 277 Training Loss: 5.933761566877365 Training Image Accuracy: 0.9453125 Training Text Accuracy: 0.9453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 278 Training Loss: 6.029778942465782 Training Image Accuracy: 0.95078125 Training Text Accuracy: 0.94765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 279 Training Loss: 5.558245524764061 Training Image Accuracy: 0.96171875 Training Text Accuracy: 0.95703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 280 Training Loss: 5.209601283073425 Training Image Accuracy: 0.9609375 Training Text Accuracy: 0.95625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 281 Training Loss: 5.932231441140175 Training Image Accuracy: 0.9484375 Training Text Accuracy: 0.9453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 282 Training Loss: 6.371746897697449 Training Image Accuracy: 0.9390625 Training Text Accuracy: 0.93359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 283 Training Loss: 6.811544761061668 Training Image Accuracy: 0.934375 Training Text Accuracy: 0.93671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4050, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.4641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 284 Training Loss: 6.6953441351652145 Training Image Accuracy: 0.94765625 Training Text Accuracy: 0.934375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 285 Training Loss: 5.957189828157425 Training Image Accuracy: 0.95 Training Text Accuracy: 0.9453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.1818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 286 Training Loss: 6.140166535973549 Training Image Accuracy: 0.94296875 Training Text Accuracy: 0.9515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 287 Training Loss: 6.416626751422882 Training Image Accuracy: 0.93828125 Training Text Accuracy: 0.9359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3849, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 288 Training Loss: 6.886013776063919 Training Image Accuracy: 0.9265625 Training Text Accuracy: 0.93671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3286, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 289 Training Loss: 6.413113087415695 Training Image Accuracy: 0.9421875 Training Text Accuracy: 0.93515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 290 Training Loss: 7.105962589383125 Training Image Accuracy: 0.925 Training Text Accuracy: 0.92265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 291 Training Loss: 6.30231973528862 Training Image Accuracy: 0.9421875 Training Text Accuracy: 0.9359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 292 Training Loss: 6.324008524417877 Training Image Accuracy: 0.946875 Training Text Accuracy: 0.94453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 293 Training Loss: 5.60889507830143 Training Image Accuracy: 0.965625 Training Text Accuracy: 0.95078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 12 / 20 , Loss: tensor(0.2464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 294 Training Loss: 5.8891371339559555 Training Image Accuracy: 0.95234375 Training Text Accuracy: 0.9515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.1823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 295 Training Loss: 6.006823718547821 Training Image Accuracy: 0.946875 Training Text Accuracy: 0.9453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 296 Training Loss: 5.581831678748131 Training Image Accuracy: 0.9578125 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 297 Training Loss: 5.377994477748871 Training Image Accuracy: 0.96015625 Training Text Accuracy: 0.95859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 298 Training Loss: 6.185590088367462 Training Image Accuracy: 0.94453125 Training Text Accuracy: 0.94296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2318, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 8 / 20 , Loss: tensor(0.4106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 299 Training Loss: 5.4737347066402435 Training Image Accuracy: 0.953125 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 300 Training Loss: 5.779371619224548 Training Image Accuracy: 0.9546875 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.1956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 301 Training Loss: 5.4375045001506805 Training Image Accuracy: 0.95859375 Training Text Accuracy: 0.9625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 302 Training Loss: 5.940388441085815 Training Image Accuracy: 0.93984375 Training Text Accuracy: 0.9484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 303 Training Loss: 5.77705205976963 Training Image Accuracy: 0.95390625 Training Text Accuracy: 0.95625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3243, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 4 / 20 , Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 304 Training Loss: 5.433950260281563 Training Image Accuracy: 0.959375 Training Text Accuracy: 0.9609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 305 Training Loss: 5.470205098390579 Training Image Accuracy: 0.9609375 Training Text Accuracy: 0.9671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 306 Training Loss: 6.914472654461861 Training Image Accuracy: 0.93984375 Training Text Accuracy: 0.93125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.7754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.5970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.8029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.5773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.5760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 307 Training Loss: 19.25372701883316 Training Image Accuracy: 0.690625 Training Text Accuracy: 0.78046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.8278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.9150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.9784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.5842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.8012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.5323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.6898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.3584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(4.3441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.9382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.1666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.0299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.0548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.9861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.9961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 308 Training Loss: 79.03072953224182 Training Image Accuracy: 0.0453125 Training Text Accuracy: 0.15078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.9570, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(3.8755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.8560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.7990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.8276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.7310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.8039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.7336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.8167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.6773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.7335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.6951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.7102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.7079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.6171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.7141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.5562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.5496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 309 Training Loss: 74.59440612792969 Training Image Accuracy: 0.06328125 Training Text Accuracy: 0.034375\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.5963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.4339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.1391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.9400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.6558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.3277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.4038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.9870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.5517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.9388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.9166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.8668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.8866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.9537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 310 Training Loss: 64.81351852416992 Training Image Accuracy: 0.10078125 Training Text Accuracy: 0.14453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.8478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.3350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.5909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.3788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.5775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.5446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.3480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.5446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.5961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.7438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.8451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.3770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 311 Training Loss: 50.33903956413269 Training Image Accuracy: 0.23671875 Training Text Accuracy: 0.2515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.3483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.9488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.0500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.9859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.9629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.5986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.9910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.9815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.3012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.7410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.6885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.7667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.7974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.9040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 312 Training Loss: 40.91563856601715 Training Image Accuracy: 0.33671875 Training Text Accuracy: 0.38203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.3638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.6742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.6398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.6507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.5307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.4345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.7517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.2869, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.0259, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.8527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 313 Training Loss: 27.56222265958786 Training Image Accuracy: 0.54453125 Training Text Accuracy: 0.55859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.9883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.1070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.9903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.0511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.9568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.8446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.9020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.9102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 314 Training Loss: 18.70205909013748 Training Image Accuracy: 0.70625 Training Text Accuracy: 0.715625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6121, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 315 Training Loss: 13.776865124702454 Training Image Accuracy: 0.78984375 Training Text Accuracy: 0.7953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4317, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 316 Training Loss: 10.624832540750504 Training Image Accuracy: 0.85859375 Training Text Accuracy: 0.8765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 317 Training Loss: 9.033870816230774 Training Image Accuracy: 0.903125 Training Text Accuracy: 0.8984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3249, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 318 Training Loss: 7.2614395916461945 Training Image Accuracy: 0.92734375 Training Text Accuracy: 0.9265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 319 Training Loss: 5.757296666502953 Training Image Accuracy: 0.96484375 Training Text Accuracy: 0.9515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 320 Training Loss: 5.295009538531303 Training Image Accuracy: 0.9671875 Training Text Accuracy: 0.96171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 321 Training Loss: 5.339951276779175 Training Image Accuracy: 0.9578125 Training Text Accuracy: 0.96015625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 322 Training Loss: 5.226932927966118 Training Image Accuracy: 0.9640625 Training Text Accuracy: 0.96640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.1913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 11 / 20 , Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 323 Training Loss: 5.530177861452103 Training Image Accuracy: 0.9578125 Training Text Accuracy: 0.95625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2401, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 324 Training Loss: 4.890350595116615 Training Image Accuracy: 0.97578125 Training Text Accuracy: 0.971875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2287, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 325 Training Loss: 5.29090142250061 Training Image Accuracy: 0.96484375 Training Text Accuracy: 0.9625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 326 Training Loss: 5.279092505574226 Training Image Accuracy: 0.959375 Training Text Accuracy: 0.959375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.1999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3256, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 327 Training Loss: 5.439753279089928 Training Image Accuracy: 0.96171875 Training Text Accuracy: 0.95625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 8 / 20 , Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 328 Training Loss: 5.108148410916328 Training Image Accuracy: 0.971875 Training Text Accuracy: 0.96875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 329 Training Loss: 5.096533298492432 Training Image Accuracy: 0.97109375 Training Text Accuracy: 0.97109375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.1994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 330 Training Loss: 5.182024955749512 Training Image Accuracy: 0.96796875 Training Text Accuracy: 0.9578125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 331 Training Loss: 5.512126386165619 Training Image Accuracy: 0.94921875 Training Text Accuracy: 0.95234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 332 Training Loss: 5.469406798481941 Training Image Accuracy: 0.96328125 Training Text Accuracy: 0.953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1961, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 4 / 20 , Loss: tensor(0.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 333 Training Loss: 5.596647217869759 Training Image Accuracy: 0.96328125 Training Text Accuracy: 0.9609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 334 Training Loss: 5.914896711707115 Training Image Accuracy: 0.95546875 Training Text Accuracy: 0.946875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.1990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4664, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 335 Training Loss: 5.848522424697876 Training Image Accuracy: 0.94921875 Training Text Accuracy: 0.95703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3394, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2678, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 336 Training Loss: 5.972303599119186 Training Image Accuracy: 0.9484375 Training Text Accuracy: 0.95\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 337 Training Loss: 5.8804771900177 Training Image Accuracy: 0.94296875 Training Text Accuracy: 0.95625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2291, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 338 Training Loss: 5.770310565829277 Training Image Accuracy: 0.95 Training Text Accuracy: 0.9515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 339 Training Loss: 6.094231948256493 Training Image Accuracy: 0.94609375 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 340 Training Loss: 6.366200655698776 Training Image Accuracy: 0.9375 Training Text Accuracy: 0.9375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 341 Training Loss: 6.280235275626183 Training Image Accuracy: 0.94453125 Training Text Accuracy: 0.9390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 342 Training Loss: 5.850981384515762 Training Image Accuracy: 0.94921875 Training Text Accuracy: 0.94765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.1802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.1924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 343 Training Loss: 5.79805463552475 Training Image Accuracy: 0.95 Training Text Accuracy: 0.93671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 344 Training Loss: 5.9001200795173645 Training Image Accuracy: 0.94296875 Training Text Accuracy: 0.9453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.1651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 345 Training Loss: 5.860708802938461 Training Image Accuracy: 0.9515625 Training Text Accuracy: 0.95703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2195, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 346 Training Loss: 5.91571968793869 Training Image Accuracy: 0.94921875 Training Text Accuracy: 0.94921875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 347 Training Loss: 5.758801087737083 Training Image Accuracy: 0.95859375 Training Text Accuracy: 0.95234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3593, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 348 Training Loss: 6.264426976442337 Training Image Accuracy: 0.93203125 Training Text Accuracy: 0.9359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3777, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 349 Training Loss: 5.956799417734146 Training Image Accuracy: 0.94921875 Training Text Accuracy: 0.95078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 350 Training Loss: 5.552332729101181 Training Image Accuracy: 0.9625 Training Text Accuracy: 0.9578125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 351 Training Loss: 6.174888163805008 Training Image Accuracy: 0.9375 Training Text Accuracy: 0.9390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 11 / 20 , Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 352 Training Loss: 5.590696960687637 Training Image Accuracy: 0.9625 Training Text Accuracy: 0.95703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 353 Training Loss: 6.205193594098091 Training Image Accuracy: 0.94140625 Training Text Accuracy: 0.9453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 354 Training Loss: 6.236937761306763 Training Image Accuracy: 0.94765625 Training Text Accuracy: 0.9421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 355 Training Loss: 6.250604525208473 Training Image Accuracy: 0.946875 Training Text Accuracy: 0.940625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 356 Training Loss: 5.9553515911102295 Training Image Accuracy: 0.953125 Training Text Accuracy: 0.946875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2931, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3651, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4615, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 7 / 20 , Loss: tensor(0.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 357 Training Loss: 6.793428331613541 Training Image Accuracy: 0.92578125 Training Text Accuracy: 0.91875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 358 Training Loss: 6.004325821995735 Training Image Accuracy: 0.95078125 Training Text Accuracy: 0.9515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 359 Training Loss: 5.39365741610527 Training Image Accuracy: 0.96171875 Training Text Accuracy: 0.9609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2702, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 360 Training Loss: 5.518461912870407 Training Image Accuracy: 0.9546875 Training Text Accuracy: 0.95859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 361 Training Loss: 6.1669580191373825 Training Image Accuracy: 0.94609375 Training Text Accuracy: 0.9484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2193, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 3 / 20 , Loss: tensor(0.3167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 362 Training Loss: 6.862395644187927 Training Image Accuracy: 0.9328125 Training Text Accuracy: 0.9359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3283, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 363 Training Loss: 7.636890858411789 Training Image Accuracy: 0.9125 Training Text Accuracy: 0.91875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.1062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.8494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.5415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.4882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.0301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.6468, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.6599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.5657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 364 Training Loss: 59.43992060422897 Training Image Accuracy: 0.23125 Training Text Accuracy: 0.35546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(4.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(4.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(4.1146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.1167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.0438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.0191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(4.0276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.9363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.0241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.9472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.8870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.8851, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.8720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.8158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.8478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.8860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.8759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 365 Training Loss: 79.88024592399597 Training Image Accuracy: 0.02421875 Training Text Accuracy: 0.03828125\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.6175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.5515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.5001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.5574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.5272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.9720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.7524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(4.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.0189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.8936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.9322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.8723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.8285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.8137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.8362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.7929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.8147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.8949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 366 Training Loss: 76.74000978469849 Training Image Accuracy: 0.04375 Training Text Accuracy: 0.05390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.6042, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(3.6954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.6370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.6144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.5573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.6161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.5553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.5603, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.4967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.5380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.5679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.6807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.6050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.5231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.7301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.6087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.6779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.5182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.4519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.5885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 367 Training Loss: 71.82673859596252 Training Image Accuracy: 0.05546875 Training Text Accuracy: 0.06484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.5203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.5704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.6717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.3804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.8982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.4806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.8545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.4712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.7351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.5486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.5917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.7011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.6754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.5118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.5227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.7816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.9010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 368 Training Loss: 72.00270628929138 Training Image Accuracy: 0.05859375 Training Text Accuracy: 0.1078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.4974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.6818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.6072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.4436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.6794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.4993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.6002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.3054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.0477, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.0435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.1941, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.7101, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.7820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.7545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 369 Training Loss: 65.58798742294312 Training Image Accuracy: 0.0953125 Training Text Accuracy: 0.165625\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.4360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.2459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.9022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.0435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.8669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.5215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.4525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.6135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.3810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.3465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.2755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.2081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.1217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.0807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 370 Training Loss: 47.86731243133545 Training Image Accuracy: 0.27109375 Training Text Accuracy: 0.31484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.8353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.9155, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.8172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.7959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.6238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.6590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.9555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.8375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.7783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.8807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.0414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.0759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.7759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.7265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.7880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.8803, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(2.1982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 371 Training Loss: 37.58425962924957 Training Image Accuracy: 0.3890625 Training Text Accuracy: 0.41640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.8844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.2962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.6054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.9526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.7711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.9097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.8955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.7179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.7078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.7205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.8138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.7190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.7685, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.7419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.5646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.7707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.7837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.7907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 372 Training Loss: 34.648738503456116 Training Image Accuracy: 0.40390625 Training Text Accuracy: 0.42734375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.5646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.5430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.5415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.4454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.3675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.9291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.4612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.3351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.6307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.5396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.5556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 373 Training Loss: 29.309025764465332 Training Image Accuracy: 0.515625 Training Text Accuracy: 0.5375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.1295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.0625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.2586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.9566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0716, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.0514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.0637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.2379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.0140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.9240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 374 Training Loss: 22.38148558139801 Training Image Accuracy: 0.6328125 Training Text Accuracy: 0.64765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.1506, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.8952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.1233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.1336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.0714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.1311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.0074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.0339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.0428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.9281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.0390, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 375 Training Loss: 20.084170758724213 Training Image Accuracy: 0.68203125 Training Text Accuracy: 0.68359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.9516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(0.7370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 376 Training Loss: 14.782808423042297 Training Image Accuracy: 0.77265625 Training Text Accuracy: 0.7765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6016, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 377 Training Loss: 12.174463093280792 Training Image Accuracy: 0.8453125 Training Text Accuracy: 0.8375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 378 Training Loss: 10.87069508433342 Training Image Accuracy: 0.86015625 Training Text Accuracy: 0.8484375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 379 Training Loss: 9.383799403905869 Training Image Accuracy: 0.89375 Training Text Accuracy: 0.89765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2885, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 380 Training Loss: 8.133315175771713 Training Image Accuracy: 0.91953125 Training Text Accuracy: 0.9265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4273, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 11 / 20 , Loss: tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 381 Training Loss: 7.646836161613464 Training Image Accuracy: 0.9296875 Training Text Accuracy: 0.921875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 382 Training Loss: 8.120483219623566 Training Image Accuracy: 0.90390625 Training Text Accuracy: 0.9234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2987, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 383 Training Loss: 7.12715008854866 Training Image Accuracy: 0.934375 Training Text Accuracy: 0.934375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2617, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 384 Training Loss: 6.534230649471283 Training Image Accuracy: 0.9421875 Training Text Accuracy: 0.9421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 385 Training Loss: 5.990648075938225 Training Image Accuracy: 0.95703125 Training Text Accuracy: 0.94609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 7 / 20 , Loss: tensor(0.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 386 Training Loss: 5.957704141736031 Training Image Accuracy: 0.95234375 Training Text Accuracy: 0.9546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.1963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 387 Training Loss: 5.612989857792854 Training Image Accuracy: 0.96015625 Training Text Accuracy: 0.96328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4020, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 388 Training Loss: 5.669856578111649 Training Image Accuracy: 0.9578125 Training Text Accuracy: 0.953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2186, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3551, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 389 Training Loss: 5.660818725824356 Training Image Accuracy: 0.96484375 Training Text Accuracy: 0.9515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.1998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 390 Training Loss: 6.6796653270721436 Training Image Accuracy: 0.93984375 Training Text Accuracy: 0.93671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 3 / 20 , Loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 391 Training Loss: 6.364782005548477 Training Image Accuracy: 0.94453125 Training Text Accuracy: 0.94296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3352, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 392 Training Loss: 5.5482238084077835 Training Image Accuracy: 0.96015625 Training Text Accuracy: 0.96328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4667, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3811, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3901, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 393 Training Loss: 6.348737850785255 Training Image Accuracy: 0.9359375 Training Text Accuracy: 0.93359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2908, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.1946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4241, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 394 Training Loss: 6.358793348073959 Training Image Accuracy: 0.93828125 Training Text Accuracy: 0.93984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2779, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 395 Training Loss: 5.66944332420826 Training Image Accuracy: 0.9578125 Training Text Accuracy: 0.95546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(0.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 396 Training Loss: 6.234319493174553 Training Image Accuracy: 0.93828125 Training Text Accuracy: 0.940625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 397 Training Loss: 6.651303023099899 Training Image Accuracy: 0.94296875 Training Text Accuracy: 0.940625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2745, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3371, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 398 Training Loss: 6.0796734392642975 Training Image Accuracy: 0.94296875 Training Text Accuracy: 0.94609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2698, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 399 Training Loss: 5.40793089568615 Training Image Accuracy: 0.96015625 Training Text Accuracy: 0.965625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3019, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 400 Training Loss: 5.845359832048416 Training Image Accuracy: 0.95234375 Training Text Accuracy: 0.94296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 401 Training Loss: 6.631952151656151 Training Image Accuracy: 0.92578125 Training Text Accuracy: 0.9328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 402 Training Loss: 7.389008730649948 Training Image Accuracy: 0.91953125 Training Text Accuracy: 0.9171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 403 Training Loss: 7.358183920383453 Training Image Accuracy: 0.92109375 Training Text Accuracy: 0.92265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 404 Training Loss: 7.47041779756546 Training Image Accuracy: 0.9234375 Training Text Accuracy: 0.9140625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3435, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(0.3539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 405 Training Loss: 6.1618459820747375 Training Image Accuracy: 0.94140625 Training Text Accuracy: 0.94453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3205, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 406 Training Loss: 5.63444285094738 Training Image Accuracy: 0.95546875 Training Text Accuracy: 0.95546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3476, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 407 Training Loss: 6.435737609863281 Training Image Accuracy: 0.9390625 Training Text Accuracy: 0.92890625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3796, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 408 Training Loss: 5.550172582268715 Training Image Accuracy: 0.953125 Training Text Accuracy: 0.9625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.1895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.1974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 409 Training Loss: 5.823518052697182 Training Image Accuracy: 0.946875 Training Text Accuracy: 0.94765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2545, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 11 / 20 , Loss: tensor(0.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 410 Training Loss: 5.435997620224953 Training Image Accuracy: 0.96484375 Training Text Accuracy: 0.95390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2571, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 411 Training Loss: 5.944792702794075 Training Image Accuracy: 0.95 Training Text Accuracy: 0.9515625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 412 Training Loss: 6.19873183965683 Training Image Accuracy: 0.94375 Training Text Accuracy: 0.95234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.2992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 413 Training Loss: 6.011993318796158 Training Image Accuracy: 0.94921875 Training Text Accuracy: 0.94609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.1773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.2526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.2421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4018, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-980a6d124ad1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_clip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-aaecc5b5f9d3>\u001b[0m in \u001b[0;36mtrain_clip\u001b[1;34m(model, text_samples, image_samples, batch_size, num_epochs, lr, temp, clip_value)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#             torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_clip(clip_model, train_text, train_images, batch_size=64, lr=1e-4, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for alpha in (1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9):\n",
    "#     print(\"Alpha:\", alpha)\n",
    "#     clip_model = CLIP(\n",
    "#         embed_dim,\n",
    "#         image_resolution, (2,2,2,2), 64,\n",
    "#         16, vocab_size, transformer_width, transformer_heads, transformer_layers\n",
    "#     ).to(device)\n",
    "#     train_clip(clip_model, train_text, train_images, batch_size=64, lr=alpha, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
