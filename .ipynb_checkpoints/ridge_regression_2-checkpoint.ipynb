{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eO1tSqzp8YE"
   },
   "source": [
    "This file contains the implementation of ridge (L2) regression for mapping fMRI embeddings to CLIP and word2vec embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d14zQ3DZq6MK"
   },
   "source": [
    "First setup baseline model (word2vec) (Not yet implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT4mOgANq4sG",
    "outputId": "da6cf362-0555-454c-8199-8c5feabb7ffb"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# semeval-2016-2017-task3-subtaskA-unannotated\n",
    "model = api.load(\"glove-twitter-25\")  # download the model and return as object ready for use\n",
    "# model.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "GahCiBSmdpZc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import nibabel as nib\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "# from google.colab import drive\n",
    "\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z63hCATpLLOt",
    "outputId": "b6eba5ad-53b3-4753-d60a-a774b16e59c8"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n",
    "fMRI_folder = Path('./doi_10.5061_dryad.gt413__v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1SWm20pKzuU",
    "outputId": "0b848180-1242-48c4-c82d-06e6e80349b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 0\n",
      "Subject: 1\n",
      "Subject: 2\n",
      "Subject: 3\n",
      "Subject: 4\n",
      "Subject: 5\n",
      "Subject: 6\n",
      "Subject: 7\n"
     ]
    }
   ],
   "source": [
    "NUM_SUBJS = 8\n",
    "subjects_fmri = [] #stores all 8 subject fmri np arrays\n",
    "\n",
    "# fMRI_folder = Path('./doi_10.5061_dryad.gt413__v1')\n",
    "# assert fMRI_folder.exists(), f\"Foldder: {fMRI_folder} does not exist.\"\n",
    "\n",
    "for subj_id in range(8):\n",
    "    print(\"Subject:\",subj_id)\n",
    "#     fmri_file_name = str(subj_id) + '_masked_2d.npy'\n",
    "#     fmri = np.load(fMRI_folder / fmri_file_name)\n",
    "    fmri_file_name = str(subj_id) + '_smooth_nifti_4d.nii'\n",
    "    fmri = nib.load(fMRI_folder / fmri_file_name)\n",
    "    fmri = np.array(fmri.dataobj)\n",
    "    assert isinstance(fmri, np.ndarray), f\"Imported fmri_scan for subject {subj_id} is not of type numpy.ndarray\"\n",
    "    assert(fmri.ndim) == 4, f\"Imported fmri_scan for subject {subj_id} is not 4 dimensional\"\n",
    "    subjects_fmri.append(fmri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(subjects_fmri) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBZTp5VgVEom",
    "outputId": "dfe79b3d-f7d0-4b42-c69b-6a7635586ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n"
     ]
    }
   ],
   "source": [
    "for x in subjects_fmri:\n",
    "    print(np.shape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 60 50\n",
      "51 60 49\n",
      "53 59 47\n",
      "53 59 44\n",
      "51 59 45\n",
      "49 56 51\n",
      "52 60 49\n",
      "52 60 48\n"
     ]
    }
   ],
   "source": [
    "mat_files = sorted(list(fMRI_folder.glob('subject_*.mat')))\n",
    "sub_num = 0\n",
    "matrices = []\n",
    "for file in mat_files:\n",
    "    mat_contents = sio.loadmat(file)\n",
    "    matrix = np.zeros((np.shape(subjects_fmri[sub_num])[3],mat_contents[\"meta\"][0][0][2][0][0],))\n",
    "    fmri = subjects_fmri[int(str(file)[-5])-1]\n",
    "    #print(np.shape(fmri))\n",
    "    #print(mat_contents[\"meta\"])\n",
    "\n",
    "    print(mat_contents[\"meta\"][0][0][3][0][0],mat_contents[\"meta\"][0][0][4][0][0],mat_contents[\"meta\"][0][0][5][0][0])\n",
    "    for x in range(mat_contents[\"meta\"][0][0][3][0][0]):\n",
    "        for y in range(mat_contents[\"meta\"][0][0][4][0][0]):\n",
    "            for z in range(mat_contents[\"meta\"][0][0][5][0][0]):\n",
    "                col = mat_contents[\"meta\"][0][0][7][x][y][z]\n",
    "                matrix[:,col] = fmri[x-1][y-1][z-1][:]\n",
    "    matrices.append(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "HKm-vOaOJwZH"
   },
   "outputs": [],
   "source": [
    "feature_matrix = np.zeros((5176,195)) #stores the feature vectors as a row for each word\n",
    "feature_names = [] #stores the names of all features in order\n",
    "feature_types = {} #stores the types of features and all the names of the features for each type\n",
    "\n",
    "features = sio.loadmat(fMRI_folder/'story_features.mat')\n",
    "feature_count = 0\n",
    "for feature_type in features['features'][0]:\n",
    "    feature_types[feature_type[0][0]] = []\n",
    "    if isinstance(feature_type[1][0], str):\n",
    "        feature_types[feature_type[0][0]].append(feature_type[1][0])\n",
    "        feature_names.append(feature_type[1][0])\n",
    "    else:\n",
    "        for feature in feature_type[1][0]:\n",
    "            feature_types[feature_type[0][0]].append(feature[0])\n",
    "            feature_names.append(feature[0])\n",
    "    feature_matrix[:, feature_count:feature_count+feature_type[2].shape[1]] = feature_type[2] #adds the (5176xN) feature values to the feature matrix for the current feature group\n",
    "    feature_count += feature_type[2].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "9Ks5wTcKJmjz"
   },
   "outputs": [],
   "source": [
    "words_info = [] #stores tuples of (word, time, features) sorted by time appeared\n",
    "\n",
    "mat_file = 'subject_1.mat' #only looks at the first subject file, somewhere it said all the timings were the same so this should be safe\n",
    "mat_contents = sio.loadmat(fMRI_folder/mat_file)\n",
    "# print(mat_content)\n",
    "for count, row in enumerate(mat_contents['words'][0]):\n",
    "    word_value = row[0][0][0][0]\n",
    "    time = row[1][0][0]\n",
    "    \n",
    "    word_tuple = (word_value, time, feature_matrix[count,:])\n",
    "    words_info.append(word_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DP3j_XQJnJR",
    "outputId": "094873e7-c700-4223-84ae-087150e3f246"
   },
   "outputs": [],
   "source": [
    "chapter_nine_text = \"\"\n",
    "for row in mat_contents['words'][0]:\n",
    "    chapter_nine_text += row[0][0][0][0] + \" \"\n",
    "# print(chapter_nine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjvOavtmUsTG",
    "outputId": "a69f8cd4-dd3c-47be-99a2-b1fcfdf391de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (53, 60, 50, 1311)\n",
      "1 (53, 60, 50, 1311)\n",
      "2 (53, 60, 50, 1311)\n",
      "3 (53, 60, 50, 1311)\n",
      "4 (53, 60, 50, 1311)\n",
      "5 (53, 60, 50, 1311)\n",
      "6 (53, 60, 50, 1311)\n",
      "7 (53, 60, 50, 1311)\n"
     ]
    }
   ],
   "source": [
    "for count, subject in enumerate(subjects_fmri):\n",
    "    print(count, np.shape(subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fmri_indices', 'rb') as f:\n",
    "    fmri_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muTykRqfJcpY"
   },
   "source": [
    "Harrison's implementation of Gaussian weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "FOE-RCeGJcNV"
   },
   "outputs": [],
   "source": [
    "def hrf_alignment(num_words, words_info, NUM_SUBJS, subjects_fmri):\n",
    "\n",
    "    subjects_samples = [[] for i in range(NUM_SUBJS)] #stores lists of all the samples for each subject\n",
    "    window = signal.windows.gaussian(16, std=1) #gaussian window for the 4 fMRI scans\n",
    "    num_words = num_words\n",
    "    word_count = 0\n",
    "    while word_count < len(words_info) - 24:\n",
    "        #gets the 4 input words, and the 4 consecutive words while verifying they were read in sequence\n",
    "        scan_words = []\n",
    "        start_time = words_info[word_count][1]\n",
    "        in_sequence = True #tracks if the words are in sequence or not\n",
    "        for i in range(num_words):\n",
    "            word_info = words_info[word_count + i]\n",
    "            if word_info[1] != start_time + 0.5*i:\n",
    "                #if some of the words are not in sequence, skip forward 1 word after innter loop\n",
    "                in_sequence = False\n",
    "            scan_words.append(word_info[0])\n",
    "        if not in_sequence:\n",
    "            word_count +=1\n",
    "            continue\n",
    "        fmri_time = start_time #fMRI is taken at first word read\n",
    "        fmri_index = fmri_time//2 #since a scan happens every two seconds, the index is the time divided by 2\n",
    "        if not np.issubdtype(fmri_index, np.integer):\n",
    "            #if the first word is not aligned with the fmri scan (i.e. its not the first word in a TR)\n",
    "            word_count += 1\n",
    "            continue\n",
    "        break_found = False\n",
    "        for count, subject in enumerate(subjects_fmri):\n",
    "#             print(\"Subject:\",count)\n",
    "            #adds tuple of (fmri_scan, four words)\n",
    "            for i in range(num_words): #time delay of reading word after fMRI scan\n",
    "                delay = 0.5*i #delay after first word\n",
    "                for j in range(1,5): #get next 4 fMRI scans\n",
    "                    fMRI_delay = 2*j - delay #delay until jth next fMRI scan\n",
    "                    weight = window[int(2*fMRI_delay)-1] #gets the gaussian weighting (16 points instead of 8 to allow for .5)\n",
    "                    try:\n",
    "                        curr_fmri_idx = fmri_indices.index((start_time + math.floor(i/4) + 2*j)//2) #gets the index of the jth next fMRI scan\n",
    "                    except:\n",
    "#                         print(\"break found at index:\",(start_time + math.floor(i/4) + 2*j)//2)\n",
    "                        break_found = True\n",
    "                        break\n",
    "                    #adds weight fMRI scan\n",
    "                    if j == 1:\n",
    "                        word_scan = weight*subject[:][curr_fmri_idx]\n",
    "                    else:\n",
    "                        word_scan += weight*subject[:][curr_fmri_idx]\n",
    "                if break_found:\n",
    "                    break\n",
    "                if i == 0:\n",
    "                    summed_weighted_scans = word_scan\n",
    "                else:\n",
    "                    summed_weighted_scans += word_scan\n",
    "            if break_found:\n",
    "                break\n",
    "            subjects_samples[count].append((summed_weighted_scans/num_words, scan_words))\n",
    "        if break_found:\n",
    "            word_count += 1\n",
    "            continue \n",
    "#         print(\"Created sample:\")\n",
    "#         print(\"\\tScan time:\", str(start_time))\n",
    "#         print(\"\\tInput words:\", str(scan_words))\n",
    "        #if successful, skip forward to the next set of 4 words\n",
    "        word_count += 4\n",
    "    return subjects_samples\n",
    "\n",
    "    print(\"Total number of samples:\", str(len(subjects_samples[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "hDooPY-xnS96"
   },
   "outputs": [],
   "source": [
    "def get_fMRI_embedding(subjects_samples):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    flattened_shape = reduce(np.multiply, subjects_samples[0][0].shape)\n",
    "    X_matrix = np.zeros((len(subjects_samples), flattened_shape))\n",
    "\n",
    "    for idx, sample in enumerate(subjects_samples):\n",
    "        tmp = sample[0]\n",
    "        # Reshape the voxels \n",
    "        tmp = tmp.ravel()\n",
    "        X_matrix[idx,:] = tmp\n",
    "        \n",
    "    # Apply voxelwise standardization        \n",
    "    X_matrix = scaler.fit_transform(X_matrix)\n",
    "    print(np.shape(X_matrix))\n",
    "    return X_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "ZoeD2JzgXvSY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BERT_embedding(subject_sample):\n",
    "    marked_text = \"[CLS] \"\n",
    "    word_list = []\n",
    "    context_length = 0\n",
    "\n",
    "    for i in range(len(subject_sample)):\n",
    "        context_length = len(subject_sample[i][1])\n",
    "        word_list.append(subject_sample[i][1])\n",
    "    new_word_list = [(' '.join(sublist)+\" [SEP]\") for sublist in word_list]\n",
    "    print(context_length)\n",
    "\n",
    "    list_embeds = []\n",
    "    for x in range(0,len(new_word_list),512//(context_length*2)):\n",
    "        segment_ids = []\n",
    "        lengths = []\n",
    "        up_to = min(x+512//(context_length*2),len(new_word_list))\n",
    "        for y in range(x,up_to):\n",
    "            lengths.append(len(tokenizer.tokenize(new_word_list[y])))\n",
    "        #print(lengths)\n",
    "        marked_text = \"[CLS] \"+ \" \".join(new_word_list[x:up_to])\n",
    "        #print(segment_ids)\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        #print(marked_text)\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        segment_ids = [ c for b in [[a]*(lengths[a-1]) for a in range(1,len(lengths)+1)] for c in b]\n",
    "        #print(segment_ids)\n",
    "        segment_ids.insert(0,1)\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segment_ids])\n",
    "        #print(tokens_tensor)\n",
    "        #print(segments_tensors)\n",
    "        model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                      output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                      )\n",
    "\n",
    "        # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "            # Evaluating the model will return a different number of objects based on\n",
    "            # how it's  configured in the `from_pretrained` call earlier. In this case,\n",
    "            # becase we set `output_hidden_states = True`, the third item will be the\n",
    "            # hidden states from all layers. See the documentation for more details:\n",
    "            # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "            #print(outputs)\n",
    "            hidden_states = outputs[2]\n",
    "        #print(hidden_states)\n",
    "        #print('Tensor shape for each layer: ', hidden_states[0].size())\n",
    "        token_vecs = hidden_states[0][0]\n",
    "        #print(token_vecs.shape)\n",
    "        # Calculate the average of all 22 token vectors.\n",
    "        #print(np.shape(token_vecs))\n",
    "        for a in range(len(lengths)):\n",
    "            if a == 0:\n",
    "            #print(token_vecs[0:5])\n",
    "                sentence_embedding = torch.mean(token_vecs[a:a+lengths[a]+1], dim=0)\n",
    "            else:\n",
    "                sentence_embedding = torch.mean(token_vecs[a:a+lengths[a]], dim=0)\n",
    "\n",
    "            #print(sentence_embedding.shape)\n",
    "            #print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())\n",
    "            list_embeds.append(np.array(sentence_embedding))\n",
    "    return np.array(list_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([423, 768])\n",
      "torch.Size([399, 768])\n",
      "torch.Size([429, 768])\n",
      "torch.Size([410, 768])\n",
      "torch.Size([435, 768])\n",
      "torch.Size([421, 768])\n",
      "torch.Size([425, 768])\n",
      "torch.Size([419, 768])\n",
      "torch.Size([457, 768])\n",
      "torch.Size([438, 768])\n",
      "torch.Size([450, 768])\n",
      "torch.Size([428, 768])\n",
      "torch.Size([452, 768])\n",
      "torch.Size([434, 768])\n",
      "torch.Size([406, 768])\n",
      "torch.Size([418, 768])\n",
      "torch.Size([462, 768])\n",
      "torch.Size([438, 768])\n",
      "torch.Size([401, 768])\n",
      "torch.Size([139, 768])\n"
     ]
    }
   ],
   "source": [
    "y_matrix = get_BERT_embedding(subjects_samples[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1235, 768)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jai's Implementation of clip embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_embedding(subject_sample, model,processor):\n",
    "    word_list = []\n",
    "    for i in range(len(subject_sample)):\n",
    "        word_list.append(subject_sample[i][1])\n",
    "    new_word_list = [' '.join(sublist) for sublist in word_list]\n",
    "\n",
    "    inputs = processor(text=new_word_list, images=image, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # text_embeds is in the same space as the given image\n",
    "        text_embeds = outputs['text_embeds']\n",
    "\n",
    "        # pooler_output is just the text embedding \n",
    "        # This is what we want to use I think \n",
    "        pooler_output = outputs['text_model_output']['pooler_output']\n",
    "#         print(pooler_output.numpy().shape)\n",
    "    return pooler_output\n",
    "    #return text_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzhyDXB3qNsU"
   },
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "\n",
    "def split_data(X_matrix, Y_matrix):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_matrix, y_matrix,\n",
    "                                                        test_size=0.20,\n",
    "                                                        seed=1234,\n",
    "                                                        shuffle=False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "XTAuddpyeVcI"
   },
   "outputs": [],
   "source": [
    "# Train Ridge Regression Model\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    model = ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "D_M1TZx5Ru1n"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, random_text_embedding):\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Predict text embedding from test fMRI data\n",
    "    y_pred = model.predict(X_test)\n",
    "#     print(np.shape(y_pred))\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    prediction_similarity_true = cosine_similarity(y_test, y_pred)\n",
    "    prediction_similarity_random = cosine_similarity(random_text_embedding, y_pred)\n",
    "#     print(np.shape(prediction_similarity_true), np.shape(prediction_similarity_true))\n",
    "    \n",
    "     # Count the occurrences of \"1\" in the first column    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if prediction_similarity_true[i].mean() >= prediction_similarity_random[i].mean():\n",
    "            correct_predictions +=1\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = (correct_predictions / X_test.shape[0])\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "Z4cuRbSqqRza",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_two_way_class_result(model, X_test, y_test, y_matrix, batches):\n",
    "    accuracy = []\n",
    "    for i in range(batches):\n",
    "        idx = np.arange(len(y_test))\n",
    "        np.random.shuffle(idx)\n",
    "\n",
    "        random_text_embedding = y_matrix[idx]\n",
    "\n",
    "        test_accuracy = evaluate_model(model, X_test, y_test, random_text_embedding)\n",
    "        accuracy.append(test_accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracy)/ batches\n",
    "    \n",
    "    print(accuracy)\n",
    "    print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "NEaDKYWTR7Mp",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining aligned fMRI scan for context length: 24---------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -17 is out of bounds for axis 0 with size 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kp/2c01k3yd3mxf7_5q6bcqn7rm0000gn/T/ipykernel_82265/1994012385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Step 1: Obtain aligned fMRI embedding with words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msubjects_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhrf_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_SUBJS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#y_matrix = get_BERT_embedding(subjects_samples[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_clip_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kp/2c01k3yd3mxf7_5q6bcqn7rm0000gn/T/ipykernel_82265/784498596.py\u001b[0m in \u001b[0;36mhrf_alignment\u001b[0;34m(num_words, words_info, NUM_SUBJS, subjects_fmri)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#get next 4 fMRI scans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mfMRI_delay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdelay\u001b[0m \u001b[0;31m#delay until jth next fMRI scan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfMRI_delay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#gets the gaussian weighting (16 points instead of 8 to allow for .5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mcurr_fmri_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmri_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#gets the index of the jth next fMRI scan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index -17 is out of bounds for axis 0 with size 16"
     ]
    }
   ],
   "source": [
    "context_lengths = [24]\n",
    "NUM_SUBJS = 8\n",
    "for length in context_lengths:\n",
    "    # Step 1: Obtain aligned fMRI embedding with words\n",
    "    print(f'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------')\n",
    "    subjects_samples = hrf_alignment(length, words_info, NUM_SUBJS, matrices)\n",
    "    #y_matrix = get_BERT_embedding(subjects_samples[0])\n",
    "    y_matrix = get_clip_embedding(subjects_samples[0],model,processor)\n",
    "\n",
    "    # Step 2: Obtain text and fMRI embedding\n",
    "    # get embeddings for subject 1\n",
    "    for subject in range(NUM_SUBJS):\n",
    "        print(f'---------Obtaining clip and fMRI embedding for subject {subject}-----------------')\n",
    "        #y_matrix = get_clip_embedding(subjects_samples[subject],model,processor)\n",
    "        X_matrix = get_fMRI_embedding(subjects_samples[subject])\n",
    "        print(f'Subject {subject} \\n fMRI Embedding Shape: {np.shape(X_matrix)} \\n Text Embedding Shape: {np.shape(y_matrix)}')\n",
    "        \n",
    "        # Split data for training\n",
    "        print(f'---------Spliting data for subject {subject}-----------------')\n",
    "        X_train, X_test, y_train, y_test = split_data(X_matrix, y_matrix)\n",
    "        \n",
    "        print(f'---------Training started for subject {subject}-----------------')\n",
    "        # Train model\n",
    "        model_ = train_model(X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(f'---------Getting two way classification accuracy for subject {subject}-----------------\\n')\n",
    "\n",
    "        batches = 8\n",
    "        accuracy = obtain_two_way_class_result(model_, X_test, y_test, y_matrix, batches)\n",
    "        \n",
    "    print(f'Subject: {subject} \\n Context Length: {length} \\n Average Accuracy: {accuracy}\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
