{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eO1tSqzp8YE"
   },
   "source": [
    "This file contains the implementation of ridge (L2) regression for mapping fMRI embeddings to CLIP and word2vec embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d14zQ3DZq6MK"
   },
   "source": [
    "First setup baseline model (word2vec) (Not yet implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT4mOgANq4sG",
    "outputId": "da6cf362-0555-454c-8199-8c5feabb7ffb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 14:12:06.268357: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GahCiBSmdpZc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import nibabel as nib\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "# from google.colab import drive\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z63hCATpLLOt",
    "outputId": "b6eba5ad-53b3-4753-d60a-a774b16e59c8"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n",
    "fMRI_folder = Path('../doi_10.5061_dryad.gt413__v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1SWm20pKzuU",
    "outputId": "0b848180-1242-48c4-c82d-06e6e80349b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 0\n",
      "Subject: 1\n",
      "Subject: 2\n",
      "Subject: 3\n",
      "Subject: 4\n",
      "Subject: 5\n",
      "Subject: 6\n",
      "Subject: 7\n"
     ]
    }
   ],
   "source": [
    "NUM_SUBJS = 8\n",
    "subjects_fmri = [] #stores all 8 subject fmri np arrays\n",
    "\n",
    "# fMRI_folder = Path('./doi_10.5061_dryad.gt413__v1')\n",
    "# assert fMRI_folder.exists(), f\"Foldder: {fMRI_folder} does not exist.\"\n",
    "\n",
    "for subj_id in range(8):\n",
    "    print(\"Subject:\",subj_id)\n",
    "#     fmri_file_name = str(subj_id) + '_masked_2d.npy'\n",
    "#     fmri = np.load(fMRI_folder / fmri_file_name)\n",
    "    fmri_file_name = str(subj_id) + '_smooth_nifti_4d.nii'\n",
    "    fmri = nib.load(fMRI_folder / fmri_file_name)\n",
    "    fmri = np.array(fmri.dataobj)\n",
    "    assert isinstance(fmri, np.ndarray), f\"Imported fmri_scan for subject {subj_id} is not of type numpy.ndarray\"\n",
    "    assert(fmri.ndim) == 4, f\"Imported fmri_scan for subject {subj_id} is not 4 dimensional\"\n",
    "    subjects_fmri.append(fmri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBZTp5VgVEom",
    "outputId": "dfe79b3d-f7d0-4b42-c69b-6a7635586ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n",
      "(53, 60, 50, 1311)\n"
     ]
    }
   ],
   "source": [
    "for x in subjects_fmri:\n",
    "    print(np.shape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 60 50\n",
      "51 60 49\n"
     ]
    }
   ],
   "source": [
    "mat_files = sorted(list(fMRI_folder.glob('subject_*.mat')))\n",
    "sub_num = 0\n",
    "matrices = []\n",
    "for file in mat_files:\n",
    "    mat_contents = sio.loadmat(file)\n",
    "    matrix = np.zeros((np.shape(subjects_fmri[sub_num])[3],mat_contents[\"meta\"][0][0][2][0][0],))\n",
    "    fmri = subjects_fmri[int(str(file)[-5])-1]\n",
    "    #print(np.shape(fmri))\n",
    "    #print(mat_contents[\"meta\"])\n",
    "\n",
    "    print(mat_contents[\"meta\"][0][0][3][0][0],mat_contents[\"meta\"][0][0][4][0][0],mat_contents[\"meta\"][0][0][5][0][0])\n",
    "    for x in range(mat_contents[\"meta\"][0][0][3][0][0]):\n",
    "        for y in range(mat_contents[\"meta\"][0][0][4][0][0]):\n",
    "            for z in range(mat_contents[\"meta\"][0][0][5][0][0]):\n",
    "                col = mat_contents[\"meta\"][0][0][7][x][y][z]\n",
    "                matrix[:,col] = fmri[x-1][y-1][z-1][:]\n",
    "    matrices.append(matrix)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKm-vOaOJwZH"
   },
   "outputs": [],
   "source": [
    "feature_matrix = np.zeros((5176,195)) #stores the feature vectors as a row for each word\n",
    "feature_names = [] #stores the names of all features in order\n",
    "feature_types = {} #stores the types of features and all the names of the features for each type\n",
    "\n",
    "features = sio.loadmat(fMRI_folder/'story_features.mat')\n",
    "feature_count = 0\n",
    "for feature_type in features['features'][0]:\n",
    "    feature_types[feature_type[0][0]] = []\n",
    "    if isinstance(feature_type[1][0], str):\n",
    "        feature_types[feature_type[0][0]].append(feature_type[1][0])\n",
    "        feature_names.append(feature_type[1][0])\n",
    "    else:\n",
    "        for feature in feature_type[1][0]:\n",
    "            feature_types[feature_type[0][0]].append(feature[0])\n",
    "            feature_names.append(feature[0])\n",
    "    feature_matrix[:, feature_count:feature_count+feature_type[2].shape[1]] = feature_type[2] #adds the (5176xN) feature values to the feature matrix for the current feature group\n",
    "    feature_count += feature_type[2].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ks5wTcKJmjz"
   },
   "outputs": [],
   "source": [
    "words_info = [] #stores tuples of (word, time, features) sorted by time appeared\n",
    "\n",
    "mat_file = 'subject_1.mat' #only looks at the first subject file, somewhere it said all the timings were the same so this should be safe\n",
    "mat_contents = sio.loadmat(fMRI_folder/mat_file)\n",
    "# print(mat_content)\n",
    "for count, row in enumerate(mat_contents['words'][0]):\n",
    "    word_value = row[0][0][0][0]\n",
    "    time = row[1][0][0]\n",
    "    \n",
    "    word_tuple = (word_value, time, feature_matrix[count,:])\n",
    "    words_info.append(word_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DP3j_XQJnJR",
    "outputId": "094873e7-c700-4223-84ae-087150e3f246"
   },
   "outputs": [],
   "source": [
    "chapter_nine_text = \"\"\n",
    "for row in mat_contents['words'][0]:\n",
    "    chapter_nine_text += row[0][0][0][0] + \" \"\n",
    "# print(chapter_nine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjvOavtmUsTG",
    "outputId": "a69f8cd4-dd3c-47be-99a2-b1fcfdf391de"
   },
   "outputs": [],
   "source": [
    "for count, subject in enumerate(subjects_fmri):\n",
    "    print(count, np.shape(subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../fmri_indices', 'rb') as f:\n",
    "    fmri_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muTykRqfJcpY"
   },
   "source": [
    "Harrison's implementation of Gaussian weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOE-RCeGJcNV"
   },
   "outputs": [],
   "source": [
    "def hrf_alignment(num_words, words_info, NUM_SUBJS, subjects_fmri):\n",
    "\n",
    "    subjects_samples = [[] for i in range(NUM_SUBJS)] #stores lists of all the samples for each subject\n",
    "    window = signal.windows.gaussian(16, std=1) #gaussian window for the 4 fMRI scans\n",
    "    num_words = num_words\n",
    "    word_count = 0\n",
    "    while word_count < len(words_info) - 24:\n",
    "        #gets the 4 input words, and the 4 consecutive words while verifying they were read in sequence\n",
    "        scan_words = []\n",
    "        start_time = words_info[word_count][1]\n",
    "        in_sequence = True #tracks if the words are in sequence or not\n",
    "        for i in range(num_words):\n",
    "            word_info = words_info[word_count + i]\n",
    "            if word_info[1] != start_time + 0.5*i:\n",
    "                #if some of the words are not in sequence, skip forward 1 word after innter loop\n",
    "                in_sequence = False\n",
    "            scan_words.append(word_info[0])\n",
    "        if not in_sequence:\n",
    "            word_count +=1\n",
    "            continue\n",
    "        fmri_time = start_time #fMRI is taken at first word read\n",
    "        fmri_index = fmri_time//2 #since a scan happens every two seconds, the index is the time divided by 2\n",
    "        if not np.issubdtype(fmri_index, np.integer):\n",
    "            #if the first word is not aligned with the fmri scan (i.e. its not the first word in a TR)\n",
    "            word_count += 1\n",
    "            continue\n",
    "        break_found = False\n",
    "        for count, subject in enumerate(subjects_fmri):\n",
    "#             print(\"Subject:\",count)\n",
    "            #adds tuple of (fmri_scan, four words)\n",
    "            for i in range(num_words): #time delay of reading word after fMRI scan\n",
    "                delay = 0.5*i #delay after first word\n",
    "                for j in range(1,5): #get next 4 fMRI scans\n",
    "                    fMRI_delay = 2*j - delay #delay until jth next fMRI scan\n",
    "                    weight = window[int(2*fMRI_delay)-1] #gets the gaussian weighting (16 points instead of 8 to allow for .5)\n",
    "                    try:\n",
    "                        curr_fmri_idx = fmri_indices.index((start_time + math.floor(i/4) + 2*j)//2) #gets the index of the jth next fMRI scan\n",
    "                    except:\n",
    "#                         print(\"break found at index:\",(start_time + math.floor(i/4) + 2*j)//2)\n",
    "                        break_found = True\n",
    "                        break\n",
    "                    #adds weight fMRI scan\n",
    "                    if j == 1:\n",
    "                        word_scan = weight*subject[:][curr_fmri_idx]\n",
    "                    else:\n",
    "                        word_scan += weight*subject[:][curr_fmri_idx]\n",
    "                if break_found:\n",
    "                    break\n",
    "                if i == 0:\n",
    "                    summed_weighted_scans = word_scan\n",
    "                else:\n",
    "                    summed_weighted_scans += word_scan\n",
    "            if break_found:\n",
    "                break\n",
    "            subjects_samples[count].append((summed_weighted_scans/num_words, scan_words))\n",
    "        if break_found:\n",
    "            word_count += 1\n",
    "            continue \n",
    "#         print(\"Created sample:\")\n",
    "#         print(\"\\tScan time:\", str(start_time))\n",
    "#         print(\"\\tInput words:\", str(scan_words))\n",
    "        #if successful, skip forward to the next set of 4 words\n",
    "        word_count += 4\n",
    "    return subjects_samples\n",
    "\n",
    "    print(\"Total number of samples:\", str(len(subjects_samples[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDooPY-xnS96"
   },
   "outputs": [],
   "source": [
    "def get_fMRI_embedding(subjects_samples):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    flattened_shape = reduce(np.multiply, subjects_samples[0][0].shape)\n",
    "    X_matrix = np.zeros((len(subjects_samples), flattened_shape))\n",
    "\n",
    "    for idx, sample in enumerate(subjects_samples):\n",
    "        tmp = sample[0]\n",
    "        # Reshape the voxels \n",
    "        tmp = tmp.ravel()\n",
    "        X_matrix[idx,:] = tmp\n",
    "        \n",
    "    # Apply voxelwise standardization        \n",
    "    X_matrix = scaler.fit_transform(X_matrix)\n",
    "    #print(np.shape(X_matrix))\n",
    "    return X_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import regex as re\n",
    "\n",
    "glove_file = 'glove.840B.300d.txt'\n",
    "glove_model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word):\n",
    "    return re.sub(r'[^\\w\\s]', '', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(word, model):\n",
    "    oov = np.zeros((300))\n",
    "    word = remove_punctuation(word)\n",
    "    if word == \"\":\n",
    "        word = \"unk\"\n",
    "    if word in model.index_to_key:\n",
    "        return model[word]\n",
    "    else:\n",
    "        return oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embedding(subject_sample, model):\n",
    "\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    embeddings = []\n",
    "    embedding_matrix = np.zeros((len(subject_sample), 300))\n",
    "\n",
    "    for count, sentence in enumerate(subject_sample):\n",
    "        try:\n",
    "            sentence_embedding = [get_embedding(word, glove_model) for word in sentence[1]]\n",
    "            sentence_embedding = np.mean(sentence_embedding, axis=0)\n",
    "            embedding_matrix[count,:] = sentence_embedding\n",
    "        except ValueError:\n",
    "            print(sentence[1])\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZoeD2JzgXvSY",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "2023-12-02 23:49:54.465493: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-02 23:49:54.465832: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-02 23:49:54.745419: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-02 23:49:55.349023: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-02 23:50:00.113230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, DistilBertTokenizer,DistilBertModel\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SBERT_embedding(subject_sample):\n",
    "    word_list = []\n",
    "    context_length = 0\n",
    "\n",
    "    for i in range(len(subject_sample)):\n",
    "        context_length = len(subject_sample[i][1])\n",
    "        word_list.append(subject_sample[i][1])\n",
    "    new_word_list = [(' '.join(sublist)) for sublist in word_list]\n",
    "    print(context_length)\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    x = model.encode(new_word_list,convert_to_tensor=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "#module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "#model = hub.load(module_url)\n",
    "#print (\"module %s loaded\" % module_url)\n",
    "##def embed(input):\n",
    " # return model(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/large/versions/2\"\n",
    "model_USE = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_USE_embedding(subject_sample):\n",
    "    word_list = []\n",
    "    context_length = 0\n",
    "\n",
    "    for i in range(len(subject_sample)):\n",
    "        context_length = len(subject_sample[i][1])\n",
    "        word_list.append(subject_sample[i][1])\n",
    "    new_word_list = [(' '.join(sublist)) for sublist in word_list]\n",
    "    #print(new_word_list)\n",
    "    #print(context_length)\n",
    "    #model = hub.load(module_url)\n",
    "    #print (\"module %s loaded\" % module_url)\n",
    "    sentence_embeddings = model_USE(new_word_list)\n",
    "\n",
    "    return np.array(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_matrix = get_USE_embedding(subjects_samples[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jai's Implementation of clip embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_embedding(subject_sample, model,processor):\n",
    "    word_list = []\n",
    "    for i in range(len(subject_sample)):\n",
    "        word_list.append(subject_sample[i][1])\n",
    "    new_word_list = [' '.join(sublist) for sublist in word_list]\n",
    "\n",
    "    inputs = processor(text=new_word_list, images=image, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # text_embeds is in the same space as the given image\n",
    "        text_embeds = outputs['text_embeds']\n",
    "\n",
    "        # pooler_output is just the text embedding \n",
    "        # This is what we want to use I think \n",
    "        pooler_output = outputs['text_model_output']['pooler_output']\n",
    "#         print(pooler_output.numpy().shape)\n",
    "    #return pooler_output\n",
    "    return text_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "UzhyDXB3qNsU"
   },
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "\n",
    "def split_data(X_matrix, Y_matrix,random_seed):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_matrix, y_matrix,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=random_seed,\n",
    "                                                        shuffle=False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XTAuddpyeVcI"
   },
   "outputs": [],
   "source": [
    "# Train Ridge Regression Model\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    model = ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "D_M1TZx5Ru1n"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, random_text_embedding):\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Predict text embedding from test fMRI data\n",
    "    y_pred = model.predict(X_test)\n",
    "#     print(np.shape(y_pred))\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    prediction_similarity_true = cosine_similarity(y_test, y_pred)\n",
    "    prediction_similarity_random = cosine_similarity(random_text_embedding, y_pred)\n",
    "#     print(np.shape(prediction_similarity_true), np.shape(prediction_similarity_true))\n",
    "    \n",
    "     # Count the occurrences of \"1\" in the first column    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if prediction_similarity_true[i].mean() >= prediction_similarity_random[i].mean():\n",
    "            correct_predictions +=1\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = (correct_predictions / X_test.shape[0])\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Z4cuRbSqqRza",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_two_way_class_result(model, X_test, y_test, y_matrix, batches):\n",
    "    accuracy = []\n",
    "    for i in range(batches):\n",
    "        idx = np.arange(len(y_test))\n",
    "        np.random.shuffle(idx)\n",
    "\n",
    "        random_text_embedding = y_matrix[idx]\n",
    "\n",
    "        test_accuracy = evaluate_model(model, X_test, y_test, random_text_embedding)\n",
    "        accuracy.append(test_accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracy)/ batches\n",
    "    \n",
    "    #print(accuracy)\n",
    "    #print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import arange\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import stdev, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds = [123,1234,122,1233,1235,1246,1232,1221,1542,1643,1231]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "NEaDKYWTR7Mp",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining aligned fMRI scan for context length: 4---------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kp/2c01k3yd3mxf7_5q6bcqn7rm0000gn/T/ipykernel_7838/908370245.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Step 1: Obtain aligned fMRI embedding with words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msubjects_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhrf_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_SUBJS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#y_matrix = get_BERT_embedding(subjects_samples[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_USE_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubjects_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kp/2c01k3yd3mxf7_5q6bcqn7rm0000gn/T/ipykernel_7838/784498596.py\u001b[0m in \u001b[0;36mhrf_alignment\u001b[0;34m(num_words, words_info, NUM_SUBJS, subjects_fmri)\u001b[0m\n\u001b[1;32m     44\u001b[0m                         \u001b[0mword_scan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_fmri_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                         \u001b[0mword_scan\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_fmri_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbreak_found\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "context_lengths = [4,8,12,16,20]\n",
    "NUM_SUBJS = 8\n",
    "\n",
    "for length in context_lengths:\n",
    "    # Step 1: Obtain aligned fMRI embedding with words\n",
    "    print(f'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------')\n",
    "    subjects_samples = hrf_alignment(length, words_info, NUM_SUBJS, matrices)\n",
    "    #y_matrix = get_BERT_embedding(subjects_samples[0])\n",
    "    y_matrix = get_USE_embedding(subjects_samples[0])\n",
    "    #print(subjects_samples)\n",
    "    #y_matrix = get_clip_embedding(subjects_samples[0],model,processor)\n",
    "\n",
    "    # Step 2: Obtain text and fMRI embedding\n",
    "    # get embeddings for subject 1\n",
    "    accuracy_runs = []\n",
    "    for x in range(10):\n",
    "        print(\"run \"+str(x))\n",
    "        subjects_avg = []\n",
    "        for subject in range(NUM_SUBJS):\n",
    "            #print(f'---------Obtaining clip and fMRI embedding for subject {subject}-----------------')\n",
    "            #y_matrix = get_clip_embedding(subjects_samples[subject],model,processor)\n",
    "            X_matrix = get_fMRI_embedding(subjects_samples[subject])\n",
    "            #print(f'Subject {subject} \\n fMRI Embedding Shape: {np.shape(X_matrix)} \\n Text Embedding Shape: {np.shape(y_matrix)}')\n",
    "\n",
    "            # Split data for training\n",
    "            #print(f'---------Spliting data for subject {subject}-----------------')\n",
    "            X_train, X_test, y_train, y_test = split_data(X_matrix, y_matrix,random_seeds[x])        #print(f'---------Training started for subject {subject}-----------------')\n",
    "            # Train model\n",
    "            model_ = train_model(X_train, y_train)\n",
    "\n",
    "            # Evaluate model\n",
    "            #print(f'---------Getting two way classification accuracy for subject {subject}-----------------\\n')\n",
    "\n",
    "            batches = 8\n",
    "            accuracy = obtain_two_way_class_result(model_, X_test, y_test, y_matrix, batches)\n",
    "\n",
    "            print(f'{accuracy*100:.2f}')\n",
    "            accuracy_runs.append(accuracy*100)\n",
    "    print(mean(accuracy_runs),stdev(accuracy_runs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT\n",
      "Obtaining aligned fMRI scan for context length: 4---------------------------------------------\n",
      "run 0\n",
      "52.78\n",
      "44.48\n",
      "57.79\n",
      "57.64\n",
      "53.59\n",
      "47.67\n",
      "60.53\n",
      "46.31\n",
      "run 1\n",
      "51.97\n",
      "44.69\n",
      "59.06\n",
      "58.25\n",
      "53.19\n",
      "49.19\n",
      "60.43\n",
      "45.34\n",
      "run 2\n",
      "51.82\n",
      "43.42\n",
      "58.81\n",
      "57.24\n",
      "52.83\n",
      "49.85\n",
      "61.08\n",
      "46.26\n",
      "run 3\n",
      "52.88\n",
      "44.03\n",
      "58.65\n",
      "58.05\n",
      "53.14\n",
      "48.58\n",
      "60.17\n",
      "45.80\n",
      "run 4\n",
      "51.37\n",
      "43.37\n",
      "58.45\n",
      "57.09\n",
      "53.04\n",
      "48.38\n",
      "59.56\n",
      "45.75\n",
      "run 5\n",
      "52.18\n",
      "43.42\n",
      "58.55\n",
      "57.49\n",
      "53.64\n",
      "48.48\n",
      "60.22\n",
      "46.76\n",
      "run 6\n",
      "52.07\n",
      "43.07\n",
      "57.14\n",
      "58.50\n",
      "53.69\n",
      "46.86\n",
      "61.54\n",
      "45.04\n",
      "run 7\n",
      "51.92\n",
      "44.99\n",
      "58.45\n",
      "58.20\n",
      "52.99\n",
      "47.32\n",
      "60.88\n",
      "45.65\n",
      "run 8\n",
      "51.47\n",
      "44.08\n",
      "58.91\n",
      "57.54\n",
      "53.19\n",
      "48.23\n",
      "60.63\n",
      "46.05\n",
      "run 9\n",
      "52.88\n",
      "44.18\n",
      "58.20\n",
      "58.65\n",
      "54.00\n",
      "48.23\n",
      "60.98\n",
      "45.19\n",
      "52.54997469635627 5.822316332165373\n",
      "Obtaining aligned fMRI scan for context length: 8---------------------------------------------\n",
      "run 0\n",
      "55.62\n",
      "45.04\n",
      "59.82\n",
      "61.49\n",
      "54.15\n",
      "42.31\n",
      "50.61\n",
      "53.14\n",
      "run 1\n",
      "56.83\n",
      "44.08\n",
      "60.53\n",
      "59.72\n",
      "53.74\n",
      "44.28\n",
      "50.91\n",
      "52.94\n",
      "run 2\n",
      "55.31\n",
      "43.83\n",
      "59.11\n",
      "62.04\n",
      "54.45\n",
      "42.31\n",
      "50.51\n",
      "53.49\n",
      "run 3\n",
      "55.72\n",
      "44.89\n",
      "59.92\n",
      "61.74\n",
      "53.85\n",
      "43.67\n",
      "49.39\n",
      "53.09\n",
      "run 4\n",
      "55.92\n",
      "44.08\n",
      "59.16\n",
      "60.53\n",
      "54.55\n",
      "42.91\n",
      "50.46\n",
      "52.33\n",
      "run 5\n",
      "57.19\n",
      "44.89\n",
      "60.02\n",
      "60.63\n",
      "53.54\n",
      "43.27\n",
      "51.47\n",
      "52.83\n",
      "run 6\n",
      "56.73\n",
      "44.74\n",
      "60.83\n",
      "59.21\n",
      "54.76\n",
      "43.88\n",
      "50.81\n",
      "52.68\n",
      "run 7\n",
      "55.87\n",
      "44.89\n",
      "60.22\n",
      "61.99\n",
      "53.85\n",
      "43.17\n",
      "50.15\n",
      "51.52\n",
      "run 8\n",
      "55.26\n",
      "44.03\n",
      "60.32\n",
      "60.93\n",
      "53.74\n",
      "42.81\n",
      "49.65\n",
      "53.69\n",
      "run 9\n",
      "56.48\n",
      "44.94\n",
      "59.41\n",
      "60.53\n",
      "54.05\n",
      "42.86\n",
      "49.29\n",
      "51.42\n",
      "52.71255060728745 6.155481570135199\n",
      "Obtaining aligned fMRI scan for context length: 12---------------------------------------------\n",
      "run 0\n",
      "48.17\n",
      "43.60\n",
      "49.85\n",
      "58.74\n",
      "52.49\n",
      "50.25\n",
      "63.72\n",
      "46.85\n",
      "run 1\n",
      "48.37\n",
      "43.19\n",
      "50.15\n",
      "59.40\n",
      "52.79\n",
      "50.51\n",
      "63.97\n",
      "46.49\n",
      "run 2\n",
      "48.88\n",
      "43.04\n",
      "50.51\n",
      "59.96\n",
      "52.13\n",
      "50.91\n",
      "63.82\n",
      "47.41\n",
      "run 3\n",
      "48.32\n",
      "43.14\n",
      "50.05\n",
      "57.83\n",
      "52.24\n",
      "51.73\n",
      "64.08\n",
      "46.95\n",
      "run 4\n",
      "49.19\n",
      "43.80\n",
      "50.76\n",
      "58.54\n",
      "52.29\n",
      "50.20\n",
      "63.77\n",
      "47.76\n",
      "run 5\n",
      "47.87\n",
      "43.04\n",
      "51.27\n",
      "57.16\n",
      "52.90\n",
      "49.44\n",
      "63.82\n",
      "46.85\n",
      "run 6\n",
      "49.09\n",
      "43.65\n",
      "50.61\n",
      "59.25\n",
      "52.29\n",
      "51.78\n",
      "64.23\n",
      "46.85\n",
      "run 7\n",
      "48.12\n",
      "43.55\n",
      "49.34\n",
      "58.03\n",
      "52.44\n",
      "51.02\n",
      "63.92\n",
      "46.80\n",
      "run 8\n",
      "47.97\n",
      "44.00\n",
      "50.76\n",
      "58.79\n",
      "52.90\n",
      "51.58\n",
      "63.72\n",
      "46.70\n",
      "run 9\n",
      "48.48\n",
      "43.50\n",
      "50.25\n",
      "58.49\n",
      "53.35\n",
      "50.51\n",
      "63.67\n",
      "45.58\n",
      "51.86737804878049 6.200781612981719\n",
      "Obtaining aligned fMRI scan for context length: 16---------------------------------------------\n",
      "run 0\n",
      "52.18\n",
      "43.95\n",
      "52.54\n",
      "57.22\n",
      "53.40\n",
      "48.37\n",
      "50.91\n",
      "45.78\n",
      "run 1\n",
      "50.41\n",
      "43.50\n",
      "52.24\n",
      "57.98\n",
      "52.44\n",
      "47.97\n",
      "51.32\n",
      "46.49\n",
      "run 2\n",
      "50.46\n",
      "43.50\n",
      "52.64\n",
      "56.20\n",
      "52.24\n",
      "50.05\n",
      "49.95\n",
      "45.12\n",
      "run 3\n",
      "51.32\n",
      "43.50\n",
      "52.74\n",
      "57.16\n",
      "52.59\n",
      "48.53\n",
      "51.58\n",
      "44.66\n",
      "run 4\n",
      "49.95\n",
      "42.94\n",
      "51.78\n",
      "57.57\n",
      "53.10\n",
      "48.53\n",
      "51.78\n",
      "44.87\n",
      "run 5\n",
      "52.85\n",
      "43.45\n",
      "52.24\n",
      "57.32\n",
      "53.35\n",
      "48.83\n",
      "50.91\n",
      "45.63\n",
      "run 6\n",
      "50.61\n",
      "43.50\n",
      "53.40\n",
      "57.37\n",
      "52.64\n",
      "49.95\n",
      "51.68\n",
      "45.58\n",
      "run 7\n",
      "51.27\n",
      "43.55\n",
      "52.69\n",
      "55.74\n",
      "52.85\n",
      "48.02\n",
      "50.30\n",
      "45.88\n",
      "run 8\n",
      "51.12\n",
      "42.38\n",
      "51.63\n",
      "57.47\n",
      "51.88\n",
      "48.53\n",
      "51.12\n",
      "45.73\n",
      "run 9\n",
      "50.71\n",
      "42.78\n",
      "51.58\n",
      "57.06\n",
      "51.63\n",
      "48.42\n",
      "50.20\n",
      "46.70\n",
      "50.22484756097561 4.105503942771454\n",
      "Obtaining aligned fMRI scan for context length: 20---------------------------------------------\n",
      "run 0\n",
      "51.48\n",
      "44.54\n",
      "50.26\n",
      "57.19\n",
      "58.11\n",
      "59.08\n",
      "65.46\n",
      "45.87\n",
      "run 1\n",
      "51.79\n",
      "44.44\n",
      "50.31\n",
      "56.89\n",
      "57.81\n",
      "59.13\n",
      "66.07\n",
      "43.98\n",
      "run 2\n",
      "52.04\n",
      "43.57\n",
      "51.73\n",
      "56.43\n",
      "56.63\n",
      "59.85\n",
      "66.53\n",
      "45.82\n",
      "run 3\n",
      "52.96\n",
      "44.39\n",
      "50.41\n",
      "55.97\n",
      "57.14\n",
      "59.29\n",
      "65.46\n",
      "44.59\n",
      "run 4\n",
      "51.89\n",
      "44.69\n",
      "50.87\n",
      "56.43\n",
      "59.29\n",
      "60.05\n",
      "65.97\n",
      "44.18\n",
      "run 5\n",
      "52.14\n",
      "44.18\n",
      "51.58\n",
      "56.79\n",
      "57.30\n",
      "59.34\n",
      "65.97\n",
      "45.15\n",
      "run 6\n",
      "53.57\n",
      "43.72\n",
      "51.07\n",
      "56.33\n",
      "57.60\n",
      "59.39\n",
      "67.35\n",
      "44.90\n",
      "run 7\n",
      "52.50\n",
      "43.88\n",
      "51.73\n",
      "56.22\n",
      "57.91\n",
      "59.59\n",
      "66.43\n",
      "46.53\n",
      "run 8\n",
      "51.89\n",
      "43.83\n",
      "51.79\n",
      "56.07\n",
      "57.35\n",
      "59.13\n",
      "66.02\n",
      "45.82\n",
      "run 9\n",
      "52.86\n",
      "43.62\n",
      "52.50\n",
      "54.90\n",
      "58.06\n",
      "59.80\n",
      "66.43\n",
      "45.31\n",
      "54.06377551020408 6.989836459274467\n"
     ]
    }
   ],
   "source": [
    "print(\"SBERT\")\n",
    "context_lengths = [4,8,12,16,20]\n",
    "NUM_SUBJS = 8\n",
    "\n",
    "for length in context_lengths:\n",
    "    # Step 1: Obtain aligned fMRI embedding with words\n",
    "    print(f'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------')\n",
    "    subjects_samples = hrf_alignment(length, words_info, NUM_SUBJS, matrices)\n",
    "    y_matrix = get_SBERT_embedding(subjects_samples[0])\n",
    "    #_matrix = get_USE_embedding(subjects_samples[0])\n",
    "    #print(subjects_samples)\n",
    "    #y_matrix = get_clip_embedding(subjects_samples[0],model,processor)\n",
    "    #y_matrix = get_glove_embedding(subjects_samples[0],glove_model)\n",
    "\n",
    "    # Step 2: Obtain text and fMRI embedding\n",
    "    # get embeddings for subject 1\n",
    "    accuracy_runs = []\n",
    "    for x in range(10):\n",
    "        print(\"run \"+str(x))\n",
    "        subjects_avg = []\n",
    "        for subject in range(NUM_SUBJS):\n",
    "            #print(f'---------Obtaining clip and fMRI embedding for subject {subject}-----------------')\n",
    "            #y_matrix = get_clip_embedding(subjects_samples[subject],model,processor)\n",
    "            X_matrix = get_fMRI_embedding(subjects_samples[subject])\n",
    "            #print(f'Subject {subject} \\n fMRI Embedding Shape: {np.shape(X_matrix)} \\n Text Embedding Shape: {np.shape(y_matrix)}')\n",
    "\n",
    "            # Split data for training\n",
    "            #print(f'---------Spliting data for subject {subject}-----------------')\n",
    "            X_train, X_test, y_train, y_test = split_data(X_matrix, y_matrix,random_seeds[x])        #print(f'---------Training started for subject {subject}-----------------')\n",
    "            # Train model\n",
    "            model_ = train_model(X_train, y_train)\n",
    "\n",
    "            # Evaluate model\n",
    "            #print(f'---------Getting two way classification accuracy for subject {subject}-----------------\\n')\n",
    "\n",
    "            batches = 8\n",
    "            accuracy = obtain_two_way_class_result(model_, X_test, y_test, y_matrix, batches)\n",
    "\n",
    "            print(f'{accuracy*100:.2f}')\n",
    "            accuracy_runs.append(accuracy*100)\n",
    "    print(mean(accuracy_runs),stdev(accuracy_runs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP\n",
      "Obtaining aligned fMRI scan for context length: 4---------------------------------------------\n",
      "run 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "split_data() missing 1 required positional argument: 'random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kp/2c01k3yd3mxf7_5q6bcqn7rm0000gn/T/ipykernel_7838/864355336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# Split data for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#print(f'---------Spliting data for subject {subject}-----------------')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_matrix\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m#print(f'---------Training started for subject {subject}-----------------')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mmodel_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: split_data() missing 1 required positional argument: 'random_seed'"
     ]
    }
   ],
   "source": [
    "print(\"CLIP\")\n",
    "context_lengths = [4,8,12,16,20]\n",
    "NUM_SUBJS = 8\n",
    "\n",
    "for length in context_lengths:\n",
    "    # Step 1: Obtain aligned fMRI embedding with words\n",
    "    print(f'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------')\n",
    "    subjects_samples = hrf_alignment(length, words_info, NUM_SUBJS, matrices)\n",
    "    #y_matrix = get_BERT_embedding(subjects_samples[0])\n",
    "    #y_matrix = get_USE_embedding(subjects_samples[0])\n",
    "    #print(subjects_samples)\n",
    "    y_matrix = get_clip_embedding(subjects_samples[0],model,processor)\n",
    "\n",
    "    # Step 2: Obtain text and fMRI embedding\n",
    "    # get embeddings for subject 1\n",
    "    accuracy_runs = []\n",
    "    for x in range(10):\n",
    "        print(\"run \"+str(x))\n",
    "        subjects_avg = []\n",
    "        for subject in range(NUM_SUBJS):\n",
    "            #print(f'---------Obtaining clip and fMRI embedding for subject {subject}-----------------')\n",
    "            #y_matrix = get_clip_embedding(subjects_samples[subject],model,processor)\n",
    "            X_matrix = get_fMRI_embedding(subjects_samples[subject])\n",
    "            #print(f'Subject {subject} \\n fMRI Embedding Shape: {np.shape(X_matrix)} \\n Text Embedding Shape: {np.shape(y_matrix)}')\n",
    "\n",
    "            # Split data for training\n",
    "            #print(f'---------Spliting data for subject {subject}-----------------')\n",
    "            X_train, X_test, y_train, y_test = split_data(X_matrix, y_matrix,random_seeds[x])        #print(f'---------Training started for subject {subject}-----------------')\n",
    "            # Train model\n",
    "            model_ = train_model(X_train, y_train)\n",
    "\n",
    "            # Evaluate model\n",
    "            #print(f'---------Getting two way classification accuracy for subject {subject}-----------------\\n')\n",
    "\n",
    "            batches = 8\n",
    "            accuracy = obtain_two_way_class_result(model_, X_test, y_test, y_matrix, batches)\n",
    "\n",
    "            print(f'{accuracy*100:.2f}')\n",
    "            accuracy_runs.append(accuracy*100)\n",
    "    print(mean(accuracy_runs),stdev(accuracy_runs))\n",
    "\n",
    "        \n",
    "##use2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GloVe\")\n",
    "context_lengths = [4,8,12,16,20]\n",
    "NUM_SUBJS = 8\n",
    "\n",
    "for length in context_lengths:\n",
    "    # Step 1: Obtain aligned fMRI embedding with words\n",
    "    print(f'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------')\n",
    "    subjects_samples = hrf_alignment(length, words_info, NUM_SUBJS, matrices)\n",
    "    #y_matrix = get_SBERT_embedding(subjects_samples[0])\n",
    "    #_matrix = get_USE_embedding(subjects_samples[0])\n",
    "    #print(subjects_samples)\n",
    "    #y_matrix = get_clip_embedding(subjects_samples[0],model,processor)\n",
    "    y_matrix = get_glove_embedding(subjects_samples[0],glove_model)\n",
    "\n",
    "    # Step 2: Obtain text and fMRI embedding\n",
    "    # get embeddings for subject 1\n",
    "    accuracy_runs = []\n",
    "    for x in range(10):\n",
    "        print(\"run \"+str(x))\n",
    "        subjects_avg = []\n",
    "        for subject in range(NUM_SUBJS):\n",
    "            #print(f'---------Obtaining clip and fMRI embedding for subject {subject}-----------------')\n",
    "            #y_matrix = get_clip_embedding(subjects_samples[subject],model,processor)\n",
    "            X_matrix = get_fMRI_embedding(subjects_samples[subject])\n",
    "            #print(f'Subject {subject} \\n fMRI Embedding Shape: {np.shape(X_matrix)} \\n Text Embedding Shape: {np.shape(y_matrix)}')\n",
    "\n",
    "            # Split data for training\n",
    "            #print(f'---------Spliting data for subject {subject}-----------------')\n",
    "            X_train, X_test, y_train, y_test = split_data(X_matrix, y_matrix,random_seeds[x])        #print(f'---------Training started for subject {subject}-----------------')\n",
    "            # Train model\n",
    "            model_ = train_model(X_train, y_train)\n",
    "\n",
    "            # Evaluate model\n",
    "            #print(f'---------Getting two way classification accuracy for subject {subject}-----------------\\n')\n",
    "\n",
    "            batches = 8\n",
    "            accuracy = obtain_two_way_class_result(model_, X_test, y_test, y_matrix, batches)\n",
    "\n",
    "            print(f'{accuracy*100:.2f}')\n",
    "            accuracy_runs.append(accuracy*100)\n",
    "    print(mean(accuracy_runs),stdev(accuracy_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement leave_one_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fMRI_embedding_CV(subjects_samples,min_shape):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_matrix = np.zeros((len(subjects_samples), min_shape))\n",
    "\n",
    "    for idx, sample in enumerate(subjects_samples):\n",
    "        tmp = sample[0][:min_shape]\n",
    "        # Reshape the voxels \n",
    "        tmp = tmp.ravel()\n",
    "        X_matrix[idx,:] = tmp\n",
    "        \n",
    "    # Apply voxelwise standardization        \n",
    "    X_matrix = scaler.fit_transform(X_matrix)\n",
    "    return X_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define min_voxel\n",
    "def get_min_voxel(matrices):\n",
    "    \n",
    "    size = []\n",
    "    for i in range(len(matrices)-1):\n",
    "        size.append(len(matrices[i][1][0]))\n",
    "    min_size = min(size)\n",
    "    return min_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train_test_split\n",
    "\n",
    "def get_train_test_split(subjects_samples, text_encoding_name, model=None, processor=None):\n",
    "    \n",
    "    # get minimum voxel value\n",
    "    min_size = get_min_voxel(subjects_samples)\n",
    "    train = []\n",
    "    ytrain = []\n",
    "    \n",
    "    # loop through first 7 subjects, obtain fmri embedding and text embedding for each     \n",
    "    for i in range(len(subjects_samples)-1):\n",
    "        \n",
    "        train_data = get_fMRI_embedding_CV(subjects_samples[i],min_size)\n",
    "        train.append(train_data)\n",
    "        \n",
    "        if text_encoding_name == 'glove':\n",
    "            train_label = get_glove_embedding(subjects_samples[i],model)\n",
    "            ytrain.append(train_label)\n",
    "        elif text_encoding_name == 'clip':\n",
    "            train_label = get_clip_embedding(subjects_samples[i],model,processor)\n",
    "            ytrain.append(train_label)\n",
    "        elif text_encoding_name == 'USE':\n",
    "            train_label = get_USE_embedding(subjects_samples[i],model,processor)\n",
    "            ytrain.append(train_label)\n",
    "        elif text_encoding_name == 'SBERT':\n",
    "            train_label = get_SBERT_embedding(subjects_samples[i],model,processor)\n",
    "            ytrain.append(train_label)\n",
    "\n",
    "        \n",
    "    # concatenate all 7 subjects data as train set    \n",
    "    X_train = np.concatenate(train, axis=0) \n",
    "    y_train = np.concatenate(ytrain, axis=0) \n",
    "\n",
    "    \n",
    "    X_test = get_fMRI_embedding_CV(subjects_samples[7],min_size)\n",
    "    if text_encoding_name == 'glove':\n",
    "        y_test = get_glove_embedding(subjects_samples[7],model)\n",
    "    elif text_encoding_name == 'clip':\n",
    "        y_test = get_clip_embedding(subjects_samples[7],model,processor)\n",
    "    elif text_encoding_name == 'USE':\n",
    "        y_test = get_USE_embedding(subjects_samples[7])\n",
    "    elif text_encoding_name == 'SBERT':\n",
    "        y_test = get_SBERT_embedding(subjects_samples[7])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context length: 4---------------------------------------------\n",
      "Average Accuracy: 50.12%\n",
      "\n",
      "\n",
      "Context length: 8---------------------------------------------\n",
      "Average Accuracy: 49.88%\n",
      "\n",
      "\n",
      "Context length: 12---------------------------------------------\n",
      "Average Accuracy: 49.62%\n",
      "\n",
      "\n",
      "Context length: 16---------------------------------------------\n",
      "Average Accuracy: 50.37%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_lengths = [4,8,12,16]\n",
    "NUM_SUBJS = 8\n",
    "\n",
    "for length in context_lengths:\n",
    "    # Step 1: Obtain aligned fMRI embedding with words\n",
    "    print(f'Context length: {length}---------------------------------------------')\n",
    "    subjects_samples = hrf_alignment(length, words_info, NUM_SUBJS, matrices)\n",
    "#     X_train, y_train, X_test, y_test = get_train_test_split(subjects_samples, 'glove', glove_model)\n",
    "\n",
    "    X_train, y_train, X_test, y_test = get_train_test_split(subjects_samples, 'clip', clip_model, clip_processor)\n",
    "#     X_train, y_train, X_test, y_test = get_train_test_split(subjects_samples, 'SBERT')\n",
    "#     X_train, y_train, X_test, y_test = get_train_test_split(subjects_samples, 'USE')\n",
    "    \n",
    "\n",
    "    # Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    batches = 8\n",
    "    accuracy = obtain_two_way_class_result(model, X_test, y_test, y_train, batches)\n",
    "\n",
    "    print(f'Average Accuracy: {accuracy * 100:.2f}%\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
