{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import CLIPConfig, CLIPModel, CLIPProcessor, CLIPImageProcessor, CLIPTokenizerFast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from gensim.models import Word2Vec\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load word and fMRI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 3d fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SUBJS = 8\n",
    "subjects_fmri = [] #stores all 8 subject fmri np arrays\n",
    "\n",
    "fMRI_folder = Path('./doi_10.5061_dryad.gt413__v1')\n",
    "assert fMRI_folder.exists(), f\"Foldder: {fMRI_folder} does not exist.\"\n",
    "\n",
    "for subj_id in range(8):\n",
    "#     fmri_file_name = str(subj_id) + '_masked_2d.npy'\n",
    "#     fmri = np.load(fMRI_folder / fmri_file_name)  \n",
    "    fmri_file_name = str(subj_id) + '_smooth_nifti_4d.nii'\n",
    "    fmri = nib.load(fMRI_folder / fmri_file_name)\n",
    "    fmri = np.array(fmri.dataobj)\n",
    "    assert isinstance(fmri, np.ndarray), f\"Imported fmri_scan for subject {subj_id} is not of type numpy.ndarray\"\n",
    "    assert(fmri.ndim) == 4, f\"Imported fmri_scan for subject {subj_id} is not 4 dimensional\"\n",
    "    subjects_fmri.append(fmri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.zeros((5176,195)) #stores the feature vectors as a row for each word\n",
    "feature_names = [] #stores the names of all features in order\n",
    "feature_types = {} #stores the types of features and all the names of the features for each type\n",
    "\n",
    "features = sio.loadmat(fMRI_folder / 'story_features.mat')\n",
    "feature_count = 0\n",
    "for feature_type in features['features'][0]:\n",
    "    feature_types[feature_type[0][0]] = []\n",
    "    if isinstance(feature_type[1][0], str):\n",
    "        feature_types[feature_type[0][0]].append(feature_type[1][0])\n",
    "        feature_names.append(feature_type[1][0])\n",
    "    else:\n",
    "        for feature in feature_type[1][0]:\n",
    "            feature_types[feature_type[0][0]].append(feature[0])\n",
    "            feature_names.append(feature[0])\n",
    "    feature_matrix[:, feature_count:feature_count+feature_type[2].shape[1]] = feature_type[2] #adds the (5176xN) feature values to the feature matrix for the current feature group\n",
    "    feature_count += feature_type[2].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_info = [] #stores tuples of (word, time, features) sorted by time appeared\n",
    "\n",
    "mat_file = fMRI_folder / 'subject_1.mat' #only looks at the first subject file, somewhere it said all the timings were the same so this should be safe\n",
    "mat_contents = sio.loadmat(mat_file)\n",
    "for count, row in enumerate(mat_contents['words'][0]):\n",
    "    word_value = row[0][0][0][0]\n",
    "    time = row[1][0][0]\n",
    "    word_tuple = (word_value, time, feature_matrix[count,:])\n",
    "    words_info.append(word_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry had never believed he would meet a boy he hated more than Dudley, but that was before he met Draco Malfoy. Still, first-year Gryffindors only had Potions with the Slytherins, so they didn't have to put up with Malfoy much. Or at least, they didn't until they spotted a notice pinned up in the Gryffindor common room that made them all groan. Flying lessons would be starting on Thursday -- and Gryffindor and Slytherin would be learning together. + \"Typical,\" said Harry darkly. \"Just what I always wanted. To make a fool of myself on a broomstick in front of Malfoy.\" + He had been looking forward to learning to fly more than anything else. \"You don't know that you'll make a fool of yourself,\" said Ron reasonably. \"Anyway, I know Malfoy's always going on about how good he is at Quidditch, but I bet that's all talk.\" + Malfoy certainly did talk about flying a lot. He complained loudly about first years never getting on the House Quidditch teams and told long, boastful stories that always seemed to end with him narrowly escaping Muggles in helicopters. He wasn't the only one, though: the way Seamus Finnigan told it, he'd spent most of his childhood zooming around the countryside on his broomstick. Even Ron would tell anyone who'd listen about the time he'd almost hit a hang glider on Charlie's old broom. Everyone from wizarding families talked about Quidditch constantly. Ron had already had a big argument with Dean Thomas, who shared their dormitory, about soccer. Ron couldn't see what was exciting about a game with only one ball where no one was allowed to fly. Harry had caught Ron prodding Dean's poster of West Ham soccer team, trying to make the players move. + Neville had never been on a broomstick in his life, because his grandmother had never let him near one. Privately, Harry felt she'd had good reason, because Neville managed to have an extraordinary number of accidents even with both feet on the ground. + Hermione Granger was almost as nervous about flying as Neville was. This was something you couldn't learn by heart out of a book -- not that she hadn't tried. At breakfast on Thursday she bored them all stupid with flying tips she'd gotten out of a library book called @Quidditch @Through @the @Ages. Neville was hanging on to her every word, desperate for anything that might help him hang on to his broomstick later, but everybody else was very pleased when Hermione's lecture was interrupted by the arrival of the mail. + Harry hadn't had a single letter since Hagrid's note, something that Malfoy had been quick to notice, of course. Malfoy's eagle owl was always bringing him packages of sweets from home, which he opened gloatingly at the Slytherin table. + A barn owl brought Neville a small package from his grandmother. He opened it excitedly and showed them a glass ball the size of a large marble, which seemed to be full of white smoke. + \"It's a Remembrall!\" he explained. \"Gran knows I forget things -- this tells you if there's something you've forgotten to do. Look, you hold it tight like this and if it turns red -- oh …\" His face fell, because the Remembrall had suddenly glowed scarlet, \"… you've forgotten something …\" + Neville was trying to remember what he'd forgotten when Draco Malfoy, who was passing the Gryffindor table, snatched the Remembrall out of his hand. + Harry and Ron jumped to their feet. They were half hoping for a reason to fight Malfoy, but Professor McGonagall, who could spot trouble quicker than any teacher in the school, was there in a flash. + \"What's going on?\" + \"Malfoy's got my Remembrall, Professor.\" + Scowling, Malfoy quickly dropped the Remembrall back on the table. + \"Just looking,\" he said, and he sloped away with Crabbe and Goyle behind him. + + At three-thirty that afternoon, Harry, Ron, and the other Gryffindors hurried down the front steps onto the grounds for their first flying lesson. It was a clear, breezy day, and the grass rippled under their feet as they marched down the sloping lawns toward a smooth, flat lawn on the opposite side of the grounds to the forbidden forest, whose trees were swaying darkly in the distance. + The Slytherins were already there, and so were twenty broomsticks lying in neat lines on the ground. Harry had heard Fred and George Weasley complain about the school brooms, saying that some of them started to vibrate if you flew too high, or always flew slightly to the left. + Their teacher, Madam Hooch, arrived. She had short, gray hair, and yellow eyes like a hawk. + \"Well, what are you all waiting for?\" she barked. \"Everyone stand by a broomstick. Come on, hurry up.\" + Harry glanced down at his broom. It was old and some of the twigs stuck out at odd angles. + \"Stick out your right hand over your broom,\" called Madam Hooch at the front, \"and say ‘Up!'\" + \"UP!\" everyone shouted. + Harry's broom jumped into his hand at once, but it was one of the few that did. Hermione Granger's had simply rolled over on the ground, and Neville's hadn't moved at all. Perhaps brooms, like horses, could tell when you were afraid, thought Harry; there was a quaver in Neville's voice that said only too clearly that he wanted to keep his feet on the ground. + Madam Hooch then showed them how to mount their brooms without sliding off the end, and walked up and down the rows correcting their grips. Harry and Ron were delighted when she told Malfoy he'd been doing it wrong for years. + \"Now, when I blow my whistle, you kick off from the ground, hard,\" said Madam Hooch. \"Keep your brooms steady, rise a few feet, and then come straight back down by leaning forward slightly. On my whistle -- three -- two —\" + But Neville, nervous and jumpy and frightened of being left on the ground, pushed off hard before the whistle had touched Madam Hooch's lips. + \"Come back, boy!\" she shouted, but Neville was rising straight up like a cork shot out of a bottle -- twelve feet -- twenty feet. Harry saw his scared white face look down at the ground falling away, saw him gasp, slip sideways off the broom and -- + WHAM -- a thud and a nasty crack and Neville lay facedown on the grass in a heap. His broomstick was still rising higher and higher, and started to drift lazily toward the forbidden forest and out of sight. + Madam Hooch was bending over Neville, her face as white as his. \"Broken wrist,\" Harry heard her mutter. \"Come on, boy -- it's all right, up you get.\" + She turned to the rest of the class. \"None of you is to move while I take this boy to the hospital wing! You leave those brooms where they are or you'll be out of Hogwarts before you can say ‘Quidditch.' Come on, dear.\" + Neville, his face tear-streaked, clutching his wrist, hobbled off with Madam Hooch, who had her arm around him. + No sooner were they out of earshot than Malfoy burst into laughter. + \"Did you see his face, the great lump?\" + The other Slytherins joined in. + \"Shut up, Malfoy,\" snapped Parvati Patil. + \"Ooh, sticking up for Longbottom?\" said Pansy Parkinson, a hard-faced Slytherin girl. \"Never thought @you'd like fat little crybabies, Parvati.\" + \"Look!\" said Malfoy, darting forward and snatching something out of the grass. \"It's that stupid thing Longbottom's gran sent him.\" + The Remembrall glittered in the sun as he held it up. + \"Give that here, Malfoy,\" said Harry quietly. Everyone stopped talking to watch. + Malfoy smiled nastily. \"I think I'll leave it somewhere for Longbottom to find -- how about -- up a tree?\" + \"Give it @here!\" Harry yelled, but Malfoy had leapt onto his broomstick and taken off. He hadn't been lying, he @could fly well. Hovering level with the topmost branches of an oak he called, \"Come and get it, Potter!\" + Harry grabbed his broom. + @\"No!\" shouted Hermione Granger. \"Madam Hooch told us not to move -- you'll get us all into trouble.\" + Harry ignored her. Blood was pounding in his ears. He mounted the broom and kicked hard against the ground and up, up he soared; air rushed through his hair, and his robes whipped out behind him -- and in a rush of fierce joy he realized he'd found something he could do without being taught -- this was easy, this was @wonderful. He pulled his broomstick up a little to take it even higher, and heard screams and gasps of girls back on the ground and an admiring whoop from Ron. + He turned his broomstick sharply to face Malfoy in midair. + Malfoy looked stunned. \"Give it here,\" Harry called, \"or I'll knock you off that broom!\" + \"Oh, yeah?\" said Malfoy, trying to sneer, but looking worried. + Harry knew, somehow, what to do. He leaned forward and grasped the broom tightly in both hands, and it shot toward Malfoy like a javelin. Malfoy only just got out of the way in time; Harry made a sharp about-face and held the broom steady. A few people below were clapping. + \"No Crabbe and Goyle up here to save your neck, Malfoy,\" Harry called. + The same thought seemed to have struck Malfoy. + \"Catch it if you can, then!\" he shouted, and he threw the glass ball high into the air and streaked back toward the ground. + Harry saw, as though in slow motion, the ball rise up in the air and then start to fall. He leaned forward and pointed his broom handle down -- next second he was gathering speed in a steep dive, racing the ball -- wind whistled in his ears, mingled with the screams of people watching -- he stretched out his hand -- a foot from the ground he caught it, just in time to pull his broom straight, and he toppled gently onto the grass with the Remembrall clutched safely in his fist. + \"HARRY POTTER!\" + His heart sank faster than he'd just dived. Professor McGonagall was running toward them. He got to his feet, trembling. + @\"Never -- in all my time at Hogwarts —\" Professor McGonagall was almost speechless with shock, and her glasses flashed furiously, \"— how @dare you -- might have broken your neck —\" + \"It wasn't his fault, Professor —\" + \"Be quiet, Miss Patil —\" + \"But Malfoy —\" \"That's enough, Mr. Weasley. Potter, follow me, now.\" + Harry caught sight of Malfoy, Crabbe, and Goyle's triumphant faces as he left, walking numbly in Professor McGonagall's wake as she strode toward the castle. He was going to be expelled, he just knew it. He wanted to say something to defend himself, but there seemed to be something wrong with his voice. Professor McGonagall was sweeping along without even looking at him; he had to jog to keep up. Now he'd done it. He hadn't even lasted two weeks. He'd be packing his bags in ten minutes. What would the Dursleys say when he turned up on the doorstep? + Up the front steps, up the marble staircase inside, and still Professor McGonagall didn't say a word to him. She wrenched open doors and marched along corridors with Harry trotting miserably behind her. Maybe she was taking him to Dumbledore. He thought of Hagrid, expelled but allowed to stay on as gamekeeper. Perhaps he could be Hagrid's assistant. His stomach twisted as he imagined it, watching Ron and the others becoming wizards while he stumped around the grounds carrying Hagrid's bag. + Professor McGonagall stopped outside a classroom. She opened the door and poked her head inside. + \"Excuse me, Professor Flitwick, could I borrow Wood for a moment?\" + Wood? thought Harry, bewildered; was Wood a cane she was going to use on him? But Wood turned out to be a person, a burly fifth-year boy who came out of Flitwick's class looking confused. + \"Follow me, you two,\" said Professor McGonagall, and they marched on up the corridor, Wood looking curiously at Harry. + \"In here.\" + Professor McGonagall pointed them into a classroom that was empty except for Peeves, who was busy writing rude words on the blackboard. + \"Out, Peeves!\" she barked. Peeves threw the chalk into a bin, which clanged loudly, and he swooped out cursing. Professor McGonagall slammed the door behind him and turned to face the two boys. + \"Potter, this is Oliver Wood. Wood -- I've found you a Seeker.\" + Wood's expression changed from puzzlement to delight. + \"Are you serious, Professor?\" + \"Absolutely,\" said Professor McGonagall crisply. \"The boy's a natural. I've never seen anything like it. Was that your first time on a broomstick, Potter?\" + Harry nodded silently. He didn't have a clue what was going on, but he didn't seem to be being expelled, and some of the feeling started coming back to his legs. + \"He caught that thing in his hand after a fifty-foot dive,\" Professor McGonagall told Wood. \"Didn't even scratch himself. Charlie Weasley couldn't have done it.\" + Wood was now looking as though all his dreams had come true at once. + \"Ever seen a game of Quidditch, Potter?\" he asked excitedly. + \"Wood's captain of the Gryffindor team,\" Professor McGonagall explained. + \"He's just the build for a Seeker, too,\" said Wood, now walking around Harry and staring at him. \"Light -- speedy -- we'll have to get him a decent broom, Professor -- a Nimbus Two Thousand or a Cleansweep Seven, I'd say.\" + \"I shall speak to Professor Dumbledore and see if we can't bend the first-year rule. Heaven knows, we need a better team than last year. Flattened in that last match by Slytherin, I couldn't look Severus Snape in the face for weeks. ….\" + Professor McGonagall peered sternly over her glasses at Harry. + \"I want to hear you're training hard, Potter, or I may change my mind about punishing you.\" + Then she suddenly smiled. + \"Your father would have been proud,\" she said. \"He was an excellent Quidditch player himself.\" + + \"You're @joking.\" + It was dinnertime. Harry had just finished telling Ron what had happened when he'd left the grounds with Professor McGonagall. Ron had a piece of steak and kidney pie halfway to his mouth, but he'd forgotten all about it. + @\"Seeker?\" he said. \"But first years @never -- you must be the youngest House player in about —\" + \"— a century,\" said Harry, shoveling pie into his mouth. He felt particularly hungry after the excitement of the afternoon. \"Wood told me.\" + Ron was so amazed, so impressed, he just sat and gaped at Harry. + \"I start training next week,\" said Harry. \"Only don't tell anyone, Wood wants to keep it a secret.\" + Fred and George Weasley now came into the hall, spotted Harry, and hurried over. + \"Well done,\" said George in a low voice. \"Wood told us. We're on the team too -- Beaters.\" + \"I tell you, we're going to win that Quidditch Cup for sure this year,\" said Fred. \"We haven't won since Charlie left, but this year's team is going to be brilliant. You must be good, Harry, Wood was almost skipping when he told us.\" + \"Anyway, we've got to go, Lee Jordan reckons he's found a new secret passageway out of the school.\" + \"Bet it's that one behind the statue of Gregory the Smarmy that we found in our first week. See you.\" + Fred and George had hardly disappeared when someone far less welcome turned up: Malfoy, flanked by Crabbe and Goyle. + \"Having a last meal, Potter? When are you getting the train back to the Muggles?\" + \"You're a lot braver now that you're back on the ground and you've got your little friends with you,\" said Harry coolly. There was of course nothing at all little about Crabbe and Goyle, but as the High Table was full of teachers, neither of them could do more than crack their knuckles and scowl. + \"I'd take you on anytime on my own,\" said Malfoy. \"Tonight, if you want. Wizard's duel. Wands only -- no contact. What's the matter? Never heard of a wizard's duel before, I suppose?\" + \"Of course he has,\" said Ron, wheeling around. \"I'm his second, who's yours?\" + Malfoy looked at Crabbe and Goyle, sizing them up. + \"Crabbe,\" he said. \"Midnight all right? We'll meet you in the trophy room; that's always unlocked.\" + When Malfoy had gone, Ron and Harry looked at each other. + \"What @is a wizard's duel?\" said Harry. \"And what do you mean, you're my second?\" + \"Well, a second's there to take over if you die,\" said Ron casually, getting started at last on his cold pie. Catching the look on Harry's face, he added quickly, \"But people only die in proper duels, you know, with real wizards. The most you and Malfoy'll be able to do is send sparks at each other. Neither of you knows enough magic to do any real damage. I bet he expected you to refuse, anyway.\" + \"And what if I wave my wand and nothing happens?\" + \"Throw it away and punch him on the nose,\" Ron suggested. + \"Excuse me.\" + They both looked up. It was Hermione Granger. + \"Can't a person eat in peace in this place?\" said Ron. + Hermione ignored him and spoke to Harry. \"I couldn't help overhearing what you and Malfoy were saying —\" + \"Bet you could,\" Ron muttered. + \"— and you @mustn't go wandering around the school at night, think of the points you'll lose Gryffindor if you're caught, and you're bound to be. It's really very selfish of you.\" + \"And it's really none of your business,\" said Harry. + \"Good-bye,\" said Ron. + + All the same, it wasn't what you'd call the perfect end to the day, Harry thought, as he lay awake much later listening to Dean and Seamus falling asleep (Neville wasn't back from the hospital wing). Ron had spent all evening giving him advice such as \"If he tries to curse you, you'd better dodge it, because I can't remember how to block them.\" There was a very good chance they were going to get caught by Filch or Mrs. Norris, and Harry felt he was pushing his luck, breaking another school rule today. On the other hand, Malfoy's sneering face kept looming up out of the darkness -- this was his big chance to beat Malfoy face-to-face. He couldn't miss it. + \"Half-past eleven,\" Ron muttered at last, \"we'd better go.\" + They pulled on their bathrobes, picked up their wands, and crept across the tower room, down the spiral staircase, and into the Gryffindor common room. A few embers were still glowing in the fireplace, turning all the armchairs into hunched black shadows. They had almost reached the portrait hole when a voice spoke from the chair nearest them, \"I can't believe you're going to do this, Harry.\" + A lamp flickered on. It was Hermione Granger, wearing a pink bathrobe and a frown. + @\"You!\" said Ron furiously. \"Go back to bed!\" + \"I almost told your brother,\" Hermione snapped, \"Percy -- he's a prefect, he'd put a stop to this.\" + Harry couldn't believe anyone could be so interfering. + \"Come on,\" he said to Ron. He pushed open the portrait of the Fat Lady and climbed through the hole. + Hermione wasn't going to give up that easily. She followed Ron through the portrait hole, hissing at them like an angry goose. \"Don't you @care about Gryffindor, do you @only care about yourselves, I don't want Slytherin to win the House Cup, and you'll lose all the points I got from Professor McGonagall for knowing about Switching Spells.\" + \"Go away.\" + \"All right, but I warned you, you just remember what I said when you're on the train home tomorrow, you're so —\" + But what they were, they didn't find out. Hermione had turned to the portrait of the Fat Lady to get back inside and found herself facing an empty painting. The Fat Lady had gone on a nighttime visit and Hermione was locked out of Gryffindor Tower. + \"Now what am I going to do?\" she asked shrilly. + \"That's your problem,\" said Ron. \"We've got to go, we're going to be late.\" + They hadn't even reached the end of the corridor when Hermione caught up with them. + \"I'm coming with you,\" she said. \"You are @not.\" + \"D'you think I'm going to stand out here and wait for Filch to catch me? If he finds all three of us I'll tell him the truth, that I was trying to stop you, and you can back me up.\" + \"You've got some nerve —\" said Ron loudly. + \"Shut up, both of you!\" said Harry sharply. \"I heard something.\" + It was a sort of snuffling. + \"Mrs. Norris?\" breathed Ron, squinting through the dark. + It wasn't Mrs. Norris. It was Neville. He was curled up on the floor, fast asleep, but jerked suddenly awake as they crept nearer. + \"Thank goodness you found me! I've been out here for hours, I couldn't remember the new password to get in to bed.\" + \"Keep your voice down, Neville. The password's ‘Pig snout' but it won't help you now, the Fat Lady's gone off somewhere.\" + \"How's your arm?\" said Harry. + \"Fine,\" said Neville, showing them. \"Madam Pomfrey mended it in about a minute.\" + \"Good -- well, look, Neville, we've got to be somewhere, we'll see you later —\" + \"Don't leave me!\" said Neville, scrambling to his feet, \"I don't want to stay here alone, the Bloody Baron's been past twice already.\" + Ron looked at his watch and then glared furiously at Hermione and Neville. + \"If either of you get us caught, I'll never rest until I've learned that Curse of the Bogies Quirrell told us about, and used it on you.\" + Hermione opened her mouth, perhaps to tell Ron exactly how to use the Curse of the Bogies, but Harry hissed at her to be quiet and beckoned them all forward. + They flitted along corridors striped with bars of moonlight from the high windows. At every turn Harry expected to run into Filch or Mrs. Norris, but they were lucky. They sped up a staircase to the third floor and tiptoed toward the trophy room. + Malfoy and Crabbe weren't there yet. The crystal trophy cases glimmered where the moonlight caught them. Cups, shields, plates, and statues winked silver and gold in the darkness. They edged along the walls, keeping their eyes on the doors at either end of the room. Harry took out his wand in case Malfoy leapt in and started at once. The minutes crept by. + \"He's late, maybe he's chickened out,\" Ron whispered. + Then a noise in the next room made them jump. Harry had only just raised his wand when they heard someone speak -- and it wasn't Malfoy. + \"Sniff around, my sweet, they might be lurking in a corner.\" + It was Filch speaking to Mrs. Norris. Horror-struck, Harry waved madly at the other three to follow him as quickly as possible; they scurried silently toward the door, away from Filch's voice. Neville's robes had barely whipped round the corner when they heard Filch enter the trophy room. + \"They're in here somewhere,\" they heard him mutter, \"probably hiding.\" + \"This way!\" Harry mouthed to the others and, petrified, they began to creep down a long gallery full of suits of armor. + They could hear Filch getting nearer. Neville suddenly let out a frightened squeak and broke into a run -- he tripped, grabbed Ron around the waist, and the pair of them toppled right into a suit of armor. + The clanging and crashing were enough to wake the whole castle. + \"RUN!\" Harry yelled, and the four of them sprinted down the gallery, not looking back to see whether Filch was following -- they swung around the doorpost and galloped down one corridor then another, Harry in the lead, without any idea where they were or where they were going -- they ripped through a tapestry and found themselves in a hidden passageway, hurtled along it and came out near their Charms classroom, which they knew was miles from the trophy room. + \"I think we've lost him,\" Harry panted, leaning against the cold wall and wiping his forehead. Neville was bent double, wheezing and spluttering. + \"I -- @told -- you,\" Hermione gasped, clutching at the stitch in her chest, \"I -- told -- you.\" + \"We've got to get back to Gryffindor Tower,\" said Ron, \"quickly as possible.\" + \"Malfoy tricked you,\" Hermione said to Harry. \"You realize that, don't you? He was never going to meet you -- Filch knew someone was going to be in the trophy room, Malfoy must have tipped him off.\" + Harry thought she was probably right, but he wasn't going to tell her that. + \"Let's go.\" + It wasn't going to be that simple. They hadn't gone more than a dozen paces when a doorknob rattled and something came shooting out of a classroom in front of them. + It was Peeves. He caught sight of them and gave a squeal of delight. + \"Shut up, Peeves -- please -- you'll get us thrown out.\" + Peeves cackled. + \"Wandering around at midnight, Ickle Firsties? Tut, tut, tut. Naughty, naughty, you'll get caughty.\" + \"Not if you don't give us away, Peeves, please.\" + \"Should tell Filch, I should,\" said Peeves in a saintly voice, but his eyes glittered wickedly. \"It's for your own good, you know.\" + \"Get out of the way,\" snapped Ron, taking a swipe at Peeves -- this was a big mistake. + \"STUDENTS OUT OF BED!\" Peeves bellowed, \"STUDENTS OUT OF BED DOWN THE CHARMS CORRIDOR!\" + Ducking under Peeves, they ran for their lives, right to the end of the corridor where they slammed into a door -- and it was locked. + \"This is it!\" Ron moaned, as they pushed helplessly at the door, \"We're done for! This is the end!\" + They could hear footsteps, Filch running as fast as he could toward Peeves's shouts. + \"Oh, move over,\" Hermione snarled. She grabbed Harry's wand, tapped the lock, and whispered, @\"Alohomora!\" + The lock clicked and the door swung open -- they piled through it, shut it quickly, and pressed their ears against it, listening. + \"Which way did they go, Peeves?\" Filch was saying. \"Quick, tell me.\" \"Say ‘please.'\" + \"Don't mess with me, Peeves, now @where @did @they @go?\" \"Shan't say nothing if you don't say please,\" said Peeves in his annoying singsong voice. \"All right -- @please.\" + \"NOTHING! Ha haaa! Told you I wouldn't say nothing if you didn't say please! Ha ha! Haaaaaa!\" And they heard the sound of Peeves whooshing away and Filch cursing in rage. + \"He thinks this door is locked,\" Harry whispered. \"I think we'll be okay -- get @off, Neville!\" For Neville had been tugging on the sleeve of Harry's bathrobe for the last minute. @\"What?\" + Harry turned around -- and saw, quite clearly, what. For a moment, he was sure he'd walked into a nightmare -- this was too much, on top of everything that had happened so far. + They weren't in a room, as he had supposed. They were in a corridor. The forbidden corridor on the third floor. And now they knew why it was forbidden. + They were looking straight into the eyes of a monstrous dog, a dog that filled the whole space between ceiling and floor. It had three heads. Three pairs of rolling, mad eyes; three noses, twitching and quivering in their direction; three drooling mouths, saliva hanging in slippery ropes from yellowish fangs. + It was standing quite still, all six eyes staring at them, and Harry knew that the only reason they weren't already dead was that their sudden appearance had taken it by surprise, but it was quickly getting over that, there was no mistaking what those thunderous growls meant. + Harry groped for the doorknob -- between Filch and death, he'd take Filch. + They fell backward -- Harry slammed the door shut, and they ran, they almost flew, back down the corridor. Filch must have hurried off to look for them somewhere else, because they didn't see him anywhere, but they hardly cared -- all they wanted to do was put as much space as possible between them and that monster. They didn't stop running until they reached the portrait of the Fat Lady on the seventh floor. + \"Where on earth have you all been?\" she asked, looking at their bathrobes hanging off their shoulders and their flushed, sweaty faces. + \"Never mind that -- pig snout, pig snout,\" panted Harry, and the portrait swung forward. They scrambled into the common room and collapsed, trembling, into armchairs. + It was a while before any of them said anything. Neville, indeed, looked as if he'd never speak again. + \"What do they think they're doing, keeping a thing like that locked up in a school?\" said Ron finally. \"If any dog needs exercise, that one does.\" + Hermione had got both her breath and her bad temper back again. + \"You don't use your eyes, any of you, do you?\" she snapped. \"Didn't you see what it was standing on?\" + \"The floor?\" Harry suggested. \"I wasn't looking at its feet, I was too busy with its heads.\" + \"No, @not the floor. It was standing on a trapdoor. It's obviously guarding something.\" + She stood up, glaring at them. + \"I hope you're pleased with yourselves. We could all have been killed -- or worse, expelled. Now, if you don't mind, I'm going to bed.\" + Ron stared after her, his mouth open. \"No, we don't mind,\" he said. \"You'd think we dragged her along, wouldn't you?\" + But Hermione had given Harry something else to think about as he climbed back into bed. The dog was guarding something. . . . What had Hagrid said? Gringotts was the safest place in the world for something you wanted to hide -- except perhaps Hogwarts. + It looked as though Harry had found out where the grubby little package from vault seven hundred and thirteen was. + \n"
     ]
    }
   ],
   "source": [
    "chapter_nine_text = \"\"\n",
    "for row in mat_contents['words'][0]:\n",
    "    chapter_nine_text += row[0][0][0][0] + \" \"\n",
    "print(chapter_nine_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align fMRI scans with sets of 4 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample:\n",
      "\tScan time: 20\n",
      "\tInput words: ['Harry', 'had', 'never', 'believed']\n",
      "Created sample:\n",
      "\tScan time: 22\n",
      "\tInput words: ['he', 'would', 'meet', 'a']\n",
      "Created sample:\n",
      "\tScan time: 24\n",
      "\tInput words: ['boy', 'he', 'hated', 'more']\n",
      "Created sample:\n",
      "\tScan time: 26\n",
      "\tInput words: ['than', 'Dudley,', 'but', 'that']\n",
      "Created sample:\n",
      "\tScan time: 28\n",
      "\tInput words: ['was', 'before', 'he', 'met']\n",
      "Created sample:\n",
      "\tScan time: 30\n",
      "\tInput words: ['Draco', 'Malfoy.', 'Still,', 'first-year']\n",
      "Created sample:\n",
      "\tScan time: 32\n",
      "\tInput words: ['Gryffindors', 'only', 'had', 'Potions']\n",
      "Created sample:\n",
      "\tScan time: 34\n",
      "\tInput words: ['with', 'the', 'Slytherins,', 'so']\n",
      "Created sample:\n",
      "\tScan time: 36\n",
      "\tInput words: ['they', \"didn't\", 'have', 'to']\n",
      "Created sample:\n",
      "\tScan time: 38\n",
      "\tInput words: ['put', 'up', 'with', 'Malfoy']\n",
      "Created sample:\n",
      "\tScan time: 40\n",
      "\tInput words: ['much.', 'Or', 'at', 'least,']\n",
      "Created sample:\n",
      "\tScan time: 42\n",
      "\tInput words: ['they', \"didn't\", 'until', 'they']\n",
      "Created sample:\n",
      "\tScan time: 44\n",
      "\tInput words: ['spotted', 'a', 'notice', 'pinned']\n",
      "Created sample:\n",
      "\tScan time: 46\n",
      "\tInput words: ['up', 'in', 'the', 'Gryffindor']\n",
      "Created sample:\n",
      "\tScan time: 48\n",
      "\tInput words: ['common', 'room', 'that', 'made']\n",
      "Created sample:\n",
      "\tScan time: 50\n",
      "\tInput words: ['them', 'all', 'groan.', 'Flying']\n",
      "Created sample:\n",
      "\tScan time: 52\n",
      "\tInput words: ['lessons', 'would', 'be', 'starting']\n",
      "Created sample:\n",
      "\tScan time: 54\n",
      "\tInput words: ['on', 'Thursday', '--', 'and']\n",
      "Created sample:\n",
      "\tScan time: 56\n",
      "\tInput words: ['Gryffindor', 'and', 'Slytherin', 'would']\n",
      "Created sample:\n",
      "\tScan time: 58\n",
      "\tInput words: ['be', 'learning', 'together.', '+']\n",
      "Created sample:\n",
      "\tScan time: 60\n",
      "\tInput words: ['\"Typical,\"', 'said', 'Harry', 'darkly.']\n",
      "Created sample:\n",
      "\tScan time: 62\n",
      "\tInput words: ['\"Just', 'what', 'I', 'always']\n",
      "Created sample:\n",
      "\tScan time: 64\n",
      "\tInput words: ['wanted.', 'To', 'make', 'a']\n",
      "Created sample:\n",
      "\tScan time: 66\n",
      "\tInput words: ['fool', 'of', 'myself', 'on']\n",
      "Created sample:\n",
      "\tScan time: 68\n",
      "\tInput words: ['a', 'broomstick', 'in', 'front']\n",
      "Created sample:\n",
      "\tScan time: 70\n",
      "\tInput words: ['of', 'Malfoy.\"', '+', 'He']\n",
      "Created sample:\n",
      "\tScan time: 72\n",
      "\tInput words: ['had', 'been', 'looking', 'forward']\n",
      "Created sample:\n",
      "\tScan time: 74\n",
      "\tInput words: ['to', 'learning', 'to', 'fly']\n",
      "Created sample:\n",
      "\tScan time: 76\n",
      "\tInput words: ['more', 'than', 'anything', 'else.']\n",
      "Created sample:\n",
      "\tScan time: 78\n",
      "\tInput words: ['\"You', \"don't\", 'know', 'that']\n",
      "Created sample:\n",
      "\tScan time: 80\n",
      "\tInput words: [\"you'll\", 'make', 'a', 'fool']\n",
      "Created sample:\n",
      "\tScan time: 82\n",
      "\tInput words: ['of', 'yourself,\"', 'said', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 84\n",
      "\tInput words: ['reasonably.', '\"Anyway,', 'I', 'know']\n",
      "Created sample:\n",
      "\tScan time: 86\n",
      "\tInput words: [\"Malfoy's\", 'always', 'going', 'on']\n",
      "Created sample:\n",
      "\tScan time: 88\n",
      "\tInput words: ['about', 'how', 'good', 'he']\n",
      "Created sample:\n",
      "\tScan time: 90\n",
      "\tInput words: ['is', 'at', 'Quidditch,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 92\n",
      "\tInput words: ['I', 'bet', \"that's\", 'all']\n",
      "Created sample:\n",
      "\tScan time: 94\n",
      "\tInput words: ['talk.\"', '+', 'Malfoy', 'certainly']\n",
      "Created sample:\n",
      "\tScan time: 96\n",
      "\tInput words: ['did', 'talk', 'about', 'flying']\n",
      "Created sample:\n",
      "\tScan time: 98\n",
      "\tInput words: ['a', 'lot.', 'He', 'complained']\n",
      "Created sample:\n",
      "\tScan time: 100\n",
      "\tInput words: ['loudly', 'about', 'first', 'years']\n",
      "Created sample:\n",
      "\tScan time: 102\n",
      "\tInput words: ['never', 'getting', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 104\n",
      "\tInput words: ['House', 'Quidditch', 'teams', 'and']\n",
      "Created sample:\n",
      "\tScan time: 106\n",
      "\tInput words: ['told', 'long,', 'boastful', 'stories']\n",
      "Created sample:\n",
      "\tScan time: 108\n",
      "\tInput words: ['that', 'always', 'seemed', 'to']\n",
      "Created sample:\n",
      "\tScan time: 110\n",
      "\tInput words: ['end', 'with', 'him', 'narrowly']\n",
      "Created sample:\n",
      "\tScan time: 112\n",
      "\tInput words: ['escaping', 'Muggles', 'in', 'helicopters.']\n",
      "Created sample:\n",
      "\tScan time: 114\n",
      "\tInput words: ['He', \"wasn't\", 'the', 'only']\n",
      "Created sample:\n",
      "\tScan time: 116\n",
      "\tInput words: ['one,', 'though:', 'the', 'way']\n",
      "Created sample:\n",
      "\tScan time: 118\n",
      "\tInput words: ['Seamus', 'Finnigan', 'told', 'it,']\n",
      "Created sample:\n",
      "\tScan time: 120\n",
      "\tInput words: [\"he'd\", 'spent', 'most', 'of']\n",
      "Created sample:\n",
      "\tScan time: 122\n",
      "\tInput words: ['his', 'childhood', 'zooming', 'around']\n",
      "Created sample:\n",
      "\tScan time: 124\n",
      "\tInput words: ['the', 'countryside', 'on', 'his']\n",
      "Created sample:\n",
      "\tScan time: 126\n",
      "\tInput words: ['broomstick.', 'Even', 'Ron', 'would']\n",
      "Created sample:\n",
      "\tScan time: 128\n",
      "\tInput words: ['tell', 'anyone', \"who'd\", 'listen']\n",
      "Created sample:\n",
      "\tScan time: 130\n",
      "\tInput words: ['about', 'the', 'time', \"he'd\"]\n",
      "Created sample:\n",
      "\tScan time: 132\n",
      "\tInput words: ['almost', 'hit', 'a', 'hang']\n",
      "Created sample:\n",
      "\tScan time: 134\n",
      "\tInput words: ['glider', 'on', \"Charlie's\", 'old']\n",
      "Created sample:\n",
      "\tScan time: 136\n",
      "\tInput words: ['broom.', 'Everyone', 'from', 'wizarding']\n",
      "Created sample:\n",
      "\tScan time: 138\n",
      "\tInput words: ['families', 'talked', 'about', 'Quidditch']\n",
      "Created sample:\n",
      "\tScan time: 140\n",
      "\tInput words: ['constantly.', 'Ron', 'had', 'already']\n",
      "Created sample:\n",
      "\tScan time: 142\n",
      "\tInput words: ['had', 'a', 'big', 'argument']\n",
      "Created sample:\n",
      "\tScan time: 144\n",
      "\tInput words: ['with', 'Dean', 'Thomas,', 'who']\n",
      "Created sample:\n",
      "\tScan time: 146\n",
      "\tInput words: ['shared', 'their', 'dormitory,', 'about']\n",
      "Created sample:\n",
      "\tScan time: 148\n",
      "\tInput words: ['soccer.', 'Ron', \"couldn't\", 'see']\n",
      "Created sample:\n",
      "\tScan time: 150\n",
      "\tInput words: ['what', 'was', 'exciting', 'about']\n",
      "Created sample:\n",
      "\tScan time: 152\n",
      "\tInput words: ['a', 'game', 'with', 'only']\n",
      "Created sample:\n",
      "\tScan time: 154\n",
      "\tInput words: ['one', 'ball', 'where', 'no']\n",
      "Created sample:\n",
      "\tScan time: 156\n",
      "\tInput words: ['one', 'was', 'allowed', 'to']\n",
      "Created sample:\n",
      "\tScan time: 158\n",
      "\tInput words: ['fly.', 'Harry', 'had', 'caught']\n",
      "Created sample:\n",
      "\tScan time: 160\n",
      "\tInput words: ['Ron', 'prodding', \"Dean's\", 'poster']\n",
      "Created sample:\n",
      "\tScan time: 162\n",
      "\tInput words: ['of', 'West', 'Ham', 'soccer']\n",
      "Created sample:\n",
      "\tScan time: 164\n",
      "\tInput words: ['team,', 'trying', 'to', 'make']\n",
      "Created sample:\n",
      "\tScan time: 166\n",
      "\tInput words: ['the', 'players', 'move.', '+']\n",
      "Created sample:\n",
      "\tScan time: 168\n",
      "\tInput words: ['Neville', 'had', 'never', 'been']\n",
      "Created sample:\n",
      "\tScan time: 170\n",
      "\tInput words: ['on', 'a', 'broomstick', 'in']\n",
      "Created sample:\n",
      "\tScan time: 172\n",
      "\tInput words: ['his', 'life,', 'because', 'his']\n",
      "Created sample:\n",
      "\tScan time: 174\n",
      "\tInput words: ['grandmother', 'had', 'never', 'let']\n",
      "Created sample:\n",
      "\tScan time: 176\n",
      "\tInput words: ['him', 'near', 'one.', 'Privately,']\n",
      "Created sample:\n",
      "\tScan time: 178\n",
      "\tInput words: ['Harry', 'felt', \"she'd\", 'had']\n",
      "Created sample:\n",
      "\tScan time: 180\n",
      "\tInput words: ['good', 'reason,', 'because', 'Neville']\n",
      "Created sample:\n",
      "\tScan time: 182\n",
      "\tInput words: ['managed', 'to', 'have', 'an']\n",
      "Created sample:\n",
      "\tScan time: 184\n",
      "\tInput words: ['extraordinary', 'number', 'of', 'accidents']\n",
      "Created sample:\n",
      "\tScan time: 186\n",
      "\tInput words: ['even', 'with', 'both', 'feet']\n",
      "Created sample:\n",
      "\tScan time: 188\n",
      "\tInput words: ['on', 'the', 'ground.', '+']\n",
      "Created sample:\n",
      "\tScan time: 190\n",
      "\tInput words: ['Hermione', 'Granger', 'was', 'almost']\n",
      "Created sample:\n",
      "\tScan time: 192\n",
      "\tInput words: ['as', 'nervous', 'about', 'flying']\n",
      "Created sample:\n",
      "\tScan time: 194\n",
      "\tInput words: ['as', 'Neville', 'was.', 'This']\n",
      "Created sample:\n",
      "\tScan time: 196\n",
      "\tInput words: ['was', 'something', 'you', \"couldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 198\n",
      "\tInput words: ['learn', 'by', 'heart', 'out']\n",
      "Created sample:\n",
      "\tScan time: 200\n",
      "\tInput words: ['of', 'a', 'book', '--']\n",
      "Created sample:\n",
      "\tScan time: 202\n",
      "\tInput words: ['not', 'that', 'she', \"hadn't\"]\n",
      "Created sample:\n",
      "\tScan time: 204\n",
      "\tInput words: ['tried.', 'At', 'breakfast', 'on']\n",
      "Created sample:\n",
      "\tScan time: 206\n",
      "\tInput words: ['Thursday', 'she', 'bored', 'them']\n",
      "Created sample:\n",
      "\tScan time: 208\n",
      "\tInput words: ['all', 'stupid', 'with', 'flying']\n",
      "Created sample:\n",
      "\tScan time: 210\n",
      "\tInput words: ['tips', \"she'd\", 'gotten', 'out']\n",
      "Created sample:\n",
      "\tScan time: 212\n",
      "\tInput words: ['of', 'a', 'library', 'book']\n",
      "Created sample:\n",
      "\tScan time: 214\n",
      "\tInput words: ['called', '@Quidditch', '@Through', '@the']\n",
      "Created sample:\n",
      "\tScan time: 216\n",
      "\tInput words: ['@Ages.', 'Neville', 'was', 'hanging']\n",
      "Created sample:\n",
      "\tScan time: 218\n",
      "\tInput words: ['on', 'to', 'her', 'every']\n",
      "Created sample:\n",
      "\tScan time: 220\n",
      "\tInput words: ['word,', 'desperate', 'for', 'anything']\n",
      "Created sample:\n",
      "\tScan time: 222\n",
      "\tInput words: ['that', 'might', 'help', 'him']\n",
      "Created sample:\n",
      "\tScan time: 224\n",
      "\tInput words: ['hang', 'on', 'to', 'his']\n",
      "Created sample:\n",
      "\tScan time: 226\n",
      "\tInput words: ['broomstick', 'later,', 'but', 'everybody']\n",
      "Created sample:\n",
      "\tScan time: 228\n",
      "\tInput words: ['else', 'was', 'very', 'pleased']\n",
      "Created sample:\n",
      "\tScan time: 230\n",
      "\tInput words: ['when', \"Hermione's\", 'lecture', 'was']\n",
      "Created sample:\n",
      "\tScan time: 232\n",
      "\tInput words: ['interrupted', 'by', 'the', 'arrival']\n",
      "Created sample:\n",
      "\tScan time: 234\n",
      "\tInput words: ['of', 'the', 'mail.', '+']\n",
      "Created sample:\n",
      "\tScan time: 236\n",
      "\tInput words: ['Harry', \"hadn't\", 'had', 'a']\n",
      "Created sample:\n",
      "\tScan time: 238\n",
      "\tInput words: ['single', 'letter', 'since', \"Hagrid's\"]\n",
      "Created sample:\n",
      "\tScan time: 240\n",
      "\tInput words: ['note,', 'something', 'that', 'Malfoy']\n",
      "Created sample:\n",
      "\tScan time: 242\n",
      "\tInput words: ['had', 'been', 'quick', 'to']\n",
      "Created sample:\n",
      "\tScan time: 244\n",
      "\tInput words: ['notice,', 'of', 'course.', \"Malfoy's\"]\n",
      "Created sample:\n",
      "\tScan time: 246\n",
      "\tInput words: ['eagle', 'owl', 'was', 'always']\n",
      "Created sample:\n",
      "\tScan time: 248\n",
      "\tInput words: ['bringing', 'him', 'packages', 'of']\n",
      "Created sample:\n",
      "\tScan time: 250\n",
      "\tInput words: ['sweets', 'from', 'home,', 'which']\n",
      "Created sample:\n",
      "\tScan time: 252\n",
      "\tInput words: ['he', 'opened', 'gloatingly', 'at']\n",
      "Created sample:\n",
      "\tScan time: 254\n",
      "\tInput words: ['the', 'Slytherin', 'table.', '+']\n",
      "Created sample:\n",
      "\tScan time: 256\n",
      "\tInput words: ['A', 'barn', 'owl', 'brought']\n",
      "Created sample:\n",
      "\tScan time: 258\n",
      "\tInput words: ['Neville', 'a', 'small', 'package']\n",
      "Created sample:\n",
      "\tScan time: 260\n",
      "\tInput words: ['from', 'his', 'grandmother.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 262\n",
      "\tInput words: ['opened', 'it', 'excitedly', 'and']\n",
      "Created sample:\n",
      "\tScan time: 264\n",
      "\tInput words: ['showed', 'them', 'a', 'glass']\n",
      "Created sample:\n",
      "\tScan time: 266\n",
      "\tInput words: ['ball', 'the', 'size', 'of']\n",
      "Created sample:\n",
      "\tScan time: 268\n",
      "\tInput words: ['a', 'large', 'marble,', 'which']\n",
      "Created sample:\n",
      "\tScan time: 270\n",
      "\tInput words: ['seemed', 'to', 'be', 'full']\n",
      "Created sample:\n",
      "\tScan time: 272\n",
      "\tInput words: ['of', 'white', 'smoke.', '+']\n",
      "Created sample:\n",
      "\tScan time: 274\n",
      "\tInput words: ['\"It\\'s', 'a', 'Remembrall!\"', 'he']\n",
      "Created sample:\n",
      "\tScan time: 276\n",
      "\tInput words: ['explained.', '\"Gran', 'knows', 'I']\n",
      "Created sample:\n",
      "\tScan time: 278\n",
      "\tInput words: ['forget', 'things', '--', 'this']\n",
      "Created sample:\n",
      "\tScan time: 280\n",
      "\tInput words: ['tells', 'you', 'if', \"there's\"]\n",
      "Created sample:\n",
      "\tScan time: 282\n",
      "\tInput words: ['something', \"you've\", 'forgotten', 'to']\n",
      "Created sample:\n",
      "\tScan time: 284\n",
      "\tInput words: ['do.', 'Look,', 'you', 'hold']\n",
      "Created sample:\n",
      "\tScan time: 286\n",
      "\tInput words: ['it', 'tight', 'like', 'this']\n",
      "Created sample:\n",
      "\tScan time: 288\n",
      "\tInput words: ['and', 'if', 'it', 'turns']\n",
      "Created sample:\n",
      "\tScan time: 290\n",
      "\tInput words: ['red', '--', 'oh', '…\"']\n",
      "Created sample:\n",
      "\tScan time: 292\n",
      "\tInput words: ['His', 'face', 'fell,', 'because']\n",
      "Created sample:\n",
      "\tScan time: 294\n",
      "\tInput words: ['the', 'Remembrall', 'had', 'suddenly']\n",
      "Created sample:\n",
      "\tScan time: 296\n",
      "\tInput words: ['glowed', 'scarlet,', '\"…', \"you've\"]\n",
      "Created sample:\n",
      "\tScan time: 298\n",
      "\tInput words: ['forgotten', 'something', '…\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 300\n",
      "\tInput words: ['Neville', 'was', 'trying', 'to']\n",
      "Created sample:\n",
      "\tScan time: 302\n",
      "\tInput words: ['remember', 'what', \"he'd\", 'forgotten']\n",
      "Created sample:\n",
      "\tScan time: 304\n",
      "\tInput words: ['when', 'Draco', 'Malfoy,', 'who']\n",
      "Created sample:\n",
      "\tScan time: 306\n",
      "\tInput words: ['was', 'passing', 'the', 'Gryffindor']\n",
      "Created sample:\n",
      "\tScan time: 308\n",
      "\tInput words: ['table,', 'snatched', 'the', 'Remembrall']\n",
      "Created sample:\n",
      "\tScan time: 310\n",
      "\tInput words: ['out', 'of', 'his', 'hand.']\n",
      "Created sample:\n",
      "\tScan time: 312\n",
      "\tInput words: ['+', 'Harry', 'and', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 314\n",
      "\tInput words: ['jumped', 'to', 'their', 'feet.']\n",
      "Created sample:\n",
      "\tScan time: 316\n",
      "\tInput words: ['They', 'were', 'half', 'hoping']\n",
      "Created sample:\n",
      "\tScan time: 318\n",
      "\tInput words: ['for', 'a', 'reason', 'to']\n",
      "Created sample:\n",
      "\tScan time: 320\n",
      "\tInput words: ['fight', 'Malfoy,', 'but', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 322\n",
      "\tInput words: ['McGonagall,', 'who', 'could', 'spot']\n",
      "Created sample:\n",
      "\tScan time: 324\n",
      "\tInput words: ['trouble', 'quicker', 'than', 'any']\n",
      "Created sample:\n",
      "\tScan time: 326\n",
      "\tInput words: ['teacher', 'in', 'the', 'school,']\n",
      "Created sample:\n",
      "\tScan time: 328\n",
      "\tInput words: ['was', 'there', 'in', 'a']\n",
      "Created sample:\n",
      "\tScan time: 330\n",
      "\tInput words: ['flash.', '+', '\"What\\'s', 'going']\n",
      "Created sample:\n",
      "\tScan time: 332\n",
      "\tInput words: ['on?\"', '+', '\"Malfoy\\'s', 'got']\n",
      "Created sample:\n",
      "\tScan time: 334\n",
      "\tInput words: ['my', 'Remembrall,', 'Professor.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 336\n",
      "\tInput words: ['Scowling,', 'Malfoy', 'quickly', 'dropped']\n",
      "Created sample:\n",
      "\tScan time: 338\n",
      "\tInput words: ['the', 'Remembrall', 'back', 'on']\n",
      "Created sample:\n",
      "\tScan time: 340\n",
      "\tInput words: ['the', 'table.', '+', '\"Just']\n",
      "Created sample:\n",
      "\tScan time: 342\n",
      "\tInput words: ['looking,\"', 'he', 'said,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 344\n",
      "\tInput words: ['he', 'sloped', 'away', 'with']\n",
      "Created sample:\n",
      "\tScan time: 346\n",
      "\tInput words: ['Crabbe', 'and', 'Goyle', 'behind']\n",
      "Created sample:\n",
      "\tScan time: 348\n",
      "\tInput words: ['him.', '+', '+', 'At']\n",
      "Created sample:\n",
      "\tScan time: 350\n",
      "\tInput words: ['three-thirty', 'that', 'afternoon,', 'Harry,']\n",
      "Created sample:\n",
      "\tScan time: 352\n",
      "\tInput words: ['Ron,', 'and', 'the', 'other']\n",
      "Created sample:\n",
      "\tScan time: 354\n",
      "\tInput words: ['Gryffindors', 'hurried', 'down', 'the']\n",
      "Created sample:\n",
      "\tScan time: 356\n",
      "\tInput words: ['front', 'steps', 'onto', 'the']\n",
      "Created sample:\n",
      "\tScan time: 358\n",
      "\tInput words: ['grounds', 'for', 'their', 'first']\n",
      "Created sample:\n",
      "\tScan time: 360\n",
      "\tInput words: ['flying', 'lesson.', 'It', 'was']\n",
      "Created sample:\n",
      "\tScan time: 362\n",
      "\tInput words: ['a', 'clear,', 'breezy', 'day,']\n",
      "Created sample:\n",
      "\tScan time: 364\n",
      "\tInput words: ['and', 'the', 'grass', 'rippled']\n",
      "Created sample:\n",
      "\tScan time: 366\n",
      "\tInput words: ['under', 'their', 'feet', 'as']\n",
      "Created sample:\n",
      "\tScan time: 368\n",
      "\tInput words: ['they', 'marched', 'down', 'the']\n",
      "Created sample:\n",
      "\tScan time: 370\n",
      "\tInput words: ['sloping', 'lawns', 'toward', 'a']\n",
      "Created sample:\n",
      "\tScan time: 372\n",
      "\tInput words: ['smooth,', 'flat', 'lawn', 'on']\n",
      "Created sample:\n",
      "\tScan time: 374\n",
      "\tInput words: ['the', 'opposite', 'side', 'of']\n",
      "Created sample:\n",
      "\tScan time: 376\n",
      "\tInput words: ['the', 'grounds', 'to', 'the']\n",
      "Created sample:\n",
      "\tScan time: 378\n",
      "\tInput words: ['forbidden', 'forest,', 'whose', 'trees']\n",
      "Created sample:\n",
      "\tScan time: 380\n",
      "\tInput words: ['were', 'swaying', 'darkly', 'in']\n",
      "Created sample:\n",
      "\tScan time: 382\n",
      "\tInput words: ['the', 'distance.', '+', 'The']\n",
      "Created sample:\n",
      "\tScan time: 384\n",
      "\tInput words: ['Slytherins', 'were', 'already', 'there,']\n",
      "Created sample:\n",
      "\tScan time: 386\n",
      "\tInput words: ['and', 'so', 'were', 'twenty']\n",
      "Created sample:\n",
      "\tScan time: 388\n",
      "\tInput words: ['broomsticks', 'lying', 'in', 'neat']\n",
      "Created sample:\n",
      "\tScan time: 390\n",
      "\tInput words: ['lines', 'on', 'the', 'ground.']\n",
      "Created sample:\n",
      "\tScan time: 392\n",
      "\tInput words: ['Harry', 'had', 'heard', 'Fred']\n",
      "Created sample:\n",
      "\tScan time: 394\n",
      "\tInput words: ['and', 'George', 'Weasley', 'complain']\n",
      "Created sample:\n",
      "\tScan time: 396\n",
      "\tInput words: ['about', 'the', 'school', 'brooms,']\n",
      "Created sample:\n",
      "\tScan time: 398\n",
      "\tInput words: ['saying', 'that', 'some', 'of']\n",
      "Created sample:\n",
      "\tScan time: 400\n",
      "\tInput words: ['them', 'started', 'to', 'vibrate']\n",
      "Created sample:\n",
      "\tScan time: 402\n",
      "\tInput words: ['if', 'you', 'flew', 'too']\n",
      "Created sample:\n",
      "\tScan time: 404\n",
      "\tInput words: ['high,', 'or', 'always', 'flew']\n",
      "Created sample:\n",
      "\tScan time: 406\n",
      "\tInput words: ['slightly', 'to', 'the', 'left.']\n",
      "Created sample:\n",
      "\tScan time: 408\n",
      "\tInput words: ['+', 'Their', 'teacher,', 'Madam']\n",
      "Created sample:\n",
      "\tScan time: 410\n",
      "\tInput words: ['Hooch,', 'arrived.', 'She', 'had']\n",
      "Created sample:\n",
      "\tScan time: 412\n",
      "\tInput words: ['short,', 'gray', 'hair,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 414\n",
      "\tInput words: ['yellow', 'eyes', 'like', 'a']\n",
      "Created sample:\n",
      "\tScan time: 416\n",
      "\tInput words: ['hawk.', '+', '\"Well,', 'what']\n",
      "Created sample:\n",
      "\tScan time: 418\n",
      "\tInput words: ['are', 'you', 'all', 'waiting']\n",
      "Created sample:\n",
      "\tScan time: 420\n",
      "\tInput words: ['for?\"', 'she', 'barked.', '\"Everyone']\n",
      "Created sample:\n",
      "\tScan time: 422\n",
      "\tInput words: ['stand', 'by', 'a', 'broomstick.']\n",
      "Created sample:\n",
      "\tScan time: 424\n",
      "\tInput words: ['Come', 'on,', 'hurry', 'up.\"']\n",
      "Created sample:\n",
      "\tScan time: 426\n",
      "\tInput words: ['+', 'Harry', 'glanced', 'down']\n",
      "Created sample:\n",
      "\tScan time: 428\n",
      "\tInput words: ['at', 'his', 'broom.', 'It']\n",
      "Created sample:\n",
      "\tScan time: 430\n",
      "\tInput words: ['was', 'old', 'and', 'some']\n",
      "Created sample:\n",
      "\tScan time: 432\n",
      "\tInput words: ['of', 'the', 'twigs', 'stuck']\n",
      "Created sample:\n",
      "\tScan time: 434\n",
      "\tInput words: ['out', 'at', 'odd', 'angles.']\n",
      "Created sample:\n",
      "\tScan time: 436\n",
      "\tInput words: ['+', '\"Stick', 'out', 'your']\n",
      "Created sample:\n",
      "\tScan time: 438\n",
      "\tInput words: ['right', 'hand', 'over', 'your']\n",
      "Created sample:\n",
      "\tScan time: 440\n",
      "\tInput words: ['broom,\"', 'called', 'Madam', 'Hooch']\n",
      "Created sample:\n",
      "\tScan time: 442\n",
      "\tInput words: ['at', 'the', 'front,', '\"and']\n",
      "Created sample:\n",
      "\tScan time: 444\n",
      "\tInput words: ['say', '‘Up!\\'\"', '+', '\"UP!\"']\n",
      "Created sample:\n",
      "\tScan time: 446\n",
      "\tInput words: ['everyone', 'shouted.', '+', \"Harry's\"]\n",
      "Created sample:\n",
      "\tScan time: 448\n",
      "\tInput words: ['broom', 'jumped', 'into', 'his']\n",
      "Created sample:\n",
      "\tScan time: 450\n",
      "\tInput words: ['hand', 'at', 'once,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 452\n",
      "\tInput words: ['it', 'was', 'one', 'of']\n",
      "Created sample:\n",
      "\tScan time: 454\n",
      "\tInput words: ['the', 'few', 'that', 'did.']\n",
      "Created sample:\n",
      "\tScan time: 456\n",
      "\tInput words: ['Hermione', \"Granger's\", 'had', 'simply']\n",
      "Created sample:\n",
      "\tScan time: 458\n",
      "\tInput words: ['rolled', 'over', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 460\n",
      "\tInput words: ['ground,', 'and', \"Neville's\", \"hadn't\"]\n",
      "Created sample:\n",
      "\tScan time: 462\n",
      "\tInput words: ['moved', 'at', 'all.', 'Perhaps']\n",
      "Created sample:\n",
      "\tScan time: 464\n",
      "\tInput words: ['brooms,', 'like', 'horses,', 'could']\n",
      "Created sample:\n",
      "\tScan time: 466\n",
      "\tInput words: ['tell', 'when', 'you', 'were']\n",
      "Created sample:\n",
      "\tScan time: 468\n",
      "\tInput words: ['afraid,', 'thought', 'Harry;', 'there']\n",
      "Created sample:\n",
      "\tScan time: 470\n",
      "\tInput words: ['was', 'a', 'quaver', 'in']\n",
      "Created sample:\n",
      "\tScan time: 472\n",
      "\tInput words: [\"Neville's\", 'voice', 'that', 'said']\n",
      "Created sample:\n",
      "\tScan time: 474\n",
      "\tInput words: ['only', 'too', 'clearly', 'that']\n",
      "Created sample:\n",
      "\tScan time: 476\n",
      "\tInput words: ['he', 'wanted', 'to', 'keep']\n",
      "Created sample:\n",
      "\tScan time: 478\n",
      "\tInput words: ['his', 'feet', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 480\n",
      "\tInput words: ['ground.', '+', 'Madam', 'Hooch']\n",
      "Created sample:\n",
      "\tScan time: 482\n",
      "\tInput words: ['then', 'showed', 'them', 'how']\n",
      "Created sample:\n",
      "\tScan time: 484\n",
      "\tInput words: ['to', 'mount', 'their', 'brooms']\n",
      "Created sample:\n",
      "\tScan time: 486\n",
      "\tInput words: ['without', 'sliding', 'off', 'the']\n",
      "Created sample:\n",
      "\tScan time: 488\n",
      "\tInput words: ['end,', 'and', 'walked', 'up']\n",
      "Created sample:\n",
      "\tScan time: 490\n",
      "\tInput words: ['and', 'down', 'the', 'rows']\n",
      "Created sample:\n",
      "\tScan time: 492\n",
      "\tInput words: ['correcting', 'their', 'grips.', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 494\n",
      "\tInput words: ['and', 'Ron', 'were', 'delighted']\n",
      "Created sample:\n",
      "\tScan time: 496\n",
      "\tInput words: ['when', 'she', 'told', 'Malfoy']\n",
      "Created sample:\n",
      "\tScan time: 498\n",
      "\tInput words: [\"he'd\", 'been', 'doing', 'it']\n",
      "Created sample:\n",
      "\tScan time: 500\n",
      "\tInput words: ['wrong', 'for', 'years.', '+']\n",
      "Created sample:\n",
      "\tScan time: 502\n",
      "\tInput words: ['\"Now,', 'when', 'I', 'blow']\n",
      "Created sample:\n",
      "\tScan time: 504\n",
      "\tInput words: ['my', 'whistle,', 'you', 'kick']\n",
      "Created sample:\n",
      "\tScan time: 506\n",
      "\tInput words: ['off', 'from', 'the', 'ground,']\n",
      "Created sample:\n",
      "\tScan time: 508\n",
      "\tInput words: ['hard,\"', 'said', 'Madam', 'Hooch.']\n",
      "Created sample:\n",
      "\tScan time: 510\n",
      "\tInput words: ['\"Keep', 'your', 'brooms', 'steady,']\n",
      "Created sample:\n",
      "\tScan time: 512\n",
      "\tInput words: ['rise', 'a', 'few', 'feet,']\n",
      "Created sample:\n",
      "\tScan time: 514\n",
      "\tInput words: ['and', 'then', 'come', 'straight']\n",
      "Created sample:\n",
      "\tScan time: 516\n",
      "\tInput words: ['back', 'down', 'by', 'leaning']\n",
      "Created sample:\n",
      "\tScan time: 518\n",
      "\tInput words: ['forward', 'slightly.', 'On', 'my']\n",
      "Created sample:\n",
      "\tScan time: 520\n",
      "\tInput words: ['whistle', '--', 'three', '--']\n",
      "Created sample:\n",
      "\tScan time: 522\n",
      "\tInput words: ['two', '—\"', '+', 'But']\n",
      "Created sample:\n",
      "\tScan time: 524\n",
      "\tInput words: ['Neville,', 'nervous', 'and', 'jumpy']\n",
      "Created sample:\n",
      "\tScan time: 526\n",
      "\tInput words: ['and', 'frightened', 'of', 'being']\n",
      "Created sample:\n",
      "\tScan time: 528\n",
      "\tInput words: ['left', 'on', 'the', 'ground,']\n",
      "Created sample:\n",
      "\tScan time: 530\n",
      "\tInput words: ['pushed', 'off', 'hard', 'before']\n",
      "Created sample:\n",
      "\tScan time: 532\n",
      "\tInput words: ['the', 'whistle', 'had', 'touched']\n",
      "Created sample:\n",
      "\tScan time: 534\n",
      "\tInput words: ['Madam', \"Hooch's\", 'lips.', '+']\n",
      "Created sample:\n",
      "\tScan time: 536\n",
      "\tInput words: ['\"Come', 'back,', 'boy!\"', 'she']\n",
      "Created sample:\n",
      "\tScan time: 538\n",
      "\tInput words: ['shouted,', 'but', 'Neville', 'was']\n",
      "Created sample:\n",
      "\tScan time: 540\n",
      "\tInput words: ['rising', 'straight', 'up', 'like']\n",
      "Created sample:\n",
      "\tScan time: 542\n",
      "\tInput words: ['a', 'cork', 'shot', 'out']\n",
      "Created sample:\n",
      "\tScan time: 544\n",
      "\tInput words: ['of', 'a', 'bottle', '--']\n",
      "Created sample:\n",
      "\tScan time: 546\n",
      "\tInput words: ['twelve', 'feet', '--', 'twenty']\n",
      "Created sample:\n",
      "\tScan time: 548\n",
      "\tInput words: ['feet.', 'Harry', 'saw', 'his']\n",
      "Created sample:\n",
      "\tScan time: 550\n",
      "\tInput words: ['scared', 'white', 'face', 'look']\n",
      "Created sample:\n",
      "\tScan time: 552\n",
      "\tInput words: ['down', 'at', 'the', 'ground']\n",
      "Created sample:\n",
      "\tScan time: 554\n",
      "\tInput words: ['falling', 'away,', 'saw', 'him']\n",
      "Created sample:\n",
      "\tScan time: 556\n",
      "\tInput words: ['gasp,', 'slip', 'sideways', 'off']\n",
      "Created sample:\n",
      "\tScan time: 558\n",
      "\tInput words: ['the', 'broom', 'and', '--']\n",
      "Created sample:\n",
      "\tScan time: 560\n",
      "\tInput words: ['+', 'WHAM', '--', 'a']\n",
      "Created sample:\n",
      "\tScan time: 562\n",
      "\tInput words: ['thud', 'and', 'a', 'nasty']\n",
      "Created sample:\n",
      "\tScan time: 564\n",
      "\tInput words: ['crack', 'and', 'Neville', 'lay']\n",
      "Created sample:\n",
      "\tScan time: 566\n",
      "\tInput words: ['facedown', 'on', 'the', 'grass']\n",
      "Created sample:\n",
      "\tScan time: 568\n",
      "\tInput words: ['in', 'a', 'heap.', 'His']\n",
      "Created sample:\n",
      "\tScan time: 570\n",
      "\tInput words: ['broomstick', 'was', 'still', 'rising']\n",
      "Created sample:\n",
      "\tScan time: 572\n",
      "\tInput words: ['higher', 'and', 'higher,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 574\n",
      "\tInput words: ['started', 'to', 'drift', 'lazily']\n",
      "Created sample:\n",
      "\tScan time: 576\n",
      "\tInput words: ['toward', 'the', 'forbidden', 'forest']\n",
      "Created sample:\n",
      "\tScan time: 578\n",
      "\tInput words: ['and', 'out', 'of', 'sight.']\n",
      "Created sample:\n",
      "\tScan time: 580\n",
      "\tInput words: ['+', 'Madam', 'Hooch', 'was']\n",
      "Created sample:\n",
      "\tScan time: 582\n",
      "\tInput words: ['bending', 'over', 'Neville,', 'her']\n",
      "Created sample:\n",
      "\tScan time: 584\n",
      "\tInput words: ['face', 'as', 'white', 'as']\n",
      "Created sample:\n",
      "\tScan time: 586\n",
      "\tInput words: ['his.', '\"Broken', 'wrist,\"', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 588\n",
      "\tInput words: ['heard', 'her', 'mutter.', '\"Come']\n",
      "Created sample:\n",
      "\tScan time: 590\n",
      "\tInput words: ['on,', 'boy', '--', \"it's\"]\n",
      "Created sample:\n",
      "\tScan time: 592\n",
      "\tInput words: ['all', 'right,', 'up', 'you']\n",
      "Created sample:\n",
      "\tScan time: 594\n",
      "\tInput words: ['get.\"', '+', 'She', 'turned']\n",
      "Created sample:\n",
      "\tScan time: 596\n",
      "\tInput words: ['to', 'the', 'rest', 'of']\n",
      "Created sample:\n",
      "\tScan time: 598\n",
      "\tInput words: ['the', 'class.', '\"None', 'of']\n",
      "Created sample:\n",
      "\tScan time: 600\n",
      "\tInput words: ['you', 'is', 'to', 'move']\n",
      "Created sample:\n",
      "\tScan time: 602\n",
      "\tInput words: ['while', 'I', 'take', 'this']\n",
      "Created sample:\n",
      "\tScan time: 604\n",
      "\tInput words: ['boy', 'to', 'the', 'hospital']\n",
      "Created sample:\n",
      "\tScan time: 606\n",
      "\tInput words: ['wing!', 'You', 'leave', 'those']\n",
      "Created sample:\n",
      "\tScan time: 608\n",
      "\tInput words: ['brooms', 'where', 'they', 'are']\n",
      "Created sample:\n",
      "\tScan time: 610\n",
      "\tInput words: ['or', \"you'll\", 'be', 'out']\n",
      "Created sample:\n",
      "\tScan time: 612\n",
      "\tInput words: ['of', 'Hogwarts', 'before', 'you']\n",
      "Created sample:\n",
      "\tScan time: 614\n",
      "\tInput words: ['can', 'say', \"‘Quidditch.'\", 'Come']\n",
      "Created sample:\n",
      "\tScan time: 616\n",
      "\tInput words: ['on,', 'dear.\"', '+', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 618\n",
      "\tInput words: ['his', 'face', 'tear-streaked,', 'clutching']\n",
      "Created sample:\n",
      "\tScan time: 620\n",
      "\tInput words: ['his', 'wrist,', 'hobbled', 'off']\n",
      "Created sample:\n",
      "\tScan time: 622\n",
      "\tInput words: ['with', 'Madam', 'Hooch,', 'who']\n",
      "Created sample:\n",
      "\tScan time: 624\n",
      "\tInput words: ['had', 'her', 'arm', 'around']\n",
      "Created sample:\n",
      "\tScan time: 626\n",
      "\tInput words: ['him.', '+', 'No', 'sooner']\n",
      "Created sample:\n",
      "\tScan time: 628\n",
      "\tInput words: ['were', 'they', 'out', 'of']\n",
      "Created sample:\n",
      "\tScan time: 630\n",
      "\tInput words: ['earshot', 'than', 'Malfoy', 'burst']\n",
      "Created sample:\n",
      "\tScan time: 632\n",
      "\tInput words: ['into', 'laughter.', '+', '\"Did']\n",
      "Created sample:\n",
      "\tScan time: 634\n",
      "\tInput words: ['you', 'see', 'his', 'face,']\n",
      "Created sample:\n",
      "\tScan time: 636\n",
      "\tInput words: ['the', 'great', 'lump?\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 638\n",
      "\tInput words: ['The', 'other', 'Slytherins', 'joined']\n",
      "Created sample:\n",
      "\tScan time: 640\n",
      "\tInput words: ['in.', '+', '\"Shut', 'up,']\n",
      "Created sample:\n",
      "\tScan time: 642\n",
      "\tInput words: ['Malfoy,\"', 'snapped', 'Parvati', 'Patil.']\n",
      "Created sample:\n",
      "\tScan time: 644\n",
      "\tInput words: ['+', '\"Ooh,', 'sticking', 'up']\n",
      "Created sample:\n",
      "\tScan time: 646\n",
      "\tInput words: ['for', 'Longbottom?\"', 'said', 'Pansy']\n",
      "Created sample:\n",
      "\tScan time: 648\n",
      "\tInput words: ['Parkinson,', 'a', 'hard-faced', 'Slytherin']\n",
      "Created sample:\n",
      "\tScan time: 650\n",
      "\tInput words: ['girl.', '\"Never', 'thought', \"@you'd\"]\n",
      "Created sample:\n",
      "\tScan time: 652\n",
      "\tInput words: ['like', 'fat', 'little', 'crybabies,']\n",
      "Created sample:\n",
      "\tScan time: 654\n",
      "\tInput words: ['Parvati.\"', '+', '\"Look!\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 656\n",
      "\tInput words: ['Malfoy,', 'darting', 'forward', 'and']\n",
      "Created sample:\n",
      "\tScan time: 658\n",
      "\tInput words: ['snatching', 'something', 'out', 'of']\n",
      "Created sample:\n",
      "\tScan time: 660\n",
      "\tInput words: ['the', 'grass.', '\"It\\'s', 'that']\n",
      "Created sample:\n",
      "\tScan time: 662\n",
      "\tInput words: ['stupid', 'thing', \"Longbottom's\", 'gran']\n",
      "Created sample:\n",
      "\tScan time: 664\n",
      "\tInput words: ['sent', 'him.\"', '+', 'The']\n",
      "Created sample:\n",
      "\tScan time: 666\n",
      "\tInput words: ['Remembrall', 'glittered', 'in', 'the']\n",
      "Created sample:\n",
      "\tScan time: 700\n",
      "\tInput words: ['\"Give', 'that', 'here,', 'Malfoy,\"']\n",
      "Created sample:\n",
      "\tScan time: 702\n",
      "\tInput words: ['said', 'Harry', 'quietly.', 'Everyone']\n",
      "Created sample:\n",
      "\tScan time: 704\n",
      "\tInput words: ['stopped', 'talking', 'to', 'watch.']\n",
      "Created sample:\n",
      "\tScan time: 706\n",
      "\tInput words: ['+', 'Malfoy', 'smiled', 'nastily.']\n",
      "Created sample:\n",
      "\tScan time: 708\n",
      "\tInput words: ['\"I', 'think', \"I'll\", 'leave']\n",
      "Created sample:\n",
      "\tScan time: 710\n",
      "\tInput words: ['it', 'somewhere', 'for', 'Longbottom']\n",
      "Created sample:\n",
      "\tScan time: 712\n",
      "\tInput words: ['to', 'find', '--', 'how']\n",
      "Created sample:\n",
      "\tScan time: 714\n",
      "\tInput words: ['about', '--', 'up', 'a']\n",
      "Created sample:\n",
      "\tScan time: 716\n",
      "\tInput words: ['tree?\"', '+', '\"Give', 'it']\n",
      "Created sample:\n",
      "\tScan time: 718\n",
      "\tInput words: ['@here!\"', 'Harry', 'yelled,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 720\n",
      "\tInput words: ['Malfoy', 'had', 'leapt', 'onto']\n",
      "Created sample:\n",
      "\tScan time: 722\n",
      "\tInput words: ['his', 'broomstick', 'and', 'taken']\n",
      "Created sample:\n",
      "\tScan time: 724\n",
      "\tInput words: ['off.', 'He', \"hadn't\", 'been']\n",
      "Created sample:\n",
      "\tScan time: 726\n",
      "\tInput words: ['lying,', 'he', '@could', 'fly']\n",
      "Created sample:\n",
      "\tScan time: 728\n",
      "\tInput words: ['well.', 'Hovering', 'level', 'with']\n",
      "Created sample:\n",
      "\tScan time: 730\n",
      "\tInput words: ['the', 'topmost', 'branches', 'of']\n",
      "Created sample:\n",
      "\tScan time: 732\n",
      "\tInput words: ['an', 'oak', 'he', 'called,']\n",
      "Created sample:\n",
      "\tScan time: 734\n",
      "\tInput words: ['\"Come', 'and', 'get', 'it,']\n",
      "Created sample:\n",
      "\tScan time: 736\n",
      "\tInput words: ['Potter!\"', '+', 'Harry', 'grabbed']\n",
      "Created sample:\n",
      "\tScan time: 738\n",
      "\tInput words: ['his', 'broom.', '+', '@\"No!\"']\n",
      "Created sample:\n",
      "\tScan time: 740\n",
      "\tInput words: ['shouted', 'Hermione', 'Granger.', '\"Madam']\n",
      "Created sample:\n",
      "\tScan time: 742\n",
      "\tInput words: ['Hooch', 'told', 'us', 'not']\n",
      "Created sample:\n",
      "\tScan time: 744\n",
      "\tInput words: ['to', 'move', '--', \"you'll\"]\n",
      "Created sample:\n",
      "\tScan time: 746\n",
      "\tInput words: ['get', 'us', 'all', 'into']\n",
      "Created sample:\n",
      "\tScan time: 748\n",
      "\tInput words: ['trouble.\"', '+', 'Harry', 'ignored']\n",
      "Created sample:\n",
      "\tScan time: 750\n",
      "\tInput words: ['her.', 'Blood', 'was', 'pounding']\n",
      "Created sample:\n",
      "\tScan time: 752\n",
      "\tInput words: ['in', 'his', 'ears.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 754\n",
      "\tInput words: ['mounted', 'the', 'broom', 'and']\n",
      "Created sample:\n",
      "\tScan time: 756\n",
      "\tInput words: ['kicked', 'hard', 'against', 'the']\n",
      "Created sample:\n",
      "\tScan time: 758\n",
      "\tInput words: ['ground', 'and', 'up,', 'up']\n",
      "Created sample:\n",
      "\tScan time: 760\n",
      "\tInput words: ['he', 'soared;', 'air', 'rushed']\n",
      "Created sample:\n",
      "\tScan time: 762\n",
      "\tInput words: ['through', 'his', 'hair,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 764\n",
      "\tInput words: ['his', 'robes', 'whipped', 'out']\n",
      "Created sample:\n",
      "\tScan time: 766\n",
      "\tInput words: ['behind', 'him', '--', 'and']\n",
      "Created sample:\n",
      "\tScan time: 768\n",
      "\tInput words: ['in', 'a', 'rush', 'of']\n",
      "Created sample:\n",
      "\tScan time: 770\n",
      "\tInput words: ['fierce', 'joy', 'he', 'realized']\n",
      "Created sample:\n",
      "\tScan time: 772\n",
      "\tInput words: [\"he'd\", 'found', 'something', 'he']\n",
      "Created sample:\n",
      "\tScan time: 774\n",
      "\tInput words: ['could', 'do', 'without', 'being']\n",
      "Created sample:\n",
      "\tScan time: 776\n",
      "\tInput words: ['taught', '--', 'this', 'was']\n",
      "Created sample:\n",
      "\tScan time: 778\n",
      "\tInput words: ['easy,', 'this', 'was', '@wonderful.']\n",
      "Created sample:\n",
      "\tScan time: 780\n",
      "\tInput words: ['He', 'pulled', 'his', 'broomstick']\n",
      "Created sample:\n",
      "\tScan time: 782\n",
      "\tInput words: ['up', 'a', 'little', 'to']\n",
      "Created sample:\n",
      "\tScan time: 784\n",
      "\tInput words: ['take', 'it', 'even', 'higher,']\n",
      "Created sample:\n",
      "\tScan time: 786\n",
      "\tInput words: ['and', 'heard', 'screams', 'and']\n",
      "Created sample:\n",
      "\tScan time: 788\n",
      "\tInput words: ['gasps', 'of', 'girls', 'back']\n",
      "Created sample:\n",
      "\tScan time: 790\n",
      "\tInput words: ['on', 'the', 'ground', 'and']\n",
      "Created sample:\n",
      "\tScan time: 792\n",
      "\tInput words: ['an', 'admiring', 'whoop', 'from']\n",
      "Created sample:\n",
      "\tScan time: 794\n",
      "\tInput words: ['Ron.', '+', 'He', 'turned']\n",
      "Created sample:\n",
      "\tScan time: 796\n",
      "\tInput words: ['his', 'broomstick', 'sharply', 'to']\n",
      "Created sample:\n",
      "\tScan time: 798\n",
      "\tInput words: ['face', 'Malfoy', 'in', 'midair.']\n",
      "Created sample:\n",
      "\tScan time: 800\n",
      "\tInput words: ['+', 'Malfoy', 'looked', 'stunned.']\n",
      "Created sample:\n",
      "\tScan time: 802\n",
      "\tInput words: ['\"Give', 'it', 'here,\"', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 804\n",
      "\tInput words: ['called,', '\"or', \"I'll\", 'knock']\n",
      "Created sample:\n",
      "\tScan time: 806\n",
      "\tInput words: ['you', 'off', 'that', 'broom!\"']\n",
      "Created sample:\n",
      "\tScan time: 808\n",
      "\tInput words: ['+', '\"Oh,', 'yeah?\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 810\n",
      "\tInput words: ['Malfoy,', 'trying', 'to', 'sneer,']\n",
      "Created sample:\n",
      "\tScan time: 812\n",
      "\tInput words: ['but', 'looking', 'worried.', '+']\n",
      "Created sample:\n",
      "\tScan time: 814\n",
      "\tInput words: ['Harry', 'knew,', 'somehow,', 'what']\n",
      "Created sample:\n",
      "\tScan time: 816\n",
      "\tInput words: ['to', 'do.', 'He', 'leaned']\n",
      "Created sample:\n",
      "\tScan time: 818\n",
      "\tInput words: ['forward', 'and', 'grasped', 'the']\n",
      "Created sample:\n",
      "\tScan time: 820\n",
      "\tInput words: ['broom', 'tightly', 'in', 'both']\n",
      "Created sample:\n",
      "\tScan time: 822\n",
      "\tInput words: ['hands,', 'and', 'it', 'shot']\n",
      "Created sample:\n",
      "\tScan time: 824\n",
      "\tInput words: ['toward', 'Malfoy', 'like', 'a']\n",
      "Created sample:\n",
      "\tScan time: 826\n",
      "\tInput words: ['javelin.', 'Malfoy', 'only', 'just']\n",
      "Created sample:\n",
      "\tScan time: 828\n",
      "\tInput words: ['got', 'out', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 830\n",
      "\tInput words: ['way', 'in', 'time;', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 832\n",
      "\tInput words: ['made', 'a', 'sharp', 'about-face']\n",
      "Created sample:\n",
      "\tScan time: 834\n",
      "\tInput words: ['and', 'held', 'the', 'broom']\n",
      "Created sample:\n",
      "\tScan time: 836\n",
      "\tInput words: ['steady.', 'A', 'few', 'people']\n",
      "Created sample:\n",
      "\tScan time: 838\n",
      "\tInput words: ['below', 'were', 'clapping.', '+']\n",
      "Created sample:\n",
      "\tScan time: 840\n",
      "\tInput words: ['\"No', 'Crabbe', 'and', 'Goyle']\n",
      "Created sample:\n",
      "\tScan time: 842\n",
      "\tInput words: ['up', 'here', 'to', 'save']\n",
      "Created sample:\n",
      "\tScan time: 844\n",
      "\tInput words: ['your', 'neck,', 'Malfoy,\"', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 846\n",
      "\tInput words: ['called.', '+', 'The', 'same']\n",
      "Created sample:\n",
      "\tScan time: 848\n",
      "\tInput words: ['thought', 'seemed', 'to', 'have']\n",
      "Created sample:\n",
      "\tScan time: 850\n",
      "\tInput words: ['struck', 'Malfoy.', '+', '\"Catch']\n",
      "Created sample:\n",
      "\tScan time: 852\n",
      "\tInput words: ['it', 'if', 'you', 'can,']\n",
      "Created sample:\n",
      "\tScan time: 854\n",
      "\tInput words: ['then!\"', 'he', 'shouted,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 856\n",
      "\tInput words: ['he', 'threw', 'the', 'glass']\n",
      "Created sample:\n",
      "\tScan time: 858\n",
      "\tInput words: ['ball', 'high', 'into', 'the']\n",
      "Created sample:\n",
      "\tScan time: 860\n",
      "\tInput words: ['air', 'and', 'streaked', 'back']\n",
      "Created sample:\n",
      "\tScan time: 862\n",
      "\tInput words: ['toward', 'the', 'ground.', '+']\n",
      "Created sample:\n",
      "\tScan time: 864\n",
      "\tInput words: ['Harry', 'saw,', 'as', 'though']\n",
      "Created sample:\n",
      "\tScan time: 866\n",
      "\tInput words: ['in', 'slow', 'motion,', 'the']\n",
      "Created sample:\n",
      "\tScan time: 868\n",
      "\tInput words: ['ball', 'rise', 'up', 'in']\n",
      "Created sample:\n",
      "\tScan time: 870\n",
      "\tInput words: ['the', 'air', 'and', 'then']\n",
      "Created sample:\n",
      "\tScan time: 872\n",
      "\tInput words: ['start', 'to', 'fall.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 874\n",
      "\tInput words: ['leaned', 'forward', 'and', 'pointed']\n",
      "Created sample:\n",
      "\tScan time: 876\n",
      "\tInput words: ['his', 'broom', 'handle', 'down']\n",
      "Created sample:\n",
      "\tScan time: 878\n",
      "\tInput words: ['--', 'next', 'second', 'he']\n",
      "Created sample:\n",
      "\tScan time: 880\n",
      "\tInput words: ['was', 'gathering', 'speed', 'in']\n",
      "Created sample:\n",
      "\tScan time: 882\n",
      "\tInput words: ['a', 'steep', 'dive,', 'racing']\n",
      "Created sample:\n",
      "\tScan time: 884\n",
      "\tInput words: ['the', 'ball', '--', 'wind']\n",
      "Created sample:\n",
      "\tScan time: 886\n",
      "\tInput words: ['whistled', 'in', 'his', 'ears,']\n",
      "Created sample:\n",
      "\tScan time: 888\n",
      "\tInput words: ['mingled', 'with', 'the', 'screams']\n",
      "Created sample:\n",
      "\tScan time: 890\n",
      "\tInput words: ['of', 'people', 'watching', '--']\n",
      "Created sample:\n",
      "\tScan time: 892\n",
      "\tInput words: ['he', 'stretched', 'out', 'his']\n",
      "Created sample:\n",
      "\tScan time: 894\n",
      "\tInput words: ['hand', '--', 'a', 'foot']\n",
      "Created sample:\n",
      "\tScan time: 896\n",
      "\tInput words: ['from', 'the', 'ground', 'he']\n",
      "Created sample:\n",
      "\tScan time: 898\n",
      "\tInput words: ['caught', 'it,', 'just', 'in']\n",
      "Created sample:\n",
      "\tScan time: 900\n",
      "\tInput words: ['time', 'to', 'pull', 'his']\n",
      "Created sample:\n",
      "\tScan time: 902\n",
      "\tInput words: ['broom', 'straight,', 'and', 'he']\n",
      "Created sample:\n",
      "\tScan time: 904\n",
      "\tInput words: ['toppled', 'gently', 'onto', 'the']\n",
      "Created sample:\n",
      "\tScan time: 906\n",
      "\tInput words: ['grass', 'with', 'the', 'Remembrall']\n",
      "Created sample:\n",
      "\tScan time: 908\n",
      "\tInput words: ['clutched', 'safely', 'in', 'his']\n",
      "Created sample:\n",
      "\tScan time: 910\n",
      "\tInput words: ['fist.', '+', '\"HARRY', 'POTTER!\"']\n",
      "Created sample:\n",
      "\tScan time: 912\n",
      "\tInput words: ['+', 'His', 'heart', 'sank']\n",
      "Created sample:\n",
      "\tScan time: 914\n",
      "\tInput words: ['faster', 'than', \"he'd\", 'just']\n",
      "Created sample:\n",
      "\tScan time: 916\n",
      "\tInput words: ['dived.', 'Professor', 'McGonagall', 'was']\n",
      "Created sample:\n",
      "\tScan time: 918\n",
      "\tInput words: ['running', 'toward', 'them.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 920\n",
      "\tInput words: ['got', 'to', 'his', 'feet,']\n",
      "Created sample:\n",
      "\tScan time: 922\n",
      "\tInput words: ['trembling.', '+', '@\"Never', '--']\n",
      "Created sample:\n",
      "\tScan time: 924\n",
      "\tInput words: ['in', 'all', 'my', 'time']\n",
      "Created sample:\n",
      "\tScan time: 926\n",
      "\tInput words: ['at', 'Hogwarts', '—\"', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 928\n",
      "\tInput words: ['McGonagall', 'was', 'almost', 'speechless']\n",
      "Created sample:\n",
      "\tScan time: 930\n",
      "\tInput words: ['with', 'shock,', 'and', 'her']\n",
      "Created sample:\n",
      "\tScan time: 932\n",
      "\tInput words: ['glasses', 'flashed', 'furiously,', '\"—']\n",
      "Created sample:\n",
      "\tScan time: 934\n",
      "\tInput words: ['how', '@dare', 'you', '--']\n",
      "Created sample:\n",
      "\tScan time: 936\n",
      "\tInput words: ['might', 'have', 'broken', 'your']\n",
      "Created sample:\n",
      "\tScan time: 938\n",
      "\tInput words: ['neck', '—\"', '+', '\"It']\n",
      "Created sample:\n",
      "\tScan time: 940\n",
      "\tInput words: [\"wasn't\", 'his', 'fault,', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 942\n",
      "\tInput words: ['—\"', '+', '\"Be', 'quiet,']\n",
      "Created sample:\n",
      "\tScan time: 944\n",
      "\tInput words: ['Miss', 'Patil', '—\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 946\n",
      "\tInput words: ['\"But', 'Malfoy', '—\"', '\"That\\'s']\n",
      "Created sample:\n",
      "\tScan time: 948\n",
      "\tInput words: ['enough,', 'Mr.', 'Weasley.', 'Potter,']\n",
      "Created sample:\n",
      "\tScan time: 950\n",
      "\tInput words: ['follow', 'me,', 'now.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 952\n",
      "\tInput words: ['Harry', 'caught', 'sight', 'of']\n",
      "Created sample:\n",
      "\tScan time: 954\n",
      "\tInput words: ['Malfoy,', 'Crabbe,', 'and', \"Goyle's\"]\n",
      "Created sample:\n",
      "\tScan time: 956\n",
      "\tInput words: ['triumphant', 'faces', 'as', 'he']\n",
      "Created sample:\n",
      "\tScan time: 958\n",
      "\tInput words: ['left,', 'walking', 'numbly', 'in']\n",
      "Created sample:\n",
      "\tScan time: 960\n",
      "\tInput words: ['Professor', \"McGonagall's\", 'wake', 'as']\n",
      "Created sample:\n",
      "\tScan time: 962\n",
      "\tInput words: ['she', 'strode', 'toward', 'the']\n",
      "Created sample:\n",
      "\tScan time: 964\n",
      "\tInput words: ['castle.', 'He', 'was', 'going']\n",
      "Created sample:\n",
      "\tScan time: 966\n",
      "\tInput words: ['to', 'be', 'expelled,', 'he']\n",
      "Created sample:\n",
      "\tScan time: 968\n",
      "\tInput words: ['just', 'knew', 'it.', 'He']\n",
      "Created sample:\n",
      "\tScan time: 970\n",
      "\tInput words: ['wanted', 'to', 'say', 'something']\n",
      "Created sample:\n",
      "\tScan time: 972\n",
      "\tInput words: ['to', 'defend', 'himself,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 974\n",
      "\tInput words: ['there', 'seemed', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 976\n",
      "\tInput words: ['something', 'wrong', 'with', 'his']\n",
      "Created sample:\n",
      "\tScan time: 978\n",
      "\tInput words: ['voice.', 'Professor', 'McGonagall', 'was']\n",
      "Created sample:\n",
      "\tScan time: 980\n",
      "\tInput words: ['sweeping', 'along', 'without', 'even']\n",
      "Created sample:\n",
      "\tScan time: 982\n",
      "\tInput words: ['looking', 'at', 'him;', 'he']\n",
      "Created sample:\n",
      "\tScan time: 984\n",
      "\tInput words: ['had', 'to', 'jog', 'to']\n",
      "Created sample:\n",
      "\tScan time: 986\n",
      "\tInput words: ['keep', 'up.', 'Now', \"he'd\"]\n",
      "Created sample:\n",
      "\tScan time: 988\n",
      "\tInput words: ['done', 'it.', 'He', \"hadn't\"]\n",
      "Created sample:\n",
      "\tScan time: 990\n",
      "\tInput words: ['even', 'lasted', 'two', 'weeks.']\n",
      "Created sample:\n",
      "\tScan time: 992\n",
      "\tInput words: [\"He'd\", 'be', 'packing', 'his']\n",
      "Created sample:\n",
      "\tScan time: 994\n",
      "\tInput words: ['bags', 'in', 'ten', 'minutes.']\n",
      "Created sample:\n",
      "\tScan time: 996\n",
      "\tInput words: ['What', 'would', 'the', 'Dursleys']\n",
      "Created sample:\n",
      "\tScan time: 998\n",
      "\tInput words: ['say', 'when', 'he', 'turned']\n",
      "Created sample:\n",
      "\tScan time: 1000\n",
      "\tInput words: ['up', 'on', 'the', 'doorstep?']\n",
      "Created sample:\n",
      "\tScan time: 1002\n",
      "\tInput words: ['+', 'Up', 'the', 'front']\n",
      "Created sample:\n",
      "\tScan time: 1004\n",
      "\tInput words: ['steps,', 'up', 'the', 'marble']\n",
      "Created sample:\n",
      "\tScan time: 1006\n",
      "\tInput words: ['staircase', 'inside,', 'and', 'still']\n",
      "Created sample:\n",
      "\tScan time: 1008\n",
      "\tInput words: ['Professor', 'McGonagall', \"didn't\", 'say']\n",
      "Created sample:\n",
      "\tScan time: 1010\n",
      "\tInput words: ['a', 'word', 'to', 'him.']\n",
      "Created sample:\n",
      "\tScan time: 1012\n",
      "\tInput words: ['She', 'wrenched', 'open', 'doors']\n",
      "Created sample:\n",
      "\tScan time: 1014\n",
      "\tInput words: ['and', 'marched', 'along', 'corridors']\n",
      "Created sample:\n",
      "\tScan time: 1016\n",
      "\tInput words: ['with', 'Harry', 'trotting', 'miserably']\n",
      "Created sample:\n",
      "\tScan time: 1018\n",
      "\tInput words: ['behind', 'her.', 'Maybe', 'she']\n",
      "Created sample:\n",
      "\tScan time: 1020\n",
      "\tInput words: ['was', 'taking', 'him', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1022\n",
      "\tInput words: ['Dumbledore.', 'He', 'thought', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1024\n",
      "\tInput words: ['Hagrid,', 'expelled', 'but', 'allowed']\n",
      "Created sample:\n",
      "\tScan time: 1026\n",
      "\tInput words: ['to', 'stay', 'on', 'as']\n",
      "Created sample:\n",
      "\tScan time: 1028\n",
      "\tInput words: ['gamekeeper.', 'Perhaps', 'he', 'could']\n",
      "Created sample:\n",
      "\tScan time: 1030\n",
      "\tInput words: ['be', \"Hagrid's\", 'assistant.', 'His']\n",
      "Created sample:\n",
      "\tScan time: 1032\n",
      "\tInput words: ['stomach', 'twisted', 'as', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1034\n",
      "\tInput words: ['imagined', 'it,', 'watching', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 1036\n",
      "\tInput words: ['and', 'the', 'others', 'becoming']\n",
      "Created sample:\n",
      "\tScan time: 1038\n",
      "\tInput words: ['wizards', 'while', 'he', 'stumped']\n",
      "Created sample:\n",
      "\tScan time: 1040\n",
      "\tInput words: ['around', 'the', 'grounds', 'carrying']\n",
      "Created sample:\n",
      "\tScan time: 1042\n",
      "\tInput words: [\"Hagrid's\", 'bag.', '+', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 1044\n",
      "\tInput words: ['McGonagall', 'stopped', 'outside', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1046\n",
      "\tInput words: ['classroom.', 'She', 'opened', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1048\n",
      "\tInput words: ['door', 'and', 'poked', 'her']\n",
      "Created sample:\n",
      "\tScan time: 1050\n",
      "\tInput words: ['head', 'inside.', '+', '\"Excuse']\n",
      "Created sample:\n",
      "\tScan time: 1052\n",
      "\tInput words: ['me,', 'Professor', 'Flitwick,', 'could']\n",
      "Created sample:\n",
      "\tScan time: 1054\n",
      "\tInput words: ['I', 'borrow', 'Wood', 'for']\n",
      "Created sample:\n",
      "\tScan time: 1056\n",
      "\tInput words: ['a', 'moment?\"', '+', 'Wood?']\n",
      "Created sample:\n",
      "\tScan time: 1058\n",
      "\tInput words: ['thought', 'Harry,', 'bewildered;', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1060\n",
      "\tInput words: ['Wood', 'a', 'cane', 'she']\n",
      "Created sample:\n",
      "\tScan time: 1062\n",
      "\tInput words: ['was', 'going', 'to', 'use']\n",
      "Created sample:\n",
      "\tScan time: 1064\n",
      "\tInput words: ['on', 'him?', 'But', 'Wood']\n",
      "Created sample:\n",
      "\tScan time: 1066\n",
      "\tInput words: ['turned', 'out', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1068\n",
      "\tInput words: ['a', 'person,', 'a', 'burly']\n",
      "Created sample:\n",
      "\tScan time: 1070\n",
      "\tInput words: ['fifth-year', 'boy', 'who', 'came']\n",
      "Created sample:\n",
      "\tScan time: 1072\n",
      "\tInput words: ['out', 'of', \"Flitwick's\", 'class']\n",
      "Created sample:\n",
      "\tScan time: 1074\n",
      "\tInput words: ['looking', 'confused.', '+', '\"Follow']\n",
      "Created sample:\n",
      "\tScan time: 1076\n",
      "\tInput words: ['me,', 'you', 'two,\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 1078\n",
      "\tInput words: ['Professor', 'McGonagall,', 'and', 'they']\n",
      "Created sample:\n",
      "\tScan time: 1080\n",
      "\tInput words: ['marched', 'on', 'up', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1082\n",
      "\tInput words: ['corridor,', 'Wood', 'looking', 'curiously']\n",
      "Created sample:\n",
      "\tScan time: 1084\n",
      "\tInput words: ['at', 'Harry.', '+', '\"In']\n",
      "Created sample:\n",
      "\tScan time: 1086\n",
      "\tInput words: ['here.\"', '+', 'Professor', 'McGonagall']\n",
      "Created sample:\n",
      "\tScan time: 1088\n",
      "\tInput words: ['pointed', 'them', 'into', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1090\n",
      "\tInput words: ['classroom', 'that', 'was', 'empty']\n",
      "Created sample:\n",
      "\tScan time: 1092\n",
      "\tInput words: ['except', 'for', 'Peeves,', 'who']\n",
      "Created sample:\n",
      "\tScan time: 1094\n",
      "\tInput words: ['was', 'busy', 'writing', 'rude']\n",
      "Created sample:\n",
      "\tScan time: 1096\n",
      "\tInput words: ['words', 'on', 'the', 'blackboard.']\n",
      "Created sample:\n",
      "\tScan time: 1098\n",
      "\tInput words: ['+', '\"Out,', 'Peeves!\"', 'she']\n",
      "Created sample:\n",
      "\tScan time: 1100\n",
      "\tInput words: ['barked.', 'Peeves', 'threw', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1102\n",
      "\tInput words: ['chalk', 'into', 'a', 'bin,']\n",
      "Created sample:\n",
      "\tScan time: 1104\n",
      "\tInput words: ['which', 'clanged', 'loudly,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1106\n",
      "\tInput words: ['he', 'swooped', 'out', 'cursing.']\n",
      "Created sample:\n",
      "\tScan time: 1108\n",
      "\tInput words: ['Professor', 'McGonagall', 'slammed', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1110\n",
      "\tInput words: ['door', 'behind', 'him', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1112\n",
      "\tInput words: ['turned', 'to', 'face', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1114\n",
      "\tInput words: ['two', 'boys.', '+', '\"Potter,']\n",
      "Created sample:\n",
      "\tScan time: 1116\n",
      "\tInput words: ['this', 'is', 'Oliver', 'Wood.']\n",
      "Created sample:\n",
      "\tScan time: 1118\n",
      "\tInput words: ['Wood', '--', \"I've\", 'found']\n",
      "Created sample:\n",
      "\tScan time: 1120\n",
      "\tInput words: ['you', 'a', 'Seeker.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1122\n",
      "\tInput words: [\"Wood's\", 'expression', 'changed', 'from']\n",
      "Created sample:\n",
      "\tScan time: 1124\n",
      "\tInput words: ['puzzlement', 'to', 'delight.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1126\n",
      "\tInput words: ['\"Are', 'you', 'serious,', 'Professor?\"']\n",
      "Created sample:\n",
      "\tScan time: 1128\n",
      "\tInput words: ['+', '\"Absolutely,\"', 'said', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 1130\n",
      "\tInput words: ['McGonagall', 'crisply.', '\"The', \"boy's\"]\n",
      "Created sample:\n",
      "\tScan time: 1132\n",
      "\tInput words: ['a', 'natural.', \"I've\", 'never']\n",
      "Created sample:\n",
      "\tScan time: 1134\n",
      "\tInput words: ['seen', 'anything', 'like', 'it.']\n",
      "Created sample:\n",
      "\tScan time: 1136\n",
      "\tInput words: ['Was', 'that', 'your', 'first']\n",
      "Created sample:\n",
      "\tScan time: 1138\n",
      "\tInput words: ['time', 'on', 'a', 'broomstick,']\n",
      "Created sample:\n",
      "\tScan time: 1140\n",
      "\tInput words: ['Potter?\"', '+', 'Harry', 'nodded']\n",
      "Created sample:\n",
      "\tScan time: 1142\n",
      "\tInput words: ['silently.', 'He', \"didn't\", 'have']\n",
      "Created sample:\n",
      "\tScan time: 1144\n",
      "\tInput words: ['a', 'clue', 'what', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1146\n",
      "\tInput words: ['going', 'on,', 'but', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1148\n",
      "\tInput words: [\"didn't\", 'seem', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1150\n",
      "\tInput words: ['being', 'expelled,', 'and', 'some']\n",
      "Created sample:\n",
      "\tScan time: 1152\n",
      "\tInput words: ['of', 'the', 'feeling', 'started']\n",
      "Created sample:\n",
      "\tScan time: 1154\n",
      "\tInput words: ['coming', 'back', 'to', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1156\n",
      "\tInput words: ['legs.', '+', '\"He', 'caught']\n",
      "Created sample:\n",
      "\tScan time: 1158\n",
      "\tInput words: ['that', 'thing', 'in', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1160\n",
      "\tInput words: ['hand', 'after', 'a', 'fifty-foot']\n",
      "Created sample:\n",
      "\tScan time: 1162\n",
      "\tInput words: ['dive,\"', 'Professor', 'McGonagall', 'told']\n",
      "Created sample:\n",
      "\tScan time: 1164\n",
      "\tInput words: ['Wood.', '\"Didn\\'t', 'even', 'scratch']\n",
      "Created sample:\n",
      "\tScan time: 1166\n",
      "\tInput words: ['himself.', 'Charlie', 'Weasley', \"couldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 1168\n",
      "\tInput words: ['have', 'done', 'it.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1170\n",
      "\tInput words: ['Wood', 'was', 'now', 'looking']\n",
      "Created sample:\n",
      "\tScan time: 1172\n",
      "\tInput words: ['as', 'though', 'all', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1174\n",
      "\tInput words: ['dreams', 'had', 'come', 'true']\n",
      "Created sample:\n",
      "\tScan time: 1176\n",
      "\tInput words: ['at', 'once.', '+', '\"Ever']\n",
      "Created sample:\n",
      "\tScan time: 1178\n",
      "\tInput words: ['seen', 'a', 'game', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1180\n",
      "\tInput words: ['Quidditch,', 'Potter?\"', 'he', 'asked']\n",
      "Created sample:\n",
      "\tScan time: 1182\n",
      "\tInput words: ['excitedly.', '+', '\"Wood\\'s', 'captain']\n",
      "Created sample:\n",
      "\tScan time: 1184\n",
      "\tInput words: ['of', 'the', 'Gryffindor', 'team,\"']\n",
      "Created sample:\n",
      "\tScan time: 1186\n",
      "\tInput words: ['Professor', 'McGonagall', 'explained.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1188\n",
      "\tInput words: ['\"He\\'s', 'just', 'the', 'build']\n",
      "Created sample:\n",
      "\tScan time: 1190\n",
      "\tInput words: ['for', 'a', 'Seeker,', 'too,\"']\n",
      "Created sample:\n",
      "\tScan time: 1192\n",
      "\tInput words: ['said', 'Wood,', 'now', 'walking']\n",
      "Created sample:\n",
      "\tScan time: 1194\n",
      "\tInput words: ['around', 'Harry', 'and', 'staring']\n",
      "Created sample:\n",
      "\tScan time: 1196\n",
      "\tInput words: ['at', 'him.', '\"Light', '--']\n",
      "Created sample:\n",
      "\tScan time: 1198\n",
      "\tInput words: ['speedy', '--', \"we'll\", 'have']\n",
      "Created sample:\n",
      "\tScan time: 1200\n",
      "\tInput words: ['to', 'get', 'him', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1202\n",
      "\tInput words: ['decent', 'broom,', 'Professor', '--']\n",
      "Created sample:\n",
      "\tScan time: 1204\n",
      "\tInput words: ['a', 'Nimbus', 'Two', 'Thousand']\n",
      "Created sample:\n",
      "\tScan time: 1206\n",
      "\tInput words: ['or', 'a', 'Cleansweep', 'Seven,']\n",
      "Created sample:\n",
      "\tScan time: 1208\n",
      "\tInput words: [\"I'd\", 'say.\"', '+', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 1210\n",
      "\tInput words: ['shall', 'speak', 'to', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 1212\n",
      "\tInput words: ['Dumbledore', 'and', 'see', 'if']\n",
      "Created sample:\n",
      "\tScan time: 1214\n",
      "\tInput words: ['we', \"can't\", 'bend', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1216\n",
      "\tInput words: ['first-year', 'rule.', 'Heaven', 'knows,']\n",
      "Created sample:\n",
      "\tScan time: 1218\n",
      "\tInput words: ['we', 'need', 'a', 'better']\n",
      "Created sample:\n",
      "\tScan time: 1220\n",
      "\tInput words: ['team', 'than', 'last', 'year.']\n",
      "Created sample:\n",
      "\tScan time: 1222\n",
      "\tInput words: ['Flattened', 'in', 'that', 'last']\n",
      "Created sample:\n",
      "\tScan time: 1224\n",
      "\tInput words: ['match', 'by', 'Slytherin,', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1226\n",
      "\tInput words: [\"couldn't\", 'look', 'Severus', 'Snape']\n",
      "Created sample:\n",
      "\tScan time: 1228\n",
      "\tInput words: ['in', 'the', 'face', 'for']\n",
      "Created sample:\n",
      "\tScan time: 1230\n",
      "\tInput words: ['weeks.', '….\"', '+', 'Professor']\n",
      "Created sample:\n",
      "\tScan time: 1232\n",
      "\tInput words: ['McGonagall', 'peered', 'sternly', 'over']\n",
      "Created sample:\n",
      "\tScan time: 1234\n",
      "\tInput words: ['her', 'glasses', 'at', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 1236\n",
      "\tInput words: ['+', '\"I', 'want', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1238\n",
      "\tInput words: ['hear', \"you're\", 'training', 'hard,']\n",
      "Created sample:\n",
      "\tScan time: 1240\n",
      "\tInput words: ['Potter,', 'or', 'I', 'may']\n",
      "Created sample:\n",
      "\tScan time: 1242\n",
      "\tInput words: ['change', 'my', 'mind', 'about']\n",
      "Created sample:\n",
      "\tScan time: 1244\n",
      "\tInput words: ['punishing', 'you.\"', '+', 'Then']\n",
      "Created sample:\n",
      "\tScan time: 1246\n",
      "\tInput words: ['she', 'suddenly', 'smiled.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1248\n",
      "\tInput words: ['\"Your', 'father', 'would', 'have']\n",
      "Created sample:\n",
      "\tScan time: 1250\n",
      "\tInput words: ['been', 'proud,\"', 'she', 'said.']\n",
      "Created sample:\n",
      "\tScan time: 1252\n",
      "\tInput words: ['\"He', 'was', 'an', 'excellent']\n",
      "Created sample:\n",
      "\tScan time: 1254\n",
      "\tInput words: ['Quidditch', 'player', 'himself.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1256\n",
      "\tInput words: ['+', '\"You\\'re', '@joking.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1258\n",
      "\tInput words: ['It', 'was', 'dinnertime.', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 1260\n",
      "\tInput words: ['had', 'just', 'finished', 'telling']\n",
      "Created sample:\n",
      "\tScan time: 1262\n",
      "\tInput words: ['Ron', 'what', 'had', 'happened']\n",
      "Created sample:\n",
      "\tScan time: 1264\n",
      "\tInput words: ['when', \"he'd\", 'left', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1266\n",
      "\tInput words: ['grounds', 'with', 'Professor', 'McGonagall.']\n",
      "Created sample:\n",
      "\tScan time: 1268\n",
      "\tInput words: ['Ron', 'had', 'a', 'piece']\n",
      "Created sample:\n",
      "\tScan time: 1270\n",
      "\tInput words: ['of', 'steak', 'and', 'kidney']\n",
      "Created sample:\n",
      "\tScan time: 1272\n",
      "\tInput words: ['pie', 'halfway', 'to', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1274\n",
      "\tInput words: ['mouth,', 'but', \"he'd\", 'forgotten']\n",
      "Created sample:\n",
      "\tScan time: 1276\n",
      "\tInput words: ['all', 'about', 'it.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1278\n",
      "\tInput words: ['@\"Seeker?\"', 'he', 'said.', '\"But']\n",
      "Created sample:\n",
      "\tScan time: 1280\n",
      "\tInput words: ['first', 'years', '@never', '--']\n",
      "Created sample:\n",
      "\tScan time: 1282\n",
      "\tInput words: ['you', 'must', 'be', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1284\n",
      "\tInput words: ['youngest', 'House', 'player', 'in']\n",
      "Created sample:\n",
      "\tScan time: 1286\n",
      "\tInput words: ['about', '—\"', '+', '\"—']\n",
      "Created sample:\n",
      "\tScan time: 1288\n",
      "\tInput words: ['a', 'century,\"', 'said', 'Harry,']\n",
      "Created sample:\n",
      "\tScan time: 1290\n",
      "\tInput words: ['shoveling', 'pie', 'into', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1292\n",
      "\tInput words: ['mouth.', 'He', 'felt', 'particularly']\n",
      "Created sample:\n",
      "\tScan time: 1294\n",
      "\tInput words: ['hungry', 'after', 'the', 'excitement']\n",
      "Created sample:\n",
      "\tScan time: 1296\n",
      "\tInput words: ['of', 'the', 'afternoon.', '\"Wood']\n",
      "Created sample:\n",
      "\tScan time: 1298\n",
      "\tInput words: ['told', 'me.\"', '+', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 1300\n",
      "\tInput words: ['was', 'so', 'amazed,', 'so']\n",
      "Created sample:\n",
      "\tScan time: 1302\n",
      "\tInput words: ['impressed,', 'he', 'just', 'sat']\n",
      "Created sample:\n",
      "\tScan time: 1304\n",
      "\tInput words: ['and', 'gaped', 'at', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 1306\n",
      "\tInput words: ['+', '\"I', 'start', 'training']\n",
      "Created sample:\n",
      "\tScan time: 1308\n",
      "\tInput words: ['next', 'week,\"', 'said', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 1310\n",
      "\tInput words: ['\"Only', \"don't\", 'tell', 'anyone,']\n",
      "Created sample:\n",
      "\tScan time: 1312\n",
      "\tInput words: ['Wood', 'wants', 'to', 'keep']\n",
      "Created sample:\n",
      "\tScan time: 1314\n",
      "\tInput words: ['it', 'a', 'secret.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1316\n",
      "\tInput words: ['Fred', 'and', 'George', 'Weasley']\n",
      "Created sample:\n",
      "\tScan time: 1318\n",
      "\tInput words: ['now', 'came', 'into', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1320\n",
      "\tInput words: ['hall,', 'spotted', 'Harry,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1322\n",
      "\tInput words: ['hurried', 'over.', '+', '\"Well']\n",
      "Created sample:\n",
      "\tScan time: 1324\n",
      "\tInput words: ['done,\"', 'said', 'George', 'in']\n",
      "Created sample:\n",
      "\tScan time: 1326\n",
      "\tInput words: ['a', 'low', 'voice.', '\"Wood']\n",
      "Created sample:\n",
      "\tScan time: 1328\n",
      "\tInput words: ['told', 'us.', \"We're\", 'on']\n",
      "Created sample:\n",
      "\tScan time: 1330\n",
      "\tInput words: ['the', 'team', 'too', '--']\n",
      "Created sample:\n",
      "\tScan time: 1332\n",
      "\tInput words: ['Beaters.\"', '+', '\"I', 'tell']\n",
      "Created sample:\n",
      "\tScan time: 1334\n",
      "\tInput words: ['you,', \"we're\", 'going', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1336\n",
      "\tInput words: ['win', 'that', 'Quidditch', 'Cup']\n",
      "Created sample:\n",
      "\tScan time: 1338\n",
      "\tInput words: ['for', 'sure', 'this', 'year,\"']\n",
      "Created sample:\n",
      "\tScan time: 1340\n",
      "\tInput words: ['said', 'Fred.', '\"We', \"haven't\"]\n",
      "Created sample:\n",
      "\tScan time: 1342\n",
      "\tInput words: ['won', 'since', 'Charlie', 'left,']\n",
      "Created sample:\n",
      "\tScan time: 1344\n",
      "\tInput words: ['but', 'this', \"year's\", 'team']\n",
      "Created sample:\n",
      "\tScan time: 1346\n",
      "\tInput words: ['is', 'going', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1348\n",
      "\tInput words: ['brilliant.', 'You', 'must', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1350\n",
      "\tInput words: ['good,', 'Harry,', 'Wood', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1352\n",
      "\tInput words: ['almost', 'skipping', 'when', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1354\n",
      "\tInput words: ['told', 'us.\"', '+', '\"Anyway,']\n",
      "Created sample:\n",
      "\tScan time: 1356\n",
      "\tInput words: [\"we've\", 'got', 'to', 'go,']\n",
      "Created sample:\n",
      "\tScan time: 1358\n",
      "\tInput words: ['Lee', 'Jordan', 'reckons', \"he's\"]\n",
      "Created sample:\n",
      "\tScan time: 1360\n",
      "\tInput words: ['found', 'a', 'new', 'secret']\n",
      "Created sample:\n",
      "\tScan time: 1362\n",
      "\tInput words: ['passageway', 'out', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1364\n",
      "\tInput words: ['school.\"', '+', '\"Bet', \"it's\"]\n",
      "Created sample:\n",
      "\tScan time: 1366\n",
      "\tInput words: ['that', 'one', 'behind', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1368\n",
      "\tInput words: ['statue', 'of', 'Gregory', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1370\n",
      "\tInput words: ['Smarmy', 'that', 'we', 'found']\n",
      "Created sample:\n",
      "\tScan time: 1404\n",
      "\tInput words: ['Fred', 'and', 'George', 'had']\n",
      "Created sample:\n",
      "\tScan time: 1406\n",
      "\tInput words: ['hardly', 'disappeared', 'when', 'someone']\n",
      "Created sample:\n",
      "\tScan time: 1408\n",
      "\tInput words: ['far', 'less', 'welcome', 'turned']\n",
      "Created sample:\n",
      "\tScan time: 1410\n",
      "\tInput words: ['up:', 'Malfoy,', 'flanked', 'by']\n",
      "Created sample:\n",
      "\tScan time: 1412\n",
      "\tInput words: ['Crabbe', 'and', 'Goyle.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1414\n",
      "\tInput words: ['\"Having', 'a', 'last', 'meal,']\n",
      "Created sample:\n",
      "\tScan time: 1416\n",
      "\tInput words: ['Potter?', 'When', 'are', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1418\n",
      "\tInput words: ['getting', 'the', 'train', 'back']\n",
      "Created sample:\n",
      "\tScan time: 1420\n",
      "\tInput words: ['to', 'the', 'Muggles?\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1422\n",
      "\tInput words: ['\"You\\'re', 'a', 'lot', 'braver']\n",
      "Created sample:\n",
      "\tScan time: 1424\n",
      "\tInput words: ['now', 'that', \"you're\", 'back']\n",
      "Created sample:\n",
      "\tScan time: 1426\n",
      "\tInput words: ['on', 'the', 'ground', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1428\n",
      "\tInput words: [\"you've\", 'got', 'your', 'little']\n",
      "Created sample:\n",
      "\tScan time: 1430\n",
      "\tInput words: ['friends', 'with', 'you,\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 1432\n",
      "\tInput words: ['Harry', 'coolly.', 'There', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1434\n",
      "\tInput words: ['of', 'course', 'nothing', 'at']\n",
      "Created sample:\n",
      "\tScan time: 1436\n",
      "\tInput words: ['all', 'little', 'about', 'Crabbe']\n",
      "Created sample:\n",
      "\tScan time: 1438\n",
      "\tInput words: ['and', 'Goyle,', 'but', 'as']\n",
      "Created sample:\n",
      "\tScan time: 1440\n",
      "\tInput words: ['the', 'High', 'Table', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1442\n",
      "\tInput words: ['full', 'of', 'teachers,', 'neither']\n",
      "Created sample:\n",
      "\tScan time: 1444\n",
      "\tInput words: ['of', 'them', 'could', 'do']\n",
      "Created sample:\n",
      "\tScan time: 1446\n",
      "\tInput words: ['more', 'than', 'crack', 'their']\n",
      "Created sample:\n",
      "\tScan time: 1448\n",
      "\tInput words: ['knuckles', 'and', 'scowl.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1450\n",
      "\tInput words: ['\"I\\'d', 'take', 'you', 'on']\n",
      "Created sample:\n",
      "\tScan time: 1452\n",
      "\tInput words: ['anytime', 'on', 'my', 'own,\"']\n",
      "Created sample:\n",
      "\tScan time: 1454\n",
      "\tInput words: ['said', 'Malfoy.', '\"Tonight,', 'if']\n",
      "Created sample:\n",
      "\tScan time: 1456\n",
      "\tInput words: ['you', 'want.', \"Wizard's\", 'duel.']\n",
      "Created sample:\n",
      "\tScan time: 1458\n",
      "\tInput words: ['Wands', 'only', '--', 'no']\n",
      "Created sample:\n",
      "\tScan time: 1460\n",
      "\tInput words: ['contact.', \"What's\", 'the', 'matter?']\n",
      "Created sample:\n",
      "\tScan time: 1462\n",
      "\tInput words: ['Never', 'heard', 'of', 'a']\n",
      "Created sample:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScan time: 1464\n",
      "\tInput words: [\"wizard's\", 'duel', 'before,', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1466\n",
      "\tInput words: ['suppose?\"', '+', '\"Of', 'course']\n",
      "Created sample:\n",
      "\tScan time: 1468\n",
      "\tInput words: ['he', 'has,\"', 'said', 'Ron,']\n",
      "Created sample:\n",
      "\tScan time: 1470\n",
      "\tInput words: ['wheeling', 'around.', '\"I\\'m', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1472\n",
      "\tInput words: ['second,', \"who's\", 'yours?\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1474\n",
      "\tInput words: ['Malfoy', 'looked', 'at', 'Crabbe']\n",
      "Created sample:\n",
      "\tScan time: 1476\n",
      "\tInput words: ['and', 'Goyle,', 'sizing', 'them']\n",
      "Created sample:\n",
      "\tScan time: 1478\n",
      "\tInput words: ['up.', '+', '\"Crabbe,\"', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1480\n",
      "\tInput words: ['said.', '\"Midnight', 'all', 'right?']\n",
      "Created sample:\n",
      "\tScan time: 1482\n",
      "\tInput words: [\"We'll\", 'meet', 'you', 'in']\n",
      "Created sample:\n",
      "\tScan time: 1484\n",
      "\tInput words: ['the', 'trophy', 'room;', \"that's\"]\n",
      "Created sample:\n",
      "\tScan time: 1486\n",
      "\tInput words: ['always', 'unlocked.\"', '+', 'When']\n",
      "Created sample:\n",
      "\tScan time: 1488\n",
      "\tInput words: ['Malfoy', 'had', 'gone,', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 1490\n",
      "\tInput words: ['and', 'Harry', 'looked', 'at']\n",
      "Created sample:\n",
      "\tScan time: 1492\n",
      "\tInput words: ['each', 'other.', '+', '\"What']\n",
      "Created sample:\n",
      "\tScan time: 1494\n",
      "\tInput words: ['@is', 'a', \"wizard's\", 'duel?\"']\n",
      "Created sample:\n",
      "\tScan time: 1496\n",
      "\tInput words: ['said', 'Harry.', '\"And', 'what']\n",
      "Created sample:\n",
      "\tScan time: 1498\n",
      "\tInput words: ['do', 'you', 'mean,', \"you're\"]\n",
      "Created sample:\n",
      "\tScan time: 1500\n",
      "\tInput words: ['my', 'second?\"', '+', '\"Well,']\n",
      "Created sample:\n",
      "\tScan time: 1502\n",
      "\tInput words: ['a', \"second's\", 'there', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1504\n",
      "\tInput words: ['take', 'over', 'if', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1506\n",
      "\tInput words: ['die,\"', 'said', 'Ron', 'casually,']\n",
      "Created sample:\n",
      "\tScan time: 1508\n",
      "\tInput words: ['getting', 'started', 'at', 'last']\n",
      "Created sample:\n",
      "\tScan time: 1510\n",
      "\tInput words: ['on', 'his', 'cold', 'pie.']\n",
      "Created sample:\n",
      "\tScan time: 1512\n",
      "\tInput words: ['Catching', 'the', 'look', 'on']\n",
      "Created sample:\n",
      "\tScan time: 1514\n",
      "\tInput words: [\"Harry's\", 'face,', 'he', 'added']\n",
      "Created sample:\n",
      "\tScan time: 1516\n",
      "\tInput words: ['quickly,', '\"But', 'people', 'only']\n",
      "Created sample:\n",
      "\tScan time: 1518\n",
      "\tInput words: ['die', 'in', 'proper', 'duels,']\n",
      "Created sample:\n",
      "\tScan time: 1520\n",
      "\tInput words: ['you', 'know,', 'with', 'real']\n",
      "Created sample:\n",
      "\tScan time: 1522\n",
      "\tInput words: ['wizards.', 'The', 'most', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1524\n",
      "\tInput words: ['and', \"Malfoy'll\", 'be', 'able']\n",
      "Created sample:\n",
      "\tScan time: 1526\n",
      "\tInput words: ['to', 'do', 'is', 'send']\n",
      "Created sample:\n",
      "\tScan time: 1528\n",
      "\tInput words: ['sparks', 'at', 'each', 'other.']\n",
      "Created sample:\n",
      "\tScan time: 1530\n",
      "\tInput words: ['Neither', 'of', 'you', 'knows']\n",
      "Created sample:\n",
      "\tScan time: 1532\n",
      "\tInput words: ['enough', 'magic', 'to', 'do']\n",
      "Created sample:\n",
      "\tScan time: 1534\n",
      "\tInput words: ['any', 'real', 'damage.', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1536\n",
      "\tInput words: ['bet', 'he', 'expected', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1538\n",
      "\tInput words: ['to', 'refuse,', 'anyway.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1540\n",
      "\tInput words: ['\"And', 'what', 'if', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1542\n",
      "\tInput words: ['wave', 'my', 'wand', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1544\n",
      "\tInput words: ['nothing', 'happens?\"', '+', '\"Throw']\n",
      "Created sample:\n",
      "\tScan time: 1546\n",
      "\tInput words: ['it', 'away', 'and', 'punch']\n",
      "Created sample:\n",
      "\tScan time: 1548\n",
      "\tInput words: ['him', 'on', 'the', 'nose,\"']\n",
      "Created sample:\n",
      "\tScan time: 1550\n",
      "\tInput words: ['Ron', 'suggested.', '+', '\"Excuse']\n",
      "Created sample:\n",
      "\tScan time: 1552\n",
      "\tInput words: ['me.\"', '+', 'They', 'both']\n",
      "Created sample:\n",
      "\tScan time: 1554\n",
      "\tInput words: ['looked', 'up.', 'It', 'was']\n",
      "Created sample:\n",
      "\tScan time: 1556\n",
      "\tInput words: ['Hermione', 'Granger.', '+', '\"Can\\'t']\n",
      "Created sample:\n",
      "\tScan time: 1558\n",
      "\tInput words: ['a', 'person', 'eat', 'in']\n",
      "Created sample:\n",
      "\tScan time: 1560\n",
      "\tInput words: ['peace', 'in', 'this', 'place?\"']\n",
      "Created sample:\n",
      "\tScan time: 1562\n",
      "\tInput words: ['said', 'Ron.', '+', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1564\n",
      "\tInput words: ['ignored', 'him', 'and', 'spoke']\n",
      "Created sample:\n",
      "\tScan time: 1566\n",
      "\tInput words: ['to', 'Harry.', '\"I', \"couldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 1568\n",
      "\tInput words: ['help', 'overhearing', 'what', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1570\n",
      "\tInput words: ['and', 'Malfoy', 'were', 'saying']\n",
      "Created sample:\n",
      "\tScan time: 1572\n",
      "\tInput words: ['—\"', '+', '\"Bet', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1574\n",
      "\tInput words: ['could,\"', 'Ron', 'muttered.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1576\n",
      "\tInput words: ['\"—', 'and', 'you', \"@mustn't\"]\n",
      "Created sample:\n",
      "\tScan time: 1578\n",
      "\tInput words: ['go', 'wandering', 'around', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1580\n",
      "\tInput words: ['school', 'at', 'night,', 'think']\n",
      "Created sample:\n",
      "\tScan time: 1582\n",
      "\tInput words: ['of', 'the', 'points', \"you'll\"]\n",
      "Created sample:\n",
      "\tScan time: 1584\n",
      "\tInput words: ['lose', 'Gryffindor', 'if', \"you're\"]\n",
      "Created sample:\n",
      "\tScan time: 1586\n",
      "\tInput words: ['caught,', 'and', \"you're\", 'bound']\n",
      "Created sample:\n",
      "\tScan time: 1588\n",
      "\tInput words: ['to', 'be.', \"It's\", 'really']\n",
      "Created sample:\n",
      "\tScan time: 1590\n",
      "\tInput words: ['very', 'selfish', 'of', 'you.\"']\n",
      "Created sample:\n",
      "\tScan time: 1592\n",
      "\tInput words: ['+', '\"And', \"it's\", 'really']\n",
      "Created sample:\n",
      "\tScan time: 1594\n",
      "\tInput words: ['none', 'of', 'your', 'business,\"']\n",
      "Created sample:\n",
      "\tScan time: 1596\n",
      "\tInput words: ['said', 'Harry.', '+', '\"Good-bye,\"']\n",
      "Created sample:\n",
      "\tScan time: 1598\n",
      "\tInput words: ['said', 'Ron.', '+', '+']\n",
      "Created sample:\n",
      "\tScan time: 1600\n",
      "\tInput words: ['All', 'the', 'same,', 'it']\n",
      "Created sample:\n",
      "\tScan time: 1602\n",
      "\tInput words: [\"wasn't\", 'what', \"you'd\", 'call']\n",
      "Created sample:\n",
      "\tScan time: 1604\n",
      "\tInput words: ['the', 'perfect', 'end', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1606\n",
      "\tInput words: ['the', 'day,', 'Harry', 'thought,']\n",
      "Created sample:\n",
      "\tScan time: 1608\n",
      "\tInput words: ['as', 'he', 'lay', 'awake']\n",
      "Created sample:\n",
      "\tScan time: 1610\n",
      "\tInput words: ['much', 'later', 'listening', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1612\n",
      "\tInput words: ['Dean', 'and', 'Seamus', 'falling']\n",
      "Created sample:\n",
      "\tScan time: 1614\n",
      "\tInput words: ['asleep', '(Neville', \"wasn't\", 'back']\n",
      "Created sample:\n",
      "\tScan time: 1616\n",
      "\tInput words: ['from', 'the', 'hospital', 'wing).']\n",
      "Created sample:\n",
      "\tScan time: 1618\n",
      "\tInput words: ['Ron', 'had', 'spent', 'all']\n",
      "Created sample:\n",
      "\tScan time: 1620\n",
      "\tInput words: ['evening', 'giving', 'him', 'advice']\n",
      "Created sample:\n",
      "\tScan time: 1622\n",
      "\tInput words: ['such', 'as', '\"If', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1624\n",
      "\tInput words: ['tries', 'to', 'curse', 'you,']\n",
      "Created sample:\n",
      "\tScan time: 1626\n",
      "\tInput words: [\"you'd\", 'better', 'dodge', 'it,']\n",
      "Created sample:\n",
      "\tScan time: 1628\n",
      "\tInput words: ['because', 'I', \"can't\", 'remember']\n",
      "Created sample:\n",
      "\tScan time: 1630\n",
      "\tInput words: ['how', 'to', 'block', 'them.\"']\n",
      "Created sample:\n",
      "\tScan time: 1632\n",
      "\tInput words: ['There', 'was', 'a', 'very']\n",
      "Created sample:\n",
      "\tScan time: 1634\n",
      "\tInput words: ['good', 'chance', 'they', 'were']\n",
      "Created sample:\n",
      "\tScan time: 1636\n",
      "\tInput words: ['going', 'to', 'get', 'caught']\n",
      "Created sample:\n",
      "\tScan time: 1638\n",
      "\tInput words: ['by', 'Filch', 'or', 'Mrs.']\n",
      "Created sample:\n",
      "\tScan time: 1640\n",
      "\tInput words: ['Norris,', 'and', 'Harry', 'felt']\n",
      "Created sample:\n",
      "\tScan time: 1642\n",
      "\tInput words: ['he', 'was', 'pushing', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1644\n",
      "\tInput words: ['luck,', 'breaking', 'another', 'school']\n",
      "Created sample:\n",
      "\tScan time: 1646\n",
      "\tInput words: ['rule', 'today.', 'On', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1648\n",
      "\tInput words: ['other', 'hand,', \"Malfoy's\", 'sneering']\n",
      "Created sample:\n",
      "\tScan time: 1650\n",
      "\tInput words: ['face', 'kept', 'looming', 'up']\n",
      "Created sample:\n",
      "\tScan time: 1652\n",
      "\tInput words: ['out', 'of', 'the', 'darkness']\n",
      "Created sample:\n",
      "\tScan time: 1654\n",
      "\tInput words: ['--', 'this', 'was', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1656\n",
      "\tInput words: ['big', 'chance', 'to', 'beat']\n",
      "Created sample:\n",
      "\tScan time: 1658\n",
      "\tInput words: ['Malfoy', 'face-to-face.', 'He', \"couldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 1660\n",
      "\tInput words: ['miss', 'it.', '+', '\"Half-past']\n",
      "Created sample:\n",
      "\tScan time: 1662\n",
      "\tInput words: ['eleven,\"', 'Ron', 'muttered', 'at']\n",
      "Created sample:\n",
      "\tScan time: 1664\n",
      "\tInput words: ['last,', '\"we\\'d', 'better', 'go.\"']\n",
      "Created sample:\n",
      "\tScan time: 1666\n",
      "\tInput words: ['+', 'They', 'pulled', 'on']\n",
      "Created sample:\n",
      "\tScan time: 1668\n",
      "\tInput words: ['their', 'bathrobes,', 'picked', 'up']\n",
      "Created sample:\n",
      "\tScan time: 1670\n",
      "\tInput words: ['their', 'wands,', 'and', 'crept']\n",
      "Created sample:\n",
      "\tScan time: 1672\n",
      "\tInput words: ['across', 'the', 'tower', 'room,']\n",
      "Created sample:\n",
      "\tScan time: 1674\n",
      "\tInput words: ['down', 'the', 'spiral', 'staircase,']\n",
      "Created sample:\n",
      "\tScan time: 1676\n",
      "\tInput words: ['and', 'into', 'the', 'Gryffindor']\n",
      "Created sample:\n",
      "\tScan time: 1678\n",
      "\tInput words: ['common', 'room.', 'A', 'few']\n",
      "Created sample:\n",
      "\tScan time: 1680\n",
      "\tInput words: ['embers', 'were', 'still', 'glowing']\n",
      "Created sample:\n",
      "\tScan time: 1682\n",
      "\tInput words: ['in', 'the', 'fireplace,', 'turning']\n",
      "Created sample:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tScan time: 1684\n",
      "\tInput words: ['all', 'the', 'armchairs', 'into']\n",
      "Created sample:\n",
      "\tScan time: 1686\n",
      "\tInput words: ['hunched', 'black', 'shadows.', 'They']\n",
      "Created sample:\n",
      "\tScan time: 1688\n",
      "\tInput words: ['had', 'almost', 'reached', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1690\n",
      "\tInput words: ['portrait', 'hole', 'when', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1692\n",
      "\tInput words: ['voice', 'spoke', 'from', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1694\n",
      "\tInput words: ['chair', 'nearest', 'them,', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 1696\n",
      "\tInput words: [\"can't\", 'believe', \"you're\", 'going']\n",
      "Created sample:\n",
      "\tScan time: 1698\n",
      "\tInput words: ['to', 'do', 'this,', 'Harry.\"']\n",
      "Created sample:\n",
      "\tScan time: 1700\n",
      "\tInput words: ['+', 'A', 'lamp', 'flickered']\n",
      "Created sample:\n",
      "\tScan time: 1702\n",
      "\tInput words: ['on.', 'It', 'was', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1704\n",
      "\tInput words: ['Granger,', 'wearing', 'a', 'pink']\n",
      "Created sample:\n",
      "\tScan time: 1706\n",
      "\tInput words: ['bathrobe', 'and', 'a', 'frown.']\n",
      "Created sample:\n",
      "\tScan time: 1708\n",
      "\tInput words: ['+', '@\"You!\"', 'said', 'Ron']\n",
      "Created sample:\n",
      "\tScan time: 1710\n",
      "\tInput words: ['furiously.', '\"Go', 'back', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1712\n",
      "\tInput words: ['bed!\"', '+', '\"I', 'almost']\n",
      "Created sample:\n",
      "\tScan time: 1714\n",
      "\tInput words: ['told', 'your', 'brother,\"', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1716\n",
      "\tInput words: ['snapped,', '\"Percy', '--', \"he's\"]\n",
      "Created sample:\n",
      "\tScan time: 1718\n",
      "\tInput words: ['a', 'prefect,', \"he'd\", 'put']\n",
      "Created sample:\n",
      "\tScan time: 1720\n",
      "\tInput words: ['a', 'stop', 'to', 'this.\"']\n",
      "Created sample:\n",
      "\tScan time: 1722\n",
      "\tInput words: ['+', 'Harry', \"couldn't\", 'believe']\n",
      "Created sample:\n",
      "\tScan time: 1724\n",
      "\tInput words: ['anyone', 'could', 'be', 'so']\n",
      "Created sample:\n",
      "\tScan time: 1726\n",
      "\tInput words: ['interfering.', '+', '\"Come', 'on,\"']\n",
      "Created sample:\n",
      "\tScan time: 1728\n",
      "\tInput words: ['he', 'said', 'to', 'Ron.']\n",
      "Created sample:\n",
      "\tScan time: 1730\n",
      "\tInput words: ['He', 'pushed', 'open', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1732\n",
      "\tInput words: ['portrait', 'of', 'the', 'Fat']\n",
      "Created sample:\n",
      "\tScan time: 1734\n",
      "\tInput words: ['Lady', 'and', 'climbed', 'through']\n",
      "Created sample:\n",
      "\tScan time: 1736\n",
      "\tInput words: ['the', 'hole.', '+', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1738\n",
      "\tInput words: [\"wasn't\", 'going', 'to', 'give']\n",
      "Created sample:\n",
      "\tScan time: 1740\n",
      "\tInput words: ['up', 'that', 'easily.', 'She']\n",
      "Created sample:\n",
      "\tScan time: 1742\n",
      "\tInput words: ['followed', 'Ron', 'through', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1744\n",
      "\tInput words: ['portrait', 'hole,', 'hissing', 'at']\n",
      "Created sample:\n",
      "\tScan time: 1746\n",
      "\tInput words: ['them', 'like', 'an', 'angry']\n",
      "Created sample:\n",
      "\tScan time: 1748\n",
      "\tInput words: ['goose.', '\"Don\\'t', 'you', '@care']\n",
      "Created sample:\n",
      "\tScan time: 1750\n",
      "\tInput words: ['about', 'Gryffindor,', 'do', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1752\n",
      "\tInput words: ['@only', 'care', 'about', 'yourselves,']\n",
      "Created sample:\n",
      "\tScan time: 1754\n",
      "\tInput words: ['I', \"don't\", 'want', 'Slytherin']\n",
      "Created sample:\n",
      "\tScan time: 1756\n",
      "\tInput words: ['to', 'win', 'the', 'House']\n",
      "Created sample:\n",
      "\tScan time: 1758\n",
      "\tInput words: ['Cup,', 'and', \"you'll\", 'lose']\n",
      "Created sample:\n",
      "\tScan time: 1760\n",
      "\tInput words: ['all', 'the', 'points', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1762\n",
      "\tInput words: ['got', 'from', 'Professor', 'McGonagall']\n",
      "Created sample:\n",
      "\tScan time: 1764\n",
      "\tInput words: ['for', 'knowing', 'about', 'Switching']\n",
      "Created sample:\n",
      "\tScan time: 1766\n",
      "\tInput words: ['Spells.\"', '+', '\"Go', 'away.\"']\n",
      "Created sample:\n",
      "\tScan time: 1768\n",
      "\tInput words: ['+', '\"All', 'right,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 1770\n",
      "\tInput words: ['I', 'warned', 'you,', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1772\n",
      "\tInput words: ['just', 'remember', 'what', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1774\n",
      "\tInput words: ['said', 'when', \"you're\", 'on']\n",
      "Created sample:\n",
      "\tScan time: 1776\n",
      "\tInput words: ['the', 'train', 'home', 'tomorrow,']\n",
      "Created sample:\n",
      "\tScan time: 1778\n",
      "\tInput words: [\"you're\", 'so', '—\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1780\n",
      "\tInput words: ['But', 'what', 'they', 'were,']\n",
      "Created sample:\n",
      "\tScan time: 1782\n",
      "\tInput words: ['they', \"didn't\", 'find', 'out.']\n",
      "Created sample:\n",
      "\tScan time: 1784\n",
      "\tInput words: ['Hermione', 'had', 'turned', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1786\n",
      "\tInput words: ['the', 'portrait', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1788\n",
      "\tInput words: ['Fat', 'Lady', 'to', 'get']\n",
      "Created sample:\n",
      "\tScan time: 1790\n",
      "\tInput words: ['back', 'inside', 'and', 'found']\n",
      "Created sample:\n",
      "\tScan time: 1792\n",
      "\tInput words: ['herself', 'facing', 'an', 'empty']\n",
      "Created sample:\n",
      "\tScan time: 1794\n",
      "\tInput words: ['painting.', 'The', 'Fat', 'Lady']\n",
      "Created sample:\n",
      "\tScan time: 1796\n",
      "\tInput words: ['had', 'gone', 'on', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1798\n",
      "\tInput words: ['nighttime', 'visit', 'and', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1800\n",
      "\tInput words: ['was', 'locked', 'out', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1802\n",
      "\tInput words: ['Gryffindor', 'Tower.', '+', '\"Now']\n",
      "Created sample:\n",
      "\tScan time: 1804\n",
      "\tInput words: ['what', 'am', 'I', 'going']\n",
      "Created sample:\n",
      "\tScan time: 1806\n",
      "\tInput words: ['to', 'do?\"', 'she', 'asked']\n",
      "Created sample:\n",
      "\tScan time: 1808\n",
      "\tInput words: ['shrilly.', '+', '\"That\\'s', 'your']\n",
      "Created sample:\n",
      "\tScan time: 1810\n",
      "\tInput words: ['problem,\"', 'said', 'Ron.', '\"We\\'ve']\n",
      "Created sample:\n",
      "\tScan time: 1812\n",
      "\tInput words: ['got', 'to', 'go,', \"we're\"]\n",
      "Created sample:\n",
      "\tScan time: 1814\n",
      "\tInput words: ['going', 'to', 'be', 'late.\"']\n",
      "Created sample:\n",
      "\tScan time: 1816\n",
      "\tInput words: ['+', 'They', \"hadn't\", 'even']\n",
      "Created sample:\n",
      "\tScan time: 1818\n",
      "\tInput words: ['reached', 'the', 'end', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1820\n",
      "\tInput words: ['the', 'corridor', 'when', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 1822\n",
      "\tInput words: ['caught', 'up', 'with', 'them.']\n",
      "Created sample:\n",
      "\tScan time: 1824\n",
      "\tInput words: ['+', '\"I\\'m', 'coming', 'with']\n",
      "Created sample:\n",
      "\tScan time: 1826\n",
      "\tInput words: ['you,\"', 'she', 'said.', '\"You']\n",
      "Created sample:\n",
      "\tScan time: 1828\n",
      "\tInput words: ['are', '@not.\"', '+', '\"D\\'you']\n",
      "Created sample:\n",
      "\tScan time: 1830\n",
      "\tInput words: ['think', \"I'm\", 'going', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1832\n",
      "\tInput words: ['stand', 'out', 'here', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1834\n",
      "\tInput words: ['wait', 'for', 'Filch', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1836\n",
      "\tInput words: ['catch', 'me?', 'If', 'he']\n",
      "Created sample:\n",
      "\tScan time: 1838\n",
      "\tInput words: ['finds', 'all', 'three', 'of']\n",
      "Created sample:\n",
      "\tScan time: 1840\n",
      "\tInput words: ['us', \"I'll\", 'tell', 'him']\n",
      "Created sample:\n",
      "\tScan time: 1842\n",
      "\tInput words: ['the', 'truth,', 'that', 'I']\n",
      "Created sample:\n",
      "\tScan time: 1844\n",
      "\tInput words: ['was', 'trying', 'to', 'stop']\n",
      "Created sample:\n",
      "\tScan time: 1846\n",
      "\tInput words: ['you,', 'and', 'you', 'can']\n",
      "Created sample:\n",
      "\tScan time: 1848\n",
      "\tInput words: ['back', 'me', 'up.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 1850\n",
      "\tInput words: ['\"You\\'ve', 'got', 'some', 'nerve']\n",
      "Created sample:\n",
      "\tScan time: 1852\n",
      "\tInput words: ['—\"', 'said', 'Ron', 'loudly.']\n",
      "Created sample:\n",
      "\tScan time: 1854\n",
      "\tInput words: ['+', '\"Shut', 'up,', 'both']\n",
      "Created sample:\n",
      "\tScan time: 1856\n",
      "\tInput words: ['of', 'you!\"', 'said', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 1858\n",
      "\tInput words: ['sharply.', '\"I', 'heard', 'something.\"']\n",
      "Created sample:\n",
      "\tScan time: 1860\n",
      "\tInput words: ['+', 'It', 'was', 'a']\n",
      "Created sample:\n",
      "\tScan time: 1862\n",
      "\tInput words: ['sort', 'of', 'snuffling.', '+']\n",
      "Created sample:\n",
      "\tScan time: 1864\n",
      "\tInput words: ['\"Mrs.', 'Norris?\"', 'breathed', 'Ron,']\n",
      "Created sample:\n",
      "\tScan time: 1866\n",
      "\tInput words: ['squinting', 'through', 'the', 'dark.']\n",
      "Created sample:\n",
      "\tScan time: 1868\n",
      "\tInput words: ['+', 'It', \"wasn't\", 'Mrs.']\n",
      "Created sample:\n",
      "\tScan time: 1870\n",
      "\tInput words: ['Norris.', 'It', 'was', 'Neville.']\n",
      "Created sample:\n",
      "\tScan time: 1872\n",
      "\tInput words: ['He', 'was', 'curled', 'up']\n",
      "Created sample:\n",
      "\tScan time: 1874\n",
      "\tInput words: ['on', 'the', 'floor,', 'fast']\n",
      "Created sample:\n",
      "\tScan time: 1876\n",
      "\tInput words: ['asleep,', 'but', 'jerked', 'suddenly']\n",
      "Created sample:\n",
      "\tScan time: 1878\n",
      "\tInput words: ['awake', 'as', 'they', 'crept']\n",
      "Created sample:\n",
      "\tScan time: 1880\n",
      "\tInput words: ['nearer.', '+', '\"Thank', 'goodness']\n",
      "Created sample:\n",
      "\tScan time: 1882\n",
      "\tInput words: ['you', 'found', 'me!', \"I've\"]\n",
      "Created sample:\n",
      "\tScan time: 1884\n",
      "\tInput words: ['been', 'out', 'here', 'for']\n",
      "Created sample:\n",
      "\tScan time: 1886\n",
      "\tInput words: ['hours,', 'I', \"couldn't\", 'remember']\n",
      "Created sample:\n",
      "\tScan time: 1888\n",
      "\tInput words: ['the', 'new', 'password', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1890\n",
      "\tInput words: ['get', 'in', 'to', 'bed.\"']\n",
      "Created sample:\n",
      "\tScan time: 1892\n",
      "\tInput words: ['+', '\"Keep', 'your', 'voice']\n",
      "Created sample:\n",
      "\tScan time: 1894\n",
      "\tInput words: ['down,', 'Neville.', 'The', \"password's\"]\n",
      "Created sample:\n",
      "\tScan time: 1896\n",
      "\tInput words: ['‘Pig', \"snout'\", 'but', 'it']\n",
      "Created sample:\n",
      "\tScan time: 1898\n",
      "\tInput words: [\"won't\", 'help', 'you', 'now,']\n",
      "Created sample:\n",
      "\tScan time: 1900\n",
      "\tInput words: ['the', 'Fat', \"Lady's\", 'gone']\n",
      "Created sample:\n",
      "\tScan time: 1902\n",
      "\tInput words: ['off', 'somewhere.\"', '+', '\"How\\'s']\n",
      "Created sample:\n",
      "\tScan time: 1904\n",
      "\tInput words: ['your', 'arm?\"', 'said', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 1906\n",
      "\tInput words: ['+', '\"Fine,\"', 'said', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 1908\n",
      "\tInput words: ['showing', 'them.', '\"Madam', 'Pomfrey']\n",
      "Created sample:\n",
      "\tScan time: 1910\n",
      "\tInput words: ['mended', 'it', 'in', 'about']\n",
      "Created sample:\n",
      "\tScan time: 1912\n",
      "\tInput words: ['a', 'minute.\"', '+', '\"Good']\n",
      "Created sample:\n",
      "\tScan time: 1914\n",
      "\tInput words: ['--', 'well,', 'look,', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 1916\n",
      "\tInput words: [\"we've\", 'got', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 1918\n",
      "\tInput words: ['somewhere,', \"we'll\", 'see', 'you']\n",
      "Created sample:\n",
      "\tScan time: 1920\n",
      "\tInput words: ['later', '—\"', '+', '\"Don\\'t']\n",
      "Created sample:\n",
      "\tScan time: 1922\n",
      "\tInput words: ['leave', 'me!\"', 'said', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 1924\n",
      "\tInput words: ['scrambling', 'to', 'his', 'feet,']\n",
      "Created sample:\n",
      "\tScan time: 1926\n",
      "\tInput words: ['\"I', \"don't\", 'want', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1928\n",
      "\tInput words: ['stay', 'here', 'alone,', 'the']\n",
      "Created sample:\n",
      "\tScan time: 1962\n",
      "\tInput words: ['Ron', 'looked', 'at', 'his']\n",
      "Created sample:\n",
      "\tScan time: 1964\n",
      "\tInput words: ['watch', 'and', 'then', 'glared']\n",
      "Created sample:\n",
      "\tScan time: 1966\n",
      "\tInput words: ['furiously', 'at', 'Hermione', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1968\n",
      "\tInput words: ['Neville.', '+', '\"If', 'either']\n",
      "Created sample:\n",
      "\tScan time: 1970\n",
      "\tInput words: ['of', 'you', 'get', 'us']\n",
      "Created sample:\n",
      "\tScan time: 1972\n",
      "\tInput words: ['caught,', \"I'll\", 'never', 'rest']\n",
      "Created sample:\n",
      "\tScan time: 1974\n",
      "\tInput words: ['until', \"I've\", 'learned', 'that']\n",
      "Created sample:\n",
      "\tScan time: 1976\n",
      "\tInput words: ['Curse', 'of', 'the', 'Bogies']\n",
      "Created sample:\n",
      "\tScan time: 1978\n",
      "\tInput words: ['Quirrell', 'told', 'us', 'about,']\n",
      "Created sample:\n",
      "\tScan time: 1980\n",
      "\tInput words: ['and', 'used', 'it', 'on']\n",
      "Created sample:\n",
      "\tScan time: 1982\n",
      "\tInput words: ['you.\"', '+', 'Hermione', 'opened']\n",
      "Created sample:\n",
      "\tScan time: 1984\n",
      "\tInput words: ['her', 'mouth,', 'perhaps', 'to']\n",
      "Created sample:\n",
      "\tScan time: 1986\n",
      "\tInput words: ['tell', 'Ron', 'exactly', 'how']\n",
      "Created sample:\n",
      "\tScan time: 1988\n",
      "\tInput words: ['to', 'use', 'the', 'Curse']\n",
      "Created sample:\n",
      "\tScan time: 1990\n",
      "\tInput words: ['of', 'the', 'Bogies,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 1992\n",
      "\tInput words: ['Harry', 'hissed', 'at', 'her']\n",
      "Created sample:\n",
      "\tScan time: 1994\n",
      "\tInput words: ['to', 'be', 'quiet', 'and']\n",
      "Created sample:\n",
      "\tScan time: 1996\n",
      "\tInput words: ['beckoned', 'them', 'all', 'forward.']\n",
      "Created sample:\n",
      "\tScan time: 1998\n",
      "\tInput words: ['+', 'They', 'flitted', 'along']\n",
      "Created sample:\n",
      "\tScan time: 2000\n",
      "\tInput words: ['corridors', 'striped', 'with', 'bars']\n",
      "Created sample:\n",
      "\tScan time: 2002\n",
      "\tInput words: ['of', 'moonlight', 'from', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2004\n",
      "\tInput words: ['high', 'windows.', 'At', 'every']\n",
      "Created sample:\n",
      "\tScan time: 2006\n",
      "\tInput words: ['turn', 'Harry', 'expected', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2008\n",
      "\tInput words: ['run', 'into', 'Filch', 'or']\n",
      "Created sample:\n",
      "\tScan time: 2010\n",
      "\tInput words: ['Mrs.', 'Norris,', 'but', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2012\n",
      "\tInput words: ['were', 'lucky.', 'They', 'sped']\n",
      "Created sample:\n",
      "\tScan time: 2014\n",
      "\tInput words: ['up', 'a', 'staircase', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2016\n",
      "\tInput words: ['the', 'third', 'floor', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2018\n",
      "\tInput words: ['tiptoed', 'toward', 'the', 'trophy']\n",
      "Created sample:\n",
      "\tScan time: 2020\n",
      "\tInput words: ['room.', '+', 'Malfoy', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2022\n",
      "\tInput words: ['Crabbe', \"weren't\", 'there', 'yet.']\n",
      "Created sample:\n",
      "\tScan time: 2024\n",
      "\tInput words: ['The', 'crystal', 'trophy', 'cases']\n",
      "Created sample:\n",
      "\tScan time: 2026\n",
      "\tInput words: ['glimmered', 'where', 'the', 'moonlight']\n",
      "Created sample:\n",
      "\tScan time: 2028\n",
      "\tInput words: ['caught', 'them.', 'Cups,', 'shields,']\n",
      "Created sample:\n",
      "\tScan time: 2030\n",
      "\tInput words: ['plates,', 'and', 'statues', 'winked']\n",
      "Created sample:\n",
      "\tScan time: 2032\n",
      "\tInput words: ['silver', 'and', 'gold', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2034\n",
      "\tInput words: ['the', 'darkness.', 'They', 'edged']\n",
      "Created sample:\n",
      "\tScan time: 2036\n",
      "\tInput words: ['along', 'the', 'walls,', 'keeping']\n",
      "Created sample:\n",
      "\tScan time: 2038\n",
      "\tInput words: ['their', 'eyes', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2040\n",
      "\tInput words: ['doors', 'at', 'either', 'end']\n",
      "Created sample:\n",
      "\tScan time: 2042\n",
      "\tInput words: ['of', 'the', 'room.', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2044\n",
      "\tInput words: ['took', 'out', 'his', 'wand']\n",
      "Created sample:\n",
      "\tScan time: 2046\n",
      "\tInput words: ['in', 'case', 'Malfoy', 'leapt']\n",
      "Created sample:\n",
      "\tScan time: 2048\n",
      "\tInput words: ['in', 'and', 'started', 'at']\n",
      "Created sample:\n",
      "\tScan time: 2050\n",
      "\tInput words: ['once.', 'The', 'minutes', 'crept']\n",
      "Created sample:\n",
      "\tScan time: 2052\n",
      "\tInput words: ['by.', '+', '\"He\\'s', 'late,']\n",
      "Created sample:\n",
      "\tScan time: 2054\n",
      "\tInput words: ['maybe', \"he's\", 'chickened', 'out,\"']\n",
      "Created sample:\n",
      "\tScan time: 2056\n",
      "\tInput words: ['Ron', 'whispered.', '+', 'Then']\n",
      "Created sample:\n",
      "\tScan time: 2058\n",
      "\tInput words: ['a', 'noise', 'in', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2060\n",
      "\tInput words: ['next', 'room', 'made', 'them']\n",
      "Created sample:\n",
      "\tScan time: 2062\n",
      "\tInput words: ['jump.', 'Harry', 'had', 'only']\n",
      "Created sample:\n",
      "\tScan time: 2064\n",
      "\tInput words: ['just', 'raised', 'his', 'wand']\n",
      "Created sample:\n",
      "\tScan time: 2066\n",
      "\tInput words: ['when', 'they', 'heard', 'someone']\n",
      "Created sample:\n",
      "\tScan time: 2068\n",
      "\tInput words: ['speak', '--', 'and', 'it']\n",
      "Created sample:\n",
      "\tScan time: 2070\n",
      "\tInput words: [\"wasn't\", 'Malfoy.', '+', '\"Sniff']\n",
      "Created sample:\n",
      "\tScan time: 2072\n",
      "\tInput words: ['around,', 'my', 'sweet,', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2074\n",
      "\tInput words: ['might', 'be', 'lurking', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2076\n",
      "\tInput words: ['a', 'corner.\"', '+', 'It']\n",
      "Created sample:\n",
      "\tScan time: 2078\n",
      "\tInput words: ['was', 'Filch', 'speaking', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2080\n",
      "\tInput words: ['Mrs.', 'Norris.', 'Horror-struck,', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2082\n",
      "\tInput words: ['waved', 'madly', 'at', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2084\n",
      "\tInput words: ['other', 'three', 'to', 'follow']\n",
      "Created sample:\n",
      "\tScan time: 2086\n",
      "\tInput words: ['him', 'as', 'quickly', 'as']\n",
      "Created sample:\n",
      "\tScan time: 2088\n",
      "\tInput words: ['possible;', 'they', 'scurried', 'silently']\n",
      "Created sample:\n",
      "\tScan time: 2090\n",
      "\tInput words: ['toward', 'the', 'door,', 'away']\n",
      "Created sample:\n",
      "\tScan time: 2092\n",
      "\tInput words: ['from', \"Filch's\", 'voice.', \"Neville's\"]\n",
      "Created sample:\n",
      "\tScan time: 2094\n",
      "\tInput words: ['robes', 'had', 'barely', 'whipped']\n",
      "Created sample:\n",
      "\tScan time: 2096\n",
      "\tInput words: ['round', 'the', 'corner', 'when']\n",
      "Created sample:\n",
      "\tScan time: 2098\n",
      "\tInput words: ['they', 'heard', 'Filch', 'enter']\n",
      "Created sample:\n",
      "\tScan time: 2100\n",
      "\tInput words: ['the', 'trophy', 'room.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2102\n",
      "\tInput words: ['\"They\\'re', 'in', 'here', 'somewhere,\"']\n",
      "Created sample:\n",
      "\tScan time: 2104\n",
      "\tInput words: ['they', 'heard', 'him', 'mutter,']\n",
      "Created sample:\n",
      "\tScan time: 2106\n",
      "\tInput words: ['\"probably', 'hiding.\"', '+', '\"This']\n",
      "Created sample:\n",
      "\tScan time: 2108\n",
      "\tInput words: ['way!\"', 'Harry', 'mouthed', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2110\n",
      "\tInput words: ['the', 'others', 'and,', 'petrified,']\n",
      "Created sample:\n",
      "\tScan time: 2112\n",
      "\tInput words: ['they', 'began', 'to', 'creep']\n",
      "Created sample:\n",
      "\tScan time: 2114\n",
      "\tInput words: ['down', 'a', 'long', 'gallery']\n",
      "Created sample:\n",
      "\tScan time: 2116\n",
      "\tInput words: ['full', 'of', 'suits', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2118\n",
      "\tInput words: ['armor.', '+', 'They', 'could']\n",
      "Created sample:\n",
      "\tScan time: 2120\n",
      "\tInput words: ['hear', 'Filch', 'getting', 'nearer.']\n",
      "Created sample:\n",
      "\tScan time: 2122\n",
      "\tInput words: ['Neville', 'suddenly', 'let', 'out']\n",
      "Created sample:\n",
      "\tScan time: 2124\n",
      "\tInput words: ['a', 'frightened', 'squeak', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2126\n",
      "\tInput words: ['broke', 'into', 'a', 'run']\n",
      "Created sample:\n",
      "\tScan time: 2128\n",
      "\tInput words: ['--', 'he', 'tripped,', 'grabbed']\n",
      "Created sample:\n",
      "\tScan time: 2130\n",
      "\tInput words: ['Ron', 'around', 'the', 'waist,']\n",
      "Created sample:\n",
      "\tScan time: 2132\n",
      "\tInput words: ['and', 'the', 'pair', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2134\n",
      "\tInput words: ['them', 'toppled', 'right', 'into']\n",
      "Created sample:\n",
      "\tScan time: 2136\n",
      "\tInput words: ['a', 'suit', 'of', 'armor.']\n",
      "Created sample:\n",
      "\tScan time: 2138\n",
      "\tInput words: ['+', 'The', 'clanging', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2140\n",
      "\tInput words: ['crashing', 'were', 'enough', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2142\n",
      "\tInput words: ['wake', 'the', 'whole', 'castle.']\n",
      "Created sample:\n",
      "\tScan time: 2144\n",
      "\tInput words: ['+', '\"RUN!\"', 'Harry', 'yelled,']\n",
      "Created sample:\n",
      "\tScan time: 2146\n",
      "\tInput words: ['and', 'the', 'four', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2148\n",
      "\tInput words: ['them', 'sprinted', 'down', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2150\n",
      "\tInput words: ['gallery,', 'not', 'looking', 'back']\n",
      "Created sample:\n",
      "\tScan time: 2152\n",
      "\tInput words: ['to', 'see', 'whether', 'Filch']\n",
      "Created sample:\n",
      "\tScan time: 2154\n",
      "\tInput words: ['was', 'following', '--', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2156\n",
      "\tInput words: ['swung', 'around', 'the', 'doorpost']\n",
      "Created sample:\n",
      "\tScan time: 2158\n",
      "\tInput words: ['and', 'galloped', 'down', 'one']\n",
      "Created sample:\n",
      "\tScan time: 2160\n",
      "\tInput words: ['corridor', 'then', 'another,', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2162\n",
      "\tInput words: ['in', 'the', 'lead,', 'without']\n",
      "Created sample:\n",
      "\tScan time: 2164\n",
      "\tInput words: ['any', 'idea', 'where', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2166\n",
      "\tInput words: ['were', 'or', 'where', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2168\n",
      "\tInput words: ['were', 'going', '--', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2170\n",
      "\tInput words: ['ripped', 'through', 'a', 'tapestry']\n",
      "Created sample:\n",
      "\tScan time: 2172\n",
      "\tInput words: ['and', 'found', 'themselves', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2174\n",
      "\tInput words: ['a', 'hidden', 'passageway,', 'hurtled']\n",
      "Created sample:\n",
      "\tScan time: 2176\n",
      "\tInput words: ['along', 'it', 'and', 'came']\n",
      "Created sample:\n",
      "\tScan time: 2178\n",
      "\tInput words: ['out', 'near', 'their', 'Charms']\n",
      "Created sample:\n",
      "\tScan time: 2180\n",
      "\tInput words: ['classroom,', 'which', 'they', 'knew']\n",
      "Created sample:\n",
      "\tScan time: 2182\n",
      "\tInput words: ['was', 'miles', 'from', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2184\n",
      "\tInput words: ['trophy', 'room.', '+', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 2186\n",
      "\tInput words: ['think', \"we've\", 'lost', 'him,\"']\n",
      "Created sample:\n",
      "\tScan time: 2188\n",
      "\tInput words: ['Harry', 'panted,', 'leaning', 'against']\n",
      "Created sample:\n",
      "\tScan time: 2190\n",
      "\tInput words: ['the', 'cold', 'wall', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2192\n",
      "\tInput words: ['wiping', 'his', 'forehead.', 'Neville']\n",
      "Created sample:\n",
      "\tScan time: 2194\n",
      "\tInput words: ['was', 'bent', 'double,', 'wheezing']\n",
      "Created sample:\n",
      "\tScan time: 2196\n",
      "\tInput words: ['and', 'spluttering.', '+', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 2198\n",
      "\tInput words: ['--', '@told', '--', 'you,\"']\n",
      "Created sample:\n",
      "\tScan time: 2200\n",
      "\tInput words: ['Hermione', 'gasped,', 'clutching', 'at']\n",
      "Created sample:\n",
      "\tScan time: 2202\n",
      "\tInput words: ['the', 'stitch', 'in', 'her']\n",
      "Created sample:\n",
      "\tScan time: 2204\n",
      "\tInput words: ['chest,', '\"I', '--', 'told']\n",
      "Created sample:\n",
      "\tScan time: 2206\n",
      "\tInput words: ['--', 'you.\"', '+', '\"We\\'ve']\n",
      "Created sample:\n",
      "\tScan time: 2208\n",
      "\tInput words: ['got', 'to', 'get', 'back']\n",
      "Created sample:\n",
      "\tScan time: 2210\n",
      "\tInput words: ['to', 'Gryffindor', 'Tower,\"', 'said']\n",
      "Created sample:\n",
      "\tScan time: 2212\n",
      "\tInput words: ['Ron,', '\"quickly', 'as', 'possible.\"']\n",
      "Created sample:\n",
      "\tScan time: 2214\n",
      "\tInput words: ['+', '\"Malfoy', 'tricked', 'you,\"']\n",
      "Created sample:\n",
      "\tScan time: 2216\n",
      "\tInput words: ['Hermione', 'said', 'to', 'Harry.']\n",
      "Created sample:\n",
      "\tScan time: 2218\n",
      "\tInput words: ['\"You', 'realize', 'that,', \"don't\"]\n",
      "Created sample:\n",
      "\tScan time: 2220\n",
      "\tInput words: ['you?', 'He', 'was', 'never']\n",
      "Created sample:\n",
      "\tScan time: 2222\n",
      "\tInput words: ['going', 'to', 'meet', 'you']\n",
      "Created sample:\n",
      "\tScan time: 2224\n",
      "\tInput words: ['--', 'Filch', 'knew', 'someone']\n",
      "Created sample:\n",
      "\tScan time: 2226\n",
      "\tInput words: ['was', 'going', 'to', 'be']\n",
      "Created sample:\n",
      "\tScan time: 2228\n",
      "\tInput words: ['in', 'the', 'trophy', 'room,']\n",
      "Created sample:\n",
      "\tScan time: 2230\n",
      "\tInput words: ['Malfoy', 'must', 'have', 'tipped']\n",
      "Created sample:\n",
      "\tScan time: 2232\n",
      "\tInput words: ['him', 'off.\"', '+', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2234\n",
      "\tInput words: ['thought', 'she', 'was', 'probably']\n",
      "Created sample:\n",
      "\tScan time: 2236\n",
      "\tInput words: ['right,', 'but', 'he', \"wasn't\"]\n",
      "Created sample:\n",
      "\tScan time: 2238\n",
      "\tInput words: ['going', 'to', 'tell', 'her']\n",
      "Created sample:\n",
      "\tScan time: 2240\n",
      "\tInput words: ['that.', '+', '\"Let\\'s', 'go.\"']\n",
      "Created sample:\n",
      "\tScan time: 2242\n",
      "\tInput words: ['+', 'It', \"wasn't\", 'going']\n",
      "Created sample:\n",
      "\tScan time: 2244\n",
      "\tInput words: ['to', 'be', 'that', 'simple.']\n",
      "Created sample:\n",
      "\tScan time: 2246\n",
      "\tInput words: ['They', \"hadn't\", 'gone', 'more']\n",
      "Created sample:\n",
      "\tScan time: 2248\n",
      "\tInput words: ['than', 'a', 'dozen', 'paces']\n",
      "Created sample:\n",
      "\tScan time: 2250\n",
      "\tInput words: ['when', 'a', 'doorknob', 'rattled']\n",
      "Created sample:\n",
      "\tScan time: 2252\n",
      "\tInput words: ['and', 'something', 'came', 'shooting']\n",
      "Created sample:\n",
      "\tScan time: 2254\n",
      "\tInput words: ['out', 'of', 'a', 'classroom']\n",
      "Created sample:\n",
      "\tScan time: 2256\n",
      "\tInput words: ['in', 'front', 'of', 'them.']\n",
      "Created sample:\n",
      "\tScan time: 2258\n",
      "\tInput words: ['+', 'It', 'was', 'Peeves.']\n",
      "Created sample:\n",
      "\tScan time: 2260\n",
      "\tInput words: ['He', 'caught', 'sight', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2262\n",
      "\tInput words: ['them', 'and', 'gave', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2264\n",
      "\tInput words: ['squeal', 'of', 'delight.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2266\n",
      "\tInput words: ['\"Shut', 'up,', 'Peeves', '--']\n",
      "Created sample:\n",
      "\tScan time: 2268\n",
      "\tInput words: ['please', '--', \"you'll\", 'get']\n",
      "Created sample:\n",
      "\tScan time: 2270\n",
      "\tInput words: ['us', 'thrown', 'out.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2272\n",
      "\tInput words: ['Peeves', 'cackled.', '+', '\"Wandering']\n",
      "Created sample:\n",
      "\tScan time: 2274\n",
      "\tInput words: ['around', 'at', 'midnight,', 'Ickle']\n",
      "Created sample:\n",
      "\tScan time: 2276\n",
      "\tInput words: ['Firsties?', 'Tut,', 'tut,', 'tut.']\n",
      "Created sample:\n",
      "\tScan time: 2278\n",
      "\tInput words: ['Naughty,', 'naughty,', \"you'll\", 'get']\n",
      "Created sample:\n",
      "\tScan time: 2280\n",
      "\tInput words: ['caughty.\"', '+', '\"Not', 'if']\n",
      "Created sample:\n",
      "\tScan time: 2282\n",
      "\tInput words: ['you', \"don't\", 'give', 'us']\n",
      "Created sample:\n",
      "\tScan time: 2284\n",
      "\tInput words: ['away,', 'Peeves,', 'please.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2286\n",
      "\tInput words: ['\"Should', 'tell', 'Filch,', 'I']\n",
      "Created sample:\n",
      "\tScan time: 2288\n",
      "\tInput words: ['should,\"', 'said', 'Peeves', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2290\n",
      "\tInput words: ['a', 'saintly', 'voice,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 2292\n",
      "\tInput words: ['his', 'eyes', 'glittered', 'wickedly.']\n",
      "Created sample:\n",
      "\tScan time: 2294\n",
      "\tInput words: ['\"It\\'s', 'for', 'your', 'own']\n",
      "Created sample:\n",
      "\tScan time: 2296\n",
      "\tInput words: ['good,', 'you', 'know.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2298\n",
      "\tInput words: ['\"Get', 'out', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2300\n",
      "\tInput words: ['way,\"', 'snapped', 'Ron,', 'taking']\n",
      "Created sample:\n",
      "\tScan time: 2302\n",
      "\tInput words: ['a', 'swipe', 'at', 'Peeves']\n",
      "Created sample:\n",
      "\tScan time: 2304\n",
      "\tInput words: ['--', 'this', 'was', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2306\n",
      "\tInput words: ['big', 'mistake.', '+', '\"STUDENTS']\n",
      "Created sample:\n",
      "\tScan time: 2308\n",
      "\tInput words: ['OUT', 'OF', 'BED!\"', 'Peeves']\n",
      "Created sample:\n",
      "\tScan time: 2310\n",
      "\tInput words: ['bellowed,', '\"STUDENTS', 'OUT', 'OF']\n",
      "Created sample:\n",
      "\tScan time: 2312\n",
      "\tInput words: ['BED', 'DOWN', 'THE', 'CHARMS']\n",
      "Created sample:\n",
      "\tScan time: 2314\n",
      "\tInput words: ['CORRIDOR!\"', '+', 'Ducking', 'under']\n",
      "Created sample:\n",
      "\tScan time: 2316\n",
      "\tInput words: ['Peeves,', 'they', 'ran', 'for']\n",
      "Created sample:\n",
      "\tScan time: 2318\n",
      "\tInput words: ['their', 'lives,', 'right', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2320\n",
      "\tInput words: ['the', 'end', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2322\n",
      "\tInput words: ['corridor', 'where', 'they', 'slammed']\n",
      "Created sample:\n",
      "\tScan time: 2324\n",
      "\tInput words: ['into', 'a', 'door', '--']\n",
      "Created sample:\n",
      "\tScan time: 2326\n",
      "\tInput words: ['and', 'it', 'was', 'locked.']\n",
      "Created sample:\n",
      "\tScan time: 2328\n",
      "\tInput words: ['+', '\"This', 'is', 'it!\"']\n",
      "Created sample:\n",
      "\tScan time: 2330\n",
      "\tInput words: ['Ron', 'moaned,', 'as', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2332\n",
      "\tInput words: ['pushed', 'helplessly', 'at', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2334\n",
      "\tInput words: ['door,', '\"We\\'re', 'done', 'for!']\n",
      "Created sample:\n",
      "\tScan time: 2336\n",
      "\tInput words: ['This', 'is', 'the', 'end!\"']\n",
      "Created sample:\n",
      "\tScan time: 2338\n",
      "\tInput words: ['+', 'They', 'could', 'hear']\n",
      "Created sample:\n",
      "\tScan time: 2340\n",
      "\tInput words: ['footsteps,', 'Filch', 'running', 'as']\n",
      "Created sample:\n",
      "\tScan time: 2342\n",
      "\tInput words: ['fast', 'as', 'he', 'could']\n",
      "Created sample:\n",
      "\tScan time: 2344\n",
      "\tInput words: ['toward', \"Peeves's\", 'shouts.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2346\n",
      "\tInput words: ['\"Oh,', 'move', 'over,\"', 'Hermione']\n",
      "Created sample:\n",
      "\tScan time: 2348\n",
      "\tInput words: ['snarled.', 'She', 'grabbed', \"Harry's\"]\n",
      "Created sample:\n",
      "\tScan time: 2350\n",
      "\tInput words: ['wand,', 'tapped', 'the', 'lock,']\n",
      "Created sample:\n",
      "\tScan time: 2352\n",
      "\tInput words: ['and', 'whispered,', '@\"Alohomora!\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2354\n",
      "\tInput words: ['The', 'lock', 'clicked', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2356\n",
      "\tInput words: ['the', 'door', 'swung', 'open']\n",
      "Created sample:\n",
      "\tScan time: 2358\n",
      "\tInput words: ['--', 'they', 'piled', 'through']\n",
      "Created sample:\n",
      "\tScan time: 2360\n",
      "\tInput words: ['it,', 'shut', 'it', 'quickly,']\n",
      "Created sample:\n",
      "\tScan time: 2362\n",
      "\tInput words: ['and', 'pressed', 'their', 'ears']\n",
      "Created sample:\n",
      "\tScan time: 2364\n",
      "\tInput words: ['against', 'it,', 'listening.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2366\n",
      "\tInput words: ['\"Which', 'way', 'did', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2368\n",
      "\tInput words: ['go,', 'Peeves?\"', 'Filch', 'was']\n",
      "Created sample:\n",
      "\tScan time: 2370\n",
      "\tInput words: ['saying.', '\"Quick,', 'tell', 'me.\"']\n",
      "Created sample:\n",
      "\tScan time: 2372\n",
      "\tInput words: ['\"Say', '‘please.\\'\"', '+', '\"Don\\'t']\n",
      "Created sample:\n",
      "\tScan time: 2374\n",
      "\tInput words: ['mess', 'with', 'me,', 'Peeves,']\n",
      "Created sample:\n",
      "\tScan time: 2376\n",
      "\tInput words: ['now', '@where', '@did', '@they']\n",
      "Created sample:\n",
      "\tScan time: 2378\n",
      "\tInput words: ['@go?\"', '\"Shan\\'t', 'say', 'nothing']\n",
      "Created sample:\n",
      "\tScan time: 2380\n",
      "\tInput words: ['if', 'you', \"don't\", 'say']\n",
      "Created sample:\n",
      "\tScan time: 2382\n",
      "\tInput words: ['please,\"', 'said', 'Peeves', 'in']\n",
      "Created sample:\n",
      "\tScan time: 2384\n",
      "\tInput words: ['his', 'annoying', 'singsong', 'voice.']\n",
      "Created sample:\n",
      "\tScan time: 2386\n",
      "\tInput words: ['\"All', 'right', '--', '@please.\"']\n",
      "Created sample:\n",
      "\tScan time: 2388\n",
      "\tInput words: ['+', '\"NOTHING!', 'Ha', 'haaa!']\n",
      "Created sample:\n",
      "\tScan time: 2390\n",
      "\tInput words: ['Told', 'you', 'I', \"wouldn't\"]\n",
      "Created sample:\n",
      "\tScan time: 2392\n",
      "\tInput words: ['say', 'nothing', 'if', 'you']\n",
      "Created sample:\n",
      "\tScan time: 2394\n",
      "\tInput words: [\"didn't\", 'say', 'please!', 'Ha']\n",
      "Created sample:\n",
      "\tScan time: 2396\n",
      "\tInput words: ['ha!', 'Haaaaaa!\"', 'And', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2398\n",
      "\tInput words: ['heard', 'the', 'sound', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2400\n",
      "\tInput words: ['Peeves', 'whooshing', 'away', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2402\n",
      "\tInput words: ['Filch', 'cursing', 'in', 'rage.']\n",
      "Created sample:\n",
      "\tScan time: 2404\n",
      "\tInput words: ['+', '\"He', 'thinks', 'this']\n",
      "Created sample:\n",
      "\tScan time: 2406\n",
      "\tInput words: ['door', 'is', 'locked,\"', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2408\n",
      "\tInput words: ['whispered.', '\"I', 'think', \"we'll\"]\n",
      "Created sample:\n",
      "\tScan time: 2410\n",
      "\tInput words: ['be', 'okay', '--', 'get']\n",
      "Created sample:\n",
      "\tScan time: 2412\n",
      "\tInput words: ['@off,', 'Neville!\"', 'For', 'Neville']\n",
      "Created sample:\n",
      "\tScan time: 2414\n",
      "\tInput words: ['had', 'been', 'tugging', 'on']\n",
      "Created sample:\n",
      "\tScan time: 2416\n",
      "\tInput words: ['the', 'sleeve', 'of', \"Harry's\"]\n",
      "Created sample:\n",
      "\tScan time: 2418\n",
      "\tInput words: ['bathrobe', 'for', 'the', 'last']\n",
      "Created sample:\n",
      "\tScan time: 2420\n",
      "\tInput words: ['minute.', '@\"What?\"', '+', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2422\n",
      "\tInput words: ['turned', 'around', '--', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2424\n",
      "\tInput words: ['saw,', 'quite', 'clearly,', 'what.']\n",
      "Created sample:\n",
      "\tScan time: 2426\n",
      "\tInput words: ['For', 'a', 'moment,', 'he']\n",
      "Created sample:\n",
      "\tScan time: 2428\n",
      "\tInput words: ['was', 'sure', \"he'd\", 'walked']\n",
      "Created sample:\n",
      "\tScan time: 2430\n",
      "\tInput words: ['into', 'a', 'nightmare', '--']\n",
      "Created sample:\n",
      "\tScan time: 2432\n",
      "\tInput words: ['this', 'was', 'too', 'much,']\n",
      "Created sample:\n",
      "\tScan time: 2434\n",
      "\tInput words: ['on', 'top', 'of', 'everything']\n",
      "Created sample:\n",
      "\tScan time: 2436\n",
      "\tInput words: ['that', 'had', 'happened', 'so']\n",
      "Created sample:\n",
      "\tScan time: 2438\n",
      "\tInput words: ['far.', '+', 'They', \"weren't\"]\n",
      "Created sample:\n",
      "\tScan time: 2440\n",
      "\tInput words: ['in', 'a', 'room,', 'as']\n",
      "Created sample:\n",
      "\tScan time: 2442\n",
      "\tInput words: ['he', 'had', 'supposed.', 'They']\n",
      "Created sample:\n",
      "\tScan time: 2444\n",
      "\tInput words: ['were', 'in', 'a', 'corridor.']\n",
      "Created sample:\n",
      "\tScan time: 2446\n",
      "\tInput words: ['The', 'forbidden', 'corridor', 'on']\n",
      "Created sample:\n",
      "\tScan time: 2448\n",
      "\tInput words: ['the', 'third', 'floor.', 'And']\n",
      "Created sample:\n",
      "\tScan time: 2450\n",
      "\tInput words: ['now', 'they', 'knew', 'why']\n",
      "Created sample:\n",
      "\tScan time: 2452\n",
      "\tInput words: ['it', 'was', 'forbidden.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2454\n",
      "\tInput words: ['They', 'were', 'looking', 'straight']\n",
      "Created sample:\n",
      "\tScan time: 2456\n",
      "\tInput words: ['into', 'the', 'eyes', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2458\n",
      "\tInput words: ['a', 'monstrous', 'dog,', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2460\n",
      "\tInput words: ['dog', 'that', 'filled', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2462\n",
      "\tInput words: ['whole', 'space', 'between', 'ceiling']\n",
      "Created sample:\n",
      "\tScan time: 2464\n",
      "\tInput words: ['and', 'floor.', 'It', 'had']\n",
      "Created sample:\n",
      "\tScan time: 2466\n",
      "\tInput words: ['three', 'heads.', 'Three', 'pairs']\n",
      "Created sample:\n",
      "\tScan time: 2468\n",
      "\tInput words: ['of', 'rolling,', 'mad', 'eyes;']\n",
      "Created sample:\n",
      "\tScan time: 2470\n",
      "\tInput words: ['three', 'noses,', 'twitching', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2472\n",
      "\tInput words: ['quivering', 'in', 'their', 'direction;']\n",
      "Created sample:\n",
      "\tScan time: 2474\n",
      "\tInput words: ['three', 'drooling', 'mouths,', 'saliva']\n",
      "Created sample:\n",
      "\tScan time: 2476\n",
      "\tInput words: ['hanging', 'in', 'slippery', 'ropes']\n",
      "Created sample:\n",
      "\tScan time: 2478\n",
      "\tInput words: ['from', 'yellowish', 'fangs.', '+']\n",
      "Created sample:\n",
      "\tScan time: 2480\n",
      "\tInput words: ['It', 'was', 'standing', 'quite']\n",
      "Created sample:\n",
      "\tScan time: 2482\n",
      "\tInput words: ['still,', 'all', 'six', 'eyes']\n",
      "Created sample:\n",
      "\tScan time: 2484\n",
      "\tInput words: ['staring', 'at', 'them,', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2486\n",
      "\tInput words: ['Harry', 'knew', 'that', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2488\n",
      "\tInput words: ['only', 'reason', 'they', \"weren't\"]\n",
      "Created sample:\n",
      "\tScan time: 2490\n",
      "\tInput words: ['already', 'dead', 'was', 'that']\n",
      "Created sample:\n",
      "\tScan time: 2492\n",
      "\tInput words: ['their', 'sudden', 'appearance', 'had']\n",
      "Created sample:\n",
      "\tScan time: 2494\n",
      "\tInput words: ['taken', 'it', 'by', 'surprise,']\n",
      "Created sample:\n",
      "\tScan time: 2496\n",
      "\tInput words: ['but', 'it', 'was', 'quickly']\n",
      "Created sample:\n",
      "\tScan time: 2498\n",
      "\tInput words: ['getting', 'over', 'that,', 'there']\n",
      "Created sample:\n",
      "\tScan time: 2500\n",
      "\tInput words: ['was', 'no', 'mistaking', 'what']\n",
      "Created sample:\n",
      "\tScan time: 2502\n",
      "\tInput words: ['those', 'thunderous', 'growls', 'meant.']\n",
      "Created sample:\n",
      "\tScan time: 2504\n",
      "\tInput words: ['+', 'Harry', 'groped', 'for']\n",
      "Created sample:\n",
      "\tScan time: 2506\n",
      "\tInput words: ['the', 'doorknob', '--', 'between']\n",
      "Created sample:\n",
      "\tScan time: 2508\n",
      "\tInput words: ['Filch', 'and', 'death,', \"he'd\"]\n",
      "Created sample:\n",
      "\tScan time: 2510\n",
      "\tInput words: ['take', 'Filch.', '+', 'They']\n",
      "Created sample:\n",
      "\tScan time: 2512\n",
      "\tInput words: ['fell', 'backward', '--', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2514\n",
      "\tInput words: ['slammed', 'the', 'door', 'shut,']\n",
      "Created sample:\n",
      "\tScan time: 2516\n",
      "\tInput words: ['and', 'they', 'ran,', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2518\n",
      "\tInput words: ['almost', 'flew,', 'back', 'down']\n",
      "Created sample:\n",
      "\tScan time: 2520\n",
      "\tInput words: ['the', 'corridor.', 'Filch', 'must']\n",
      "Created sample:\n",
      "\tScan time: 2522\n",
      "\tInput words: ['have', 'hurried', 'off', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2524\n",
      "\tInput words: ['look', 'for', 'them', 'somewhere']\n",
      "Created sample:\n",
      "\tScan time: 2526\n",
      "\tInput words: ['else,', 'because', 'they', \"didn't\"]\n",
      "Created sample:\n",
      "\tScan time: 2528\n",
      "\tInput words: ['see', 'him', 'anywhere,', 'but']\n",
      "Created sample:\n",
      "\tScan time: 2530\n",
      "\tInput words: ['they', 'hardly', 'cared', '--']\n",
      "Created sample:\n",
      "\tScan time: 2532\n",
      "\tInput words: ['all', 'they', 'wanted', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2534\n",
      "\tInput words: ['do', 'was', 'put', 'as']\n",
      "Created sample:\n",
      "\tScan time: 2536\n",
      "\tInput words: ['much', 'space', 'as', 'possible']\n",
      "Created sample:\n",
      "\tScan time: 2538\n",
      "\tInput words: ['between', 'them', 'and', 'that']\n",
      "Created sample:\n",
      "\tScan time: 2540\n",
      "\tInput words: ['monster.', 'They', \"didn't\", 'stop']\n",
      "Created sample:\n",
      "\tScan time: 2542\n",
      "\tInput words: ['running', 'until', 'they', 'reached']\n",
      "Created sample:\n",
      "\tScan time: 2544\n",
      "\tInput words: ['the', 'portrait', 'of', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2546\n",
      "\tInput words: ['Fat', 'Lady', 'on', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2548\n",
      "\tInput words: ['seventh', 'floor.', '+', '\"Where']\n",
      "Created sample:\n",
      "\tScan time: 2550\n",
      "\tInput words: ['on', 'earth', 'have', 'you']\n",
      "Created sample:\n",
      "\tScan time: 2552\n",
      "\tInput words: ['all', 'been?\"', 'she', 'asked,']\n",
      "Created sample:\n",
      "\tScan time: 2554\n",
      "\tInput words: ['looking', 'at', 'their', 'bathrobes']\n",
      "Created sample:\n",
      "\tScan time: 2556\n",
      "\tInput words: ['hanging', 'off', 'their', 'shoulders']\n",
      "Created sample:\n",
      "\tScan time: 2558\n",
      "\tInput words: ['and', 'their', 'flushed,', 'sweaty']\n",
      "Created sample:\n",
      "\tScan time: 2560\n",
      "\tInput words: ['faces.', '+', '\"Never', 'mind']\n",
      "Created sample:\n",
      "\tScan time: 2562\n",
      "\tInput words: ['that', '--', 'pig', 'snout,']\n",
      "Created sample:\n",
      "\tScan time: 2564\n",
      "\tInput words: ['pig', 'snout,\"', 'panted', 'Harry,']\n",
      "Created sample:\n",
      "\tScan time: 2566\n",
      "\tInput words: ['and', 'the', 'portrait', 'swung']\n",
      "Created sample:\n",
      "\tScan time: 2568\n",
      "\tInput words: ['forward.', 'They', 'scrambled', 'into']\n",
      "Created sample:\n",
      "\tScan time: 2570\n",
      "\tInput words: ['the', 'common', 'room', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2572\n",
      "\tInput words: ['collapsed,', 'trembling,', 'into', 'armchairs.']\n",
      "Created sample:\n",
      "\tScan time: 2574\n",
      "\tInput words: ['+', 'It', 'was', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2576\n",
      "\tInput words: ['while', 'before', 'any', 'of']\n",
      "Created sample:\n",
      "\tScan time: 2578\n",
      "\tInput words: ['them', 'said', 'anything.', 'Neville,']\n",
      "Created sample:\n",
      "\tScan time: 2580\n",
      "\tInput words: ['indeed,', 'looked', 'as', 'if']\n",
      "Created sample:\n",
      "\tScan time: 2582\n",
      "\tInput words: [\"he'd\", 'never', 'speak', 'again.']\n",
      "Created sample:\n",
      "\tScan time: 2584\n",
      "\tInput words: ['+', '\"What', 'do', 'they']\n",
      "Created sample:\n",
      "\tScan time: 2586\n",
      "\tInput words: ['think', \"they're\", 'doing,', 'keeping']\n",
      "Created sample:\n",
      "\tScan time: 2588\n",
      "\tInput words: ['a', 'thing', 'like', 'that']\n",
      "Created sample:\n",
      "\tScan time: 2590\n",
      "\tInput words: ['locked', 'up', 'in', 'a']\n",
      "Created sample:\n",
      "\tScan time: 2592\n",
      "\tInput words: ['school?\"', 'said', 'Ron', 'finally.']\n",
      "Created sample:\n",
      "\tScan time: 2594\n",
      "\tInput words: ['\"If', 'any', 'dog', 'needs']\n",
      "Created sample:\n",
      "\tScan time: 2596\n",
      "\tInput words: ['exercise,', 'that', 'one', 'does.\"']\n",
      "Created sample:\n",
      "\tScan time: 2598\n",
      "\tInput words: ['+', 'Hermione', 'had', 'got']\n",
      "Created sample:\n",
      "\tScan time: 2600\n",
      "\tInput words: ['both', 'her', 'breath', 'and']\n",
      "Created sample:\n",
      "\tScan time: 2602\n",
      "\tInput words: ['her', 'bad', 'temper', 'back']\n",
      "Created sample:\n",
      "\tScan time: 2604\n",
      "\tInput words: ['again.', '+', '\"You', \"don't\"]\n",
      "Created sample:\n",
      "\tScan time: 2606\n",
      "\tInput words: ['use', 'your', 'eyes,', 'any']\n",
      "Created sample:\n",
      "\tScan time: 2608\n",
      "\tInput words: ['of', 'you,', 'do', 'you?\"']\n",
      "Created sample:\n",
      "\tScan time: 2610\n",
      "\tInput words: ['she', 'snapped.', '\"Didn\\'t', 'you']\n",
      "Created sample:\n",
      "\tScan time: 2612\n",
      "\tInput words: ['see', 'what', 'it', 'was']\n",
      "Created sample:\n",
      "\tScan time: 2614\n",
      "\tInput words: ['standing', 'on?\"', '+', '\"The']\n",
      "Created sample:\n",
      "\tScan time: 2616\n",
      "\tInput words: ['floor?\"', 'Harry', 'suggested.', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 2618\n",
      "\tInput words: [\"wasn't\", 'looking', 'at', 'its']\n",
      "Created sample:\n",
      "\tScan time: 2620\n",
      "\tInput words: ['feet,', 'I', 'was', 'too']\n",
      "Created sample:\n",
      "\tScan time: 2622\n",
      "\tInput words: ['busy', 'with', 'its', 'heads.\"']\n",
      "Created sample:\n",
      "\tScan time: 2624\n",
      "\tInput words: ['+', '\"No,', '@not', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2626\n",
      "\tInput words: ['floor.', 'It', 'was', 'standing']\n",
      "Created sample:\n",
      "\tScan time: 2628\n",
      "\tInput words: ['on', 'a', 'trapdoor.', \"It's\"]\n",
      "Created sample:\n",
      "\tScan time: 2630\n",
      "\tInput words: ['obviously', 'guarding', 'something.\"', '+']\n",
      "Created sample:\n",
      "\tScan time: 2632\n",
      "\tInput words: ['She', 'stood', 'up,', 'glaring']\n",
      "Created sample:\n",
      "\tScan time: 2634\n",
      "\tInput words: ['at', 'them.', '+', '\"I']\n",
      "Created sample:\n",
      "\tScan time: 2636\n",
      "\tInput words: ['hope', \"you're\", 'pleased', 'with']\n",
      "Created sample:\n",
      "\tScan time: 2638\n",
      "\tInput words: ['yourselves.', 'We', 'could', 'all']\n",
      "Created sample:\n",
      "\tScan time: 2640\n",
      "\tInput words: ['have', 'been', 'killed', '--']\n",
      "Created sample:\n",
      "\tScan time: 2642\n",
      "\tInput words: ['or', 'worse,', 'expelled.', 'Now,']\n",
      "Created sample:\n",
      "\tScan time: 2644\n",
      "\tInput words: ['if', 'you', \"don't\", 'mind,']\n",
      "Created sample:\n",
      "\tScan time: 2646\n",
      "\tInput words: [\"I'm\", 'going', 'to', 'bed.\"']\n",
      "Created sample:\n",
      "\tScan time: 2648\n",
      "\tInput words: ['+', 'Ron', 'stared', 'after']\n",
      "Created sample:\n",
      "\tScan time: 2650\n",
      "\tInput words: ['her,', 'his', 'mouth', 'open.']\n",
      "Created sample:\n",
      "\tScan time: 2652\n",
      "\tInput words: ['\"No,', 'we', \"don't\", 'mind,\"']\n",
      "Created sample:\n",
      "\tScan time: 2654\n",
      "\tInput words: ['he', 'said.', '\"You\\'d', 'think']\n",
      "Created sample:\n",
      "\tScan time: 2656\n",
      "\tInput words: ['we', 'dragged', 'her', 'along,']\n",
      "Created sample:\n",
      "\tScan time: 2658\n",
      "\tInput words: [\"wouldn't\", 'you?\"', '+', 'But']\n",
      "Created sample:\n",
      "\tScan time: 2660\n",
      "\tInput words: ['Hermione', 'had', 'given', 'Harry']\n",
      "Created sample:\n",
      "\tScan time: 2662\n",
      "\tInput words: ['something', 'else', 'to', 'think']\n",
      "Created sample:\n",
      "\tScan time: 2664\n",
      "\tInput words: ['about', 'as', 'he', 'climbed']\n",
      "Created sample:\n",
      "\tScan time: 2666\n",
      "\tInput words: ['back', 'into', 'bed.', 'The']\n",
      "Created sample:\n",
      "\tScan time: 2668\n",
      "\tInput words: ['dog', 'was', 'guarding', 'something.']\n",
      "Created sample:\n",
      "\tScan time: 2670\n",
      "\tInput words: ['.', '.', '.', 'What']\n",
      "Created sample:\n",
      "\tScan time: 2672\n",
      "\tInput words: ['had', 'Hagrid', 'said?', 'Gringotts']\n",
      "Created sample:\n",
      "\tScan time: 2674\n",
      "\tInput words: ['was', 'the', 'safest', 'place']\n",
      "Created sample:\n",
      "\tScan time: 2676\n",
      "\tInput words: ['in', 'the', 'world', 'for']\n",
      "Created sample:\n",
      "\tScan time: 2678\n",
      "\tInput words: ['something', 'you', 'wanted', 'to']\n",
      "Created sample:\n",
      "\tScan time: 2680\n",
      "\tInput words: ['hide', '--', 'except', 'perhaps']\n",
      "Created sample:\n",
      "\tScan time: 2682\n",
      "\tInput words: ['Hogwarts.', '+', 'It', 'looked']\n",
      "Created sample:\n",
      "\tScan time: 2684\n",
      "\tInput words: ['as', 'though', 'Harry', 'had']\n",
      "Created sample:\n",
      "\tScan time: 2686\n",
      "\tInput words: ['found', 'out', 'where', 'the']\n",
      "Created sample:\n",
      "\tScan time: 2688\n",
      "\tInput words: ['grubby', 'little', 'package', 'from']\n",
      "Total number of samples: 1287\n"
     ]
    }
   ],
   "source": [
    "subjects_samples = [[] for i in range(NUM_SUBJS)] #stores lists of all the samples for each subject\n",
    "\n",
    "word_count = 0\n",
    "while word_count < len(words_info) - 8:\n",
    "    #gets the 4 input words, and the 4 consecutive words while verifying they were read in sequence\n",
    "    scan_words = []\n",
    "    start_time = words_info[word_count][1]\n",
    "    in_sequence = True #tracks if the words are in sequence or not\n",
    "    for i in range(8):\n",
    "        word_info = words_info[word_count + i]\n",
    "        if word_info[1] != start_time + 0.5*i:\n",
    "            #if some of the words are not in sequence, skip forward 1 word after innter loop\n",
    "            in_sequence = False\n",
    "        scan_words.append(word_info[0])\n",
    "    if not in_sequence:\n",
    "        word_count +=1\n",
    "        continue\n",
    "    fmri_time = start_time + 2 #effect of reading words is assumed to start 2 seconds after and end 8 seconds after\n",
    "    fmri_index = fmri_time//2 #since a scan happens every two seconds, the index is the time divided by 2\n",
    "    if not isinstance(fmri_index, np.int32):\n",
    "        #if the first word is not aligned with the fmri scan (i.e. its not the first word in a TR)\n",
    "        word_count += 1\n",
    "        continue\n",
    "    for count, subject in enumerate(subjects_fmri):\n",
    "        #adds tuple of (fmri_scan, four words)\n",
    "        subjects_samples[count].append((subject[:,:,:,fmri_index+2], scan_words[0:4]))\n",
    "    print(\"Created sample:\")\n",
    "    print(\"\\tScan time:\", str(start_time))\n",
    "    print(\"\\tInput words:\", str(scan_words[0:4]))\n",
    "    #if successful, skip forward to the next set of 4 words\n",
    "    word_count += 4\n",
    "\n",
    "print(\"Total number of samples:\", str(len(subjects_samples[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import html\n",
    "import os\n",
    "from functools import lru_cache\n",
    "\n",
    "import ftfy\n",
    "import regex as re\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def default_bpe():\n",
    "    return os.path.join(os.path.dirname(os.path.abspath(\"./doi_10.5061_dryad.gt413__v1\")), \"bpe_simple_vocab_16e6.txt.gz\")\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def bytes_to_unicode():\n",
    "    \"\"\"\n",
    "    Returns list of utf-8 byte and a corresponding list of unicode strings.\n",
    "    The reversible bpe codes work on unicode strings.\n",
    "    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n",
    "    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n",
    "    This is a signficant percentage of your normal, say, 32K bpe vocab.\n",
    "    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n",
    "    And avoids mapping to whitespace/control characters the bpe code barfs on.\n",
    "    \"\"\"\n",
    "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
    "    cs = bs[:]\n",
    "    n = 0\n",
    "    for b in range(2**8):\n",
    "        if b not in bs:\n",
    "            bs.append(b)\n",
    "            cs.append(2**8+n)\n",
    "            n += 1\n",
    "    cs = [chr(n) for n in cs]\n",
    "    return dict(zip(bs, cs))\n",
    "\n",
    "\n",
    "def get_pairs(word):\n",
    "    \"\"\"Return set of symbol pairs in a word.\n",
    "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def basic_clean(text):\n",
    "    text = ftfy.fix_text(text)\n",
    "    text = html.unescape(html.unescape(text))\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def whitespace_clean(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "class SimpleTokenizer(object):\n",
    "    def __init__(self, bpe_path: str = default_bpe()):\n",
    "        self.byte_encoder = bytes_to_unicode()\n",
    "        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\n",
    "        merges = gzip.open(bpe_path).read().decode(\"utf-8\").split('\\n')\n",
    "        merges = merges[1:49152-256-2+1]\n",
    "        merges = [tuple(merge.split()) for merge in merges]\n",
    "        vocab = list(bytes_to_unicode().values())\n",
    "        vocab = vocab + [v+'</w>' for v in vocab]\n",
    "        for merge in merges:\n",
    "            vocab.append(''.join(merge))\n",
    "        vocab.extend(['<|startoftext|>', '<|endoftext|>'])\n",
    "        self.encoder = dict(zip(vocab, range(len(vocab))))\n",
    "        self.decoder = {v: k for k, v in self.encoder.items()}\n",
    "        self.bpe_ranks = dict(zip(merges, range(len(merges))))\n",
    "        self.cache = {'<|startoftext|>': '<|startoftext|>', '<|endoftext|>': '<|endoftext|>'}\n",
    "        self.pat = re.compile(r\"\"\"<\\|startoftext\\|>|<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\", re.IGNORECASE)\n",
    "\n",
    "    def bpe(self, token):\n",
    "        if token in self.cache:\n",
    "            return self.cache[token]\n",
    "        word = tuple(token[:-1]) + ( token[-1] + '</w>',)\n",
    "        pairs = get_pairs(word)\n",
    "\n",
    "        if not pairs:\n",
    "            return token+'</w>'\n",
    "\n",
    "        while True:\n",
    "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
    "            if bigram not in self.bpe_ranks:\n",
    "                break\n",
    "            first, second = bigram\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                try:\n",
    "                    j = word.index(first, i)\n",
    "                    new_word.extend(word[i:j])\n",
    "                    i = j\n",
    "                except:\n",
    "                    new_word.extend(word[i:])\n",
    "                    break\n",
    "\n",
    "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                    new_word.append(first+second)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            new_word = tuple(new_word)\n",
    "            word = new_word\n",
    "            if len(word) == 1:\n",
    "                break\n",
    "            else:\n",
    "                pairs = get_pairs(word)\n",
    "        word = ' '.join(word)\n",
    "        self.cache[token] = word\n",
    "        return word\n",
    "\n",
    "    def encode(self, text):\n",
    "        bpe_tokens = []\n",
    "        text = whitespace_clean(basic_clean(text)).lower()\n",
    "        for token in re.findall(self.pat, text):\n",
    "            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n",
    "            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n",
    "        return bpe_tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        text = ''.join([self.decoder[token] for token in tokens])\n",
    "        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=\"replace\").replace('</w>', ' ')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import urllib\n",
    "import warnings\n",
    "from typing import Any, Union, List\n",
    "from pkg_resources import packaging\n",
    "\n",
    "_tokenizer = SimpleTokenizer()\n",
    "\n",
    "def tokenize(texts: Union[str, List[str]], context_length: int = 16, truncate: bool = False) -> Union[torch.IntTensor, torch.LongTensor]:\n",
    "    \"\"\"\n",
    "    Returns the tokenized representation of given input string(s)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : Union[str, List[str]]\n",
    "        An input string or a list of input strings to tokenize\n",
    "\n",
    "    context_length : int\n",
    "        The context length to use; all CLIP models use 77 as the context length\n",
    "\n",
    "    truncate: bool\n",
    "        Whether to truncate the text in case its encoding is longer than the context length\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A two-dimensional tensor containing the resulting tokens, shape = [number of input strings, context_length].\n",
    "    We return LongTensor when torch version is <1.8.0, since older index_select requires indices to be long.\n",
    "    \"\"\"\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    sot_token = _tokenizer.encoder[\"<|startoftext|>\"]\n",
    "    eot_token = _tokenizer.encoder[\"<|endoftext|>\"]\n",
    "    all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]\n",
    "    if packaging.version.parse(torch.__version__) < packaging.version.parse(\"1.8.0\"):\n",
    "        result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)\n",
    "    else:\n",
    "        result = torch.zeros(len(all_tokens), context_length, dtype=torch.int)\n",
    "\n",
    "    for i, tokens in enumerate(all_tokens):\n",
    "        if len(tokens) > context_length:\n",
    "            if truncate:\n",
    "                tokens = tokens[:context_length]\n",
    "                tokens[-1] = eot_token\n",
    "            else:\n",
    "                raise RuntimeError(f\"Input {texts[i]} is too long for context length {context_length}\")\n",
    "        result[i, :len(tokens)] = torch.tensor(tokens)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # all conv layers have stride 1. an avgpool is performed after the second convolution when stride > 1\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(planes, planes, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.avgpool = nn.AvgPool3d(stride) if stride > 1 else nn.Identity()\n",
    "\n",
    "        self.conv3 = nn.Conv3d(planes, planes * self.expansion, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = None\n",
    "        self.stride = stride\n",
    "\n",
    "        if stride > 1 or inplanes != planes * Bottleneck.expansion:\n",
    "            # downsampling layer is prepended with an avgpool, and the subsequent convolution has stride 1\n",
    "            self.downsample = nn.Sequential(OrderedDict([\n",
    "                (\"-1\", nn.AvgPool3d(stride)),\n",
    "                (\"0\", nn.Conv3d(inplanes, planes * self.expansion, 1, stride=1, bias=False)),\n",
    "                (\"1\", nn.BatchNorm3d(planes * self.expansion))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        identity = x\n",
    "\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\n",
    "        out = self.relu2(self.bn2(self.conv2(out)))\n",
    "        out = self.avgpool(out)\n",
    "        out = self.bn3(self.conv3(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# class AttentionPool2d(nn.Module):\n",
    "#     def __init__(self, spacial_dim: int, embed_dim: int, num_heads: int, output_dim: int = None):\n",
    "#         super().__init__()\n",
    "#         self.positional_embedding = nn.Parameter(torch.randn(spacial_dim ** 2 + 1, embed_dim) / embed_dim ** 0.5)\n",
    "#         self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "#         self.c_proj = nn.Linear(embed_dim, output_dim or embed_dim)\n",
    "#         self.num_heads = num_heads\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.flatten(start_dim=2).permute(2, 0, 1)  # NCHW -> (HW)NC\n",
    "#         x = torch.cat([x.mean(dim=0, keepdim=True), x], dim=0)  # (HW+1)NC\n",
    "#         x = x + self.positional_embedding[:, None, :].to(x.dtype)  # (HW+1)NC\n",
    "#         x, _ = F.multi_head_attention_forward(\n",
    "#             query=x[:1], key=x, value=x,\n",
    "#             embed_dim_to_check=x.shape[-1],\n",
    "#             num_heads=self.num_heads,\n",
    "#             q_proj_weight=self.q_proj.weight,\n",
    "#             k_proj_weight=self.k_proj.weight,\n",
    "#             v_proj_weight=self.v_proj.weight,\n",
    "#             in_proj_weight=None,\n",
    "#             in_proj_bias=torch.cat([self.q_proj.bias, self.k_proj.bias, self.v_proj.bias]),\n",
    "#             bias_k=None,\n",
    "#             bias_v=None,\n",
    "#             add_zero_attn=False,\n",
    "#             dropout_p=0,\n",
    "#             out_proj_weight=self.c_proj.weight,\n",
    "#             out_proj_bias=self.c_proj.bias,\n",
    "#             use_separate_proj_weight=True,\n",
    "#             training=self.training,\n",
    "#             need_weights=False\n",
    "#         )\n",
    "#         return x.squeeze(0)\n",
    "\n",
    "\n",
    "class ModifiedResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet class that is similar to torchvision's but contains the following changes:\n",
    "    - There are now 3 \"stem\" convolutions as opposed to 1, with an average pool instead of a max pool.\n",
    "    - Performs anti-aliasing strided convolutions, where an avgpool is prepended to convolutions with stride > 1\n",
    "    - The final pooling layer is a QKV attention instead of an average pool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, output_dim, heads, input_resolution=224, width=64):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.input_resolution = input_resolution\n",
    "\n",
    "        # the 3-layer stem\n",
    "        self.conv1 = nn.Conv3d(1, width // 2, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(width // 2)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(width // 2, width // 2, kernel_size=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(width // 2)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv3d(width // 2, width, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(width)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AvgPool3d(2)\n",
    "        self.linear = nn.Linear(2048, 1024)\n",
    "\n",
    "        # residual layers\n",
    "        self._inplanes = width  # this is a *mutable* variable used during construction\n",
    "        self.layer1 = self._make_layer(width, layers[0])\n",
    "        self.layer2 = self._make_layer(width * 2, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(width * 4, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(width * 8, layers[3], stride=2)\n",
    "\n",
    "        embed_dim = width * 32  # the ResNet feature dimension\n",
    "#         self.attnpool = AttentionPool2d(input_resolution // 32, embed_dim, heads, output_dim)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1):\n",
    "        layers = [Bottleneck(self._inplanes, planes, stride)]\n",
    "\n",
    "        self._inplanes = planes * Bottleneck.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(Bottleneck(self._inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        def stem(x):\n",
    "            x = self.relu1(self.bn1(self.conv1(x)))\n",
    "            x = self.relu2(self.bn2(self.conv2(x)))\n",
    "            x = self.relu3(self.bn3(self.conv3(x)))\n",
    "            x = self.avgpool(x)\n",
    "            return x\n",
    "\n",
    "        x = x.type(self.conv1.weight.dtype)\n",
    "        x = stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "#         x = self.avgpool(x) #changed final attentionpool to avgpool\n",
    "        #x = self.attnpool(x)\n",
    "        x = x.view(-1,2048) #will have to change this if different layer/kernel sizes used\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNorm(nn.LayerNorm):\n",
    "    \"\"\"Subclass torch's LayerNorm to handle fp16.\"\"\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        orig_type = x.dtype\n",
    "        ret = super().forward(x.type(torch.float32))\n",
    "        return ret.type(orig_type)\n",
    "\n",
    "\n",
    "class QuickGELU(nn.Module):\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x * torch.sigmoid(1.702 * x)\n",
    "\n",
    "\n",
    "class ResidualAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int, attn_mask: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_head)\n",
    "        self.ln_1 = LayerNorm(d_model)\n",
    "        self.mlp = nn.Sequential(OrderedDict([\n",
    "            (\"c_fc\", nn.Linear(d_model, d_model * 4)),\n",
    "            (\"gelu\", QuickGELU()),\n",
    "            (\"c_proj\", nn.Linear(d_model * 4, d_model))\n",
    "        ]))\n",
    "        self.ln_2 = LayerNorm(d_model)\n",
    "        self.attn_mask = attn_mask\n",
    "\n",
    "    def attention(self, x: torch.Tensor):\n",
    "        self.attn_mask = self.attn_mask.to(dtype=x.dtype, device=x.device) if self.attn_mask is not None else None\n",
    "        return self.attn(x, x, x, need_weights=False, attn_mask=self.attn_mask)[0]\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + self.attention(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, width: int, layers: int, heads: int, attn_mask: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "        self.layers = layers\n",
    "        self.resblocks = nn.Sequential(*[ResidualAttentionBlock(width, heads, attn_mask) for _ in range(layers)])\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.resblocks(x)\n",
    "\n",
    "\n",
    "class CLIP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 # vision\n",
    "                 image_resolution: int,\n",
    "                 vision_layers: Union[Tuple[int, int, int, int], int],\n",
    "                 vision_width: int,\n",
    "                 # text\n",
    "                 context_length: int,\n",
    "                 vocab_size: int,\n",
    "                 transformer_width: int,\n",
    "                 transformer_heads: int,\n",
    "                 transformer_layers: int\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.context_length = context_length\n",
    "\n",
    "        #initializes resnet (removed option for vision transformer)\n",
    "        vision_heads = vision_width * 32 // 64\n",
    "        self.visual = ModifiedResNet(\n",
    "            layers=vision_layers,\n",
    "            output_dim=embed_dim,\n",
    "            heads=vision_heads,\n",
    "            input_resolution=image_resolution,\n",
    "            width=vision_width\n",
    "        )\n",
    "\n",
    "        #initializes text transformer\n",
    "        self.transformer = Transformer(\n",
    "            width=transformer_width,\n",
    "            layers=transformer_layers,\n",
    "            heads=transformer_heads,\n",
    "            attn_mask=self.build_attention_mask()\n",
    "        )\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_embedding = nn.Embedding(vocab_size, transformer_width)\n",
    "        self.positional_embedding = nn.Parameter(torch.empty(self.context_length, transformer_width))\n",
    "        self.ln_final = LayerNorm(transformer_width)\n",
    "\n",
    "        self.text_projection = nn.Parameter(torch.empty(transformer_width, embed_dim))\n",
    "        #self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "        self.logit_scale = torch.ones([]) * np.log(1 / 0.07)\n",
    "\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        nn.init.normal_(self.token_embedding.weight, std=0.02)\n",
    "        nn.init.normal_(self.positional_embedding, std=0.01)\n",
    "\n",
    "        if isinstance(self.visual, ModifiedResNet):\n",
    "#             if self.visual.attnpool is not None:\n",
    "#                 std = self.visual.attnpool.c_proj.in_features ** -0.5\n",
    "#                 nn.init.normal_(self.visual.attnpool.q_proj.weight, std=std)\n",
    "#                 nn.init.normal_(self.visual.attnpool.k_proj.weight, std=std)\n",
    "#                 nn.init.normal_(self.visual.attnpool.v_proj.weight, std=std)\n",
    "#                 nn.init.normal_(self.visual.attnpool.c_proj.weight, std=std)\n",
    "\n",
    "            for resnet_block in [self.visual.layer1, self.visual.layer2, self.visual.layer3, self.visual.layer4]:\n",
    "                for name, param in resnet_block.named_parameters():\n",
    "                    if name.endswith(\"bn3.weight\"):\n",
    "                        nn.init.zeros_(param)\n",
    "\n",
    "        proj_std = (self.transformer.width ** -0.5) * ((2 * self.transformer.layers) ** -0.5)\n",
    "        attn_std = self.transformer.width ** -0.5\n",
    "        fc_std = (2 * self.transformer.width) ** -0.5\n",
    "        for block in self.transformer.resblocks:\n",
    "            nn.init.normal_(block.attn.in_proj_weight, std=attn_std)\n",
    "            nn.init.normal_(block.attn.out_proj.weight, std=proj_std)\n",
    "            nn.init.normal_(block.mlp.c_fc.weight, std=fc_std)\n",
    "            nn.init.normal_(block.mlp.c_proj.weight, std=proj_std)\n",
    "\n",
    "        if self.text_projection is not None:\n",
    "            nn.init.normal_(self.text_projection, std=self.transformer.width ** -0.5)\n",
    "\n",
    "    def build_attention_mask(self):\n",
    "        # lazily create causal attention mask, with full attention between the vision tokens\n",
    "        # pytorch uses additive attention mask; fill with -inf\n",
    "        mask = torch.empty(self.context_length, self.context_length)\n",
    "        mask.fill_(float(\"-inf\"))\n",
    "        mask.triu_(1)  # zero out the lower diagonal\n",
    "        return mask\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.visual.conv1.weight.dtype\n",
    "\n",
    "    def encode_image(self, image):\n",
    "        return self.visual(image.type(self.dtype))\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        x = self.token_embedding(text).type(self.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "        x = x + self.positional_embedding.type(self.dtype)\n",
    "        x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "        x = self.transformer(x)\n",
    "        x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "        x = self.ln_final(x).type(self.dtype)\n",
    "\n",
    "        # x.shape = [batch_size, n_ctx, transformer.width]\n",
    "        # take features from the eot embedding (eot_token is the highest number in each sequence)\n",
    "        x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ self.text_projection\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        image_features = self.encode_image(image)\n",
    "        text_features = self.encode_text(text)\n",
    "\n",
    "        # normalized features\n",
    "        image_features = image_features / image_features.norm(dim=1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=1, keepdim=True)\n",
    "\n",
    "        # cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_features @ text_features.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "\n",
    "        # shape = [global_batch_size, global_batch_size]\n",
    "        return logits_per_image, logits_per_text\n",
    "\n",
    "\n",
    "def convert_weights(model: nn.Module):\n",
    "    \"\"\"Convert applicable model parameters to fp16\"\"\"\n",
    "\n",
    "    def _convert_weights_to_fp16(l):\n",
    "        if isinstance(l, (nn.Conv1d, nn.Conv3d, nn.Linear)):\n",
    "            l.weight.data = l.weight.data.half()\n",
    "            if l.bias is not None:\n",
    "                l.bias.data = l.bias.data.half()\n",
    "\n",
    "        if isinstance(l, nn.MultiheadAttention):\n",
    "            for attr in [*[f\"{s}_proj_weight\" for s in [\"in\", \"q\", \"k\", \"v\"]], \"in_proj_bias\", \"bias_k\", \"bias_v\"]:\n",
    "                tensor = getattr(l, attr)\n",
    "                if tensor is not None:\n",
    "                    tensor.data = tensor.data.half()\n",
    "\n",
    "        for name in [\"text_projection\", \"proj\"]:\n",
    "            if hasattr(l, name):\n",
    "                attr = getattr(l, name)\n",
    "                if attr is not None:\n",
    "                    attr.data = attr.data.half()\n",
    "\n",
    "    model.apply(_convert_weights_to_fp16)\n",
    "\n",
    "\n",
    "def build_model(state_dict: dict):\n",
    "    vit = \"visual.proj\" in state_dict\n",
    "\n",
    "    if vit:\n",
    "        vision_width = state_dict[\"visual.conv1.weight\"].shape[0]\n",
    "        vision_layers = len([k for k in state_dict.keys() if k.startswith(\"visual.\") and k.endswith(\".attn.in_proj_weight\")])\n",
    "        vision_patch_size = state_dict[\"visual.conv1.weight\"].shape[-1]\n",
    "        grid_size = round((state_dict[\"visual.positional_embedding\"].shape[0] - 1) ** 0.5)\n",
    "        image_resolution = vision_patch_size * grid_size\n",
    "    else:\n",
    "        counts: list = [len(set(k.split(\".\")[2] for k in state_dict if k.startswith(f\"visual.layer{b}\"))) for b in [1, 2, 3, 4]]\n",
    "        vision_layers = tuple(counts)\n",
    "        vision_width = state_dict[\"visual.layer1.0.conv1.weight\"].shape[0]\n",
    "        output_width = round((state_dict[\"visual.attnpool.positional_embedding\"].shape[0] - 1) ** 0.5)\n",
    "        vision_patch_size = None\n",
    "        assert output_width ** 2 + 1 == state_dict[\"visual.attnpool.positional_embedding\"].shape[0]\n",
    "        image_resolution = output_width * 32\n",
    "\n",
    "    embed_dim = state_dict[\"text_projection\"].shape[1]\n",
    "    context_length = state_dict[\"positional_embedding\"].shape[0]\n",
    "    vocab_size = state_dict[\"token_embedding.weight\"].shape[0]\n",
    "    transformer_width = state_dict[\"ln_final.weight\"].shape[0]\n",
    "    transformer_heads = transformer_width // 64\n",
    "    transformer_layers = len(set(k.split(\".\")[2] for k in state_dict if k.startswith(\"transformer.resblocks\")))\n",
    "\n",
    "    model = CLIP(\n",
    "        embed_dim,\n",
    "        image_resolution, vision_layers, vision_width, vision_patch_size,\n",
    "        context_length, vocab_size, transformer_width, transformer_heads, transformer_layers\n",
    "    )\n",
    "\n",
    "    for key in [\"input_resolution\", \"context_length\", \"vocab_size\"]:\n",
    "        if key in state_dict:\n",
    "            del state_dict[key]\n",
    "\n",
    "    convert_weights(model)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_MODELS = {\n",
    "    \"RN50\": \"https://openaipublic.azureedge.net/clip/models/afeb0e10f9e5a86da6080e35cf09123aca3b358a0c3e3b6c78a7b63bc04b6762/RN50.pt\",\n",
    "    \"RN101\": \"https://openaipublic.azureedge.net/clip/models/8fa8567bab74a42d41c5915025a8e4538c3bdbe8804a470a72f30b0d94fab599/RN101.pt\",\n",
    "    \"RN50x4\": \"https://openaipublic.azureedge.net/clip/models/7e526bd135e493cef0776de27d5f42653e6b4c8bf9e0f653bb11773263205fdd/RN50x4.pt\",\n",
    "    \"RN50x16\": \"https://openaipublic.azureedge.net/clip/models/52378b407f34354e150460fe41077663dd5b39c54cd0bfd2b27167a4a06ec9aa/RN50x16.pt\",\n",
    "    \"RN50x64\": \"https://openaipublic.azureedge.net/clip/models/be1cfb55d75a9666199fb2206c106743da0f6468c9d327f3e0d0a543a9919d9c/RN50x64.pt\",\n",
    "    \"ViT-B/32\": \"https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\",\n",
    "    \"ViT-B/16\": \"https://openaipublic.azureedge.net/clip/models/5806e77cd80f8b59890b7e101eabd078d9fb84e6937f9e85e4ecb61988df416f/ViT-B-16.pt\",\n",
    "    \"ViT-L/14\": \"https://openaipublic.azureedge.net/clip/models/b8cca3fd41ae0c99ba7e8951adf17d267cdb84cd88be6f7c2e0eca1737a03836/ViT-L-14.pt\",\n",
    "    \"ViT-L/14@336px\": \"https://openaipublic.azureedge.net/clip/models/3035c92b350959924f9f00213499208652fc7ea050643e8b385c2dac08641f02/ViT-L-14-336px.pt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _download(url: str, root: str):\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "    filename = os.path.basename(url)\n",
    "\n",
    "    expected_sha256 = url.split(\"/\")[-2]\n",
    "    download_target = os.path.join(root, filename)\n",
    "\n",
    "    if os.path.exists(download_target) and not os.path.isfile(download_target):\n",
    "        raise RuntimeError(f\"{download_target} exists and is not a regular file\")\n",
    "\n",
    "    if os.path.isfile(download_target):\n",
    "        if hashlib.sha256(open(download_target, \"rb\").read()).hexdigest() == expected_sha256:\n",
    "            return download_target\n",
    "        else:\n",
    "            warnings.warn(f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\")\n",
    "\n",
    "    with urllib.request.urlopen(url) as source, open(download_target, \"wb\") as output:\n",
    "        with tqdm(total=int(source.info().get(\"Content-Length\")), ncols=80, unit='iB', unit_scale=True, unit_divisor=1024) as loop:\n",
    "            while True:\n",
    "                buffer = source.read(8192)\n",
    "                if not buffer:\n",
    "                    break\n",
    "\n",
    "                output.write(buffer)\n",
    "                loop.update(len(buffer))\n",
    "\n",
    "    if hashlib.sha256(open(download_target, \"rb\").read()).hexdigest() != expected_sha256:\n",
    "        raise RuntimeError(\"Model has been downloaded but the SHA256 checksum does not not match\")\n",
    "\n",
    "    return download_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"RN50\"\n",
    "if name in _MODELS:\n",
    "    model_path = _download(_MODELS[name], os.path.expanduser(\"~/.cache/clip\"))\n",
    "else:\n",
    "    raise RuntimeError(f\"Model {name} not found; available models = {available_models()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit=True\n",
    "with open(model_path, 'rb') as opened_file:\n",
    "    try:\n",
    "        # loading JIT archive\n",
    "        model = torch.jit.load(opened_file, map_location=device if jit else \"cpu\").eval()\n",
    "        state_dict = model.state_dict()\n",
    "    except RuntimeError:\n",
    "        # loading saved state dict\n",
    "        if jit:\n",
    "            warnings.warn(f\"File {model_path} is not a JIT archive. Loading as a state dict instead\")\n",
    "            jit = False\n",
    "        state_dict = torch.load(opened_file, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 6, 3)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#vision\n",
    "counts: list = [len(set(k.split(\".\")[2] for k in state_dict if k.startswith(f\"visual.layer{b}\"))) for b in [1, 2, 3, 4]]\n",
    "vision_layers = tuple(counts)\n",
    "print(vision_layers)\n",
    "vision_width = state_dict[\"visual.layer1.0.conv1.weight\"].shape[0]\n",
    "output_width = round((state_dict[\"visual.attnpool.positional_embedding\"].shape[0] - 1) ** 0.5)\n",
    "print(output_width)\n",
    "assert output_width ** 2 + 1 == state_dict[\"visual.attnpool.positional_embedding\"].shape[0]\n",
    "image_resolution = output_width * 32\n",
    "\n",
    "#transformer\n",
    "embed_dim = state_dict[\"text_projection\"].shape[1]\n",
    "context_length = state_dict[\"positional_embedding\"].shape[0]\n",
    "vocab_size = state_dict[\"token_embedding.weight\"].shape[0]\n",
    "transformer_width = state_dict[\"ln_final.weight\"].shape[0]\n",
    "transformer_heads = transformer_width // 64\n",
    "transformer_layers = len(set(k.split(\".\")[2] for k in state_dict if k.startswith(\"transformer.resblocks\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CLIP(\n",
    "#     embed_dim=state_dict[\"text_projection\"].shape[1],\n",
    "#     image_resolution=None, \n",
    "#     vision_layers=[3, 4, 6, 3], \n",
    "#     vision_width=64,\n",
    "#     context_length=state_dict[\"positional_embedding\"].shape[0], \n",
    "#     vocab_size=state_dict[\"token_embedding.weight\"].shape[0], \n",
    "#     transformer_width=state_dict[\"ln_final.weight\"].shape[0], \n",
    "#     transformer_heads=state_dict[\"ln_final.weight\"].shape[0]//64, \n",
    "#     transformer_layers=len(set(k.split(\".\")[2] for k in state_dict if k.startswith(\"transformer.resblocks\")))\n",
    "# )\n",
    "\n",
    "model = CLIP(\n",
    "    embed_dim,\n",
    "    image_resolution, vision_layers, vision_width,\n",
    "    context_length, vocab_size, transformer_width, transformer_heads, transformer_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trains the clip model from scratch\n",
    "def train_clip(model, text_samples, image_samples, batch_size=10, num_epochs=100, lr=1e-3, temp=0.07, clip_value=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.2)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        image_epoch_correct = 0\n",
    "        text_epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        text_samples, image_samples = unison_shuffled_copies(text_samples, image_samples)\n",
    "        for batch in range(math.floor(image_samples.shape[0]/batch_size)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #gets embeddings for text and image batches\n",
    "            start_idx = batch*batch_size\n",
    "            end_idx = (batch+1)*batch_size\n",
    "            text_batch, image_batch = text_samples[start_idx:end_idx], image_samples[start_idx:end_idx]\n",
    "            \n",
    "            logits_per_image, logits_per_text = model(torch.unsqueeze(image_batch, dim=1), text_batch)\n",
    "#             print(logits_per_image.shape)\n",
    "#             print(logits_per_image)\n",
    "            \n",
    "            #symmetric loss function\n",
    "            labels = torch.arange(batch_size).to(device)\n",
    "            loss_text = loss_fn(logits_per_text, labels)\n",
    "            loss_image = loss_fn(logits_per_image, labels)\n",
    "            loss = (loss_text + loss_image)/2\n",
    "            print(\"\\tBatch:\", batch, \"/\", math.floor(image_samples.shape[0]/batch_size), \", Loss:\", loss)\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #compute accuracy\n",
    "            image_winners = torch.argmax(logits_per_image, dim=0)\n",
    "            text_winners = torch.argmax(logits_per_text, dim=0)\n",
    "            #print(winners)\n",
    "            #print(labels)\n",
    "            image_corrects = (image_winners == labels)\n",
    "            text_corrects = (text_winners == labels)\n",
    "            total_image_correct = image_corrects.sum().float().item()\n",
    "            total_text_correct = text_corrects.sum().float().item()\n",
    "            image_epoch_correct += total_image_correct\n",
    "            text_epoch_correct += total_text_correct\n",
    "            epoch_total += batch_size\n",
    "#             for param in model.parameters():\n",
    "#                 print(torch.absolute(param.grad.data).sum())\n",
    "# #                 print(param.grad.data)\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Epoch:\", epoch, \"Training Loss:\", epoch_loss, \"Training Image Accuracy:\", image_epoch_correct/epoch_total, \"Training Text Accuracy:\", text_epoch_correct/epoch_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train using real fMRI and text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[49406,  3600,  9026,   739,   320, 49407,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [49406, 14295,   537,   797,  1466, 49407,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]], dtype=torch.int32)\n",
      "torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "print(tokenize([\"Harry potter was a\", \"wizard and he always\"]))\n",
    "print(tokenize([\"Harry potter was a\", \"wizard and he always\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_samples(samples):\n",
    "    images = torch.zeros([len(samples)] + list(samples[0][0].shape))\n",
    "    text = torch.zeros((len(samples), 16), dtype=int)\n",
    "    for idx, sample in enumerate(samples):\n",
    "        images[idx] = torch.tensor(sample[0])\n",
    "        text[idx] = tokenize([\" \".join(sample[1])])\n",
    "    images = (images - images.min())/(images.max() - images.min())\n",
    "    return images.to(device), text.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "torch.Size([1287, 16])\n",
      "torch.Size([1287, 53, 60, 50])\n"
     ]
    }
   ],
   "source": [
    "train_split = 1.0\n",
    "\n",
    "train_samples = subjects_samples[0][:int(len(subjects_samples[0])*train_split)]\n",
    "train_images, train_text = split_samples(train_samples)\n",
    "print(\"Train:\")\n",
    "print(train_text.shape)\n",
    "print(train_images.shape)\n",
    "if torch.isnan(torch.sum(train_text)) or torch.isinf(torch.sum(train_text)):\n",
    "    print('invalid input detected in text.')\n",
    "if torch.isnan(torch.sum(train_images)) or torch.isinf(torch.sum(train_images)):\n",
    "    print('invalid input detected in images.')\n",
    "\n",
    "# test_samples = subjects_samples[0][int(len(subjects_samples[0])*train_split):]\n",
    "# test_images, test_text = split_samples(test_samples)\n",
    "# print(\"Test:\")\n",
    "# print(len(test_text))\n",
    "# print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model = CLIP(\n",
    "    embed_dim,\n",
    "    image_resolution, (2,2,2,2), 64,\n",
    "    16, vocab_size, transformer_width, transformer_heads, transformer_layers\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 0 / 20 , Loss: tensor(4.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.8290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(5.0569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.3817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(4.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.2058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.1997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(4.1993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.1689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.1631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.1600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.1621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 0 Training Loss: 85.79557275772095 Training Image Accuracy: 0.0171875 Training Text Accuracy: 0.021875\n",
      "\tBatch: 0 / 20 , Loss: tensor(4.1424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.1556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(4.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(4.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(4.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.1379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.1450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(4.1296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.1327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.1245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.1340, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.1406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.1017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.1053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 1 Training Loss: 82.50481653213501 Training Image Accuracy: 0.01875 Training Text Accuracy: 0.0359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(4.0820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(4.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(4.0123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.9416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.7950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(4.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(4.3847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(4.1448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(4.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.9711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.0123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(4.0605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(4.1036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(4.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(4.0962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(4.0426, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(4.0404, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(4.1998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.0795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.9578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 2 Training Loss: 81.13617157936096 Training Image Accuracy: 0.0421875 Training Text Accuracy: 0.0390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.7657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.7888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(4.0108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.9095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.9331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.8017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.8174, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.7640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.8712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(4.0203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.8865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.8599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.7962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.8466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.8009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.8859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.7083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(4.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(4.0425, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 3 Training Loss: 77.10231018066406 Training Image Accuracy: 0.05859375 Training Text Accuracy: 0.07421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.7128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.5272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.5561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.6566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.5515, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(3.5521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.5373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.5351, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.3688, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.2117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.5466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.6507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.4819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.4253, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.5289, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 18 / 20 , Loss: tensor(3.6282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 4 Training Loss: 70.51367282867432 Training Image Accuracy: 0.08984375 Training Text Accuracy: 0.1015625\n",
      "\tBatch: 0 / 20 , Loss: tensor(3.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(3.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.2897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(3.2158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.8975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(3.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(3.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.2784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(3.1973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(3.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.3610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(3.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.3657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 5 Training Loss: 64.86231017112732 Training Image Accuracy: 0.11015625 Training Text Accuracy: 0.1265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.8418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(3.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.7427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(3.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.9634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.8814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.8752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.7248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(3.0846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(3.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(3.0189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(3.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.9918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.7514, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.9833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(3.3368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.9822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(3.2834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(3.0285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 6 Training Loss: 60.03501510620117 Training Image Accuracy: 0.14765625 Training Text Accuracy: 0.15859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.7740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.9272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.7599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.5116, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.8368, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(3.0672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.5856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.7436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.7572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.6372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(3.0382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.6898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.8591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.8871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.7561, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.8306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.9872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 7 Training Loss: 55.13221788406372 Training Image Accuracy: 0.1859375 Training Text Accuracy: 0.18671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.5408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.3292, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.5281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.5042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.8583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.7381, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.8147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.6454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.5333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.6532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.7762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.9407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.7002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.7923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.6662, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.9204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 8 Training Loss: 52.22615957260132 Training Image Accuracy: 0.21171875 Training Text Accuracy: 0.2203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.6407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.5937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.3771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.5150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.4100, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.2965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.4791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.4746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.5124, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.2958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.2999, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(2.5790, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.6592, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.5348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.7632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 9 Training Loss: 49.16825079917908 Training Image Accuracy: 0.24296875 Training Text Accuracy: 0.2359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(2.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.9997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(2.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.1674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.0402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.0575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.1559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.2284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.0103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.0580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.3841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.2776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.1212, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 10 Training Loss: 43.246243715286255 Training Image Accuracy: 0.3078125 Training Text Accuracy: 0.2984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.9264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.9825, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(2.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.9930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.9620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.9958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.9428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.9575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.0049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.1397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.9032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.4316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.2304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.4479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.0275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.2003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 11 Training Loss: 42.379660844802856 Training Image Accuracy: 0.3046875 Training Text Accuracy: 0.31171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(2.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.9621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.8427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(2.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.9856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(2.1407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(2.2538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(2.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.7977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(2.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.8772, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(2.1781, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(2.1784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.0013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(2.1596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.0338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.8729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 12 Training Loss: 41.18114101886749 Training Image Accuracy: 0.33359375 Training Text Accuracy: 0.3109375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.7799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.5821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.9583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.7621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.8737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.6303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.7638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.6594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(2.1422, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.6975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.9277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.7960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.6558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.2181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.7795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.6525, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.7473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.9187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 13 Training Loss: 36.40448868274689 Training Image Accuracy: 0.39921875 Training Text Accuracy: 0.4015625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.8546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.6030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.7233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.6472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.9644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.8521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.9485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.9626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.8677, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.7251, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 11 / 20 , Loss: tensor(2.1459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.9501, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.7364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(2.0579, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(2.2723, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.9649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(2.0297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(2.3118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.1846, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 14 Training Loss: 38.319405913352966 Training Image Accuracy: 0.384375 Training Text Accuracy: 0.365625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.7763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.8607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.7033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.9159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.6446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.8946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.9225, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.5803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(2.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.6556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.8498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(2.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.6823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.6663, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.8857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.7447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.5764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(2.0624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 15 Training Loss: 36.10843217372894 Training Image Accuracy: 0.4046875 Training Text Accuracy: 0.39140625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.6581, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.5380, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.7060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.7391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.5892, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.6349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.6586, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.4911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.3990, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.6904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.5533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.5284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.5674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.8862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.6932, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.9487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.8006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 16 Training Loss: 32.57222390174866 Training Image Accuracy: 0.4671875 Training Text Accuracy: 0.43203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.9659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.7784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.8689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.7540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.4700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.7710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.5584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.7052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.7518, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.5995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.7764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.6793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.7714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.4582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.7048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.5305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.6147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 17 Training Loss: 33.31865954399109 Training Image Accuracy: 0.4375 Training Text Accuracy: 0.42265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.4744, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.2085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.3409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.0848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.2810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.3304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.3742, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.4257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.3680, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.6965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.3907, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.5888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 18 Training Loss: 27.55555748939514 Training Image Accuracy: 0.53828125 Training Text Accuracy: 0.52578125\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.4661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.3443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.7682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.5686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.4565, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 7 / 20 , Loss: tensor(1.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.6144, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.3405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.5439, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.5858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.4587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.2430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 19 Training Loss: 27.946170449256897 Training Image Accuracy: 0.52265625 Training Text Accuracy: 0.5265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.1949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.2652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.1044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.2760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.3318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.2706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.2456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.4691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.4917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 20 Training Loss: 25.93335473537445 Training Image Accuracy: 0.5671875 Training Text Accuracy: 0.5375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.1845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.1403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.1740, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.9632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.0648, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.2474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.2747, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.5467, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.1854, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 21 Training Loss: 24.730577290058136 Training Image Accuracy: 0.5859375 Training Text Accuracy: 0.55625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.9257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.9880, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.9326, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.8802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.9267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.1040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.2066, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.2607, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 22 Training Loss: 21.342093348503113 Training Image Accuracy: 0.6609375 Training Text Accuracy: 0.621875\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.3080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8555, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.9492, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.5005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.0559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.6589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.5327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.4199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.7267, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.3975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.7818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.0797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 23 Training Loss: 26.245633959770203 Training Image Accuracy: 0.575 Training Text Accuracy: 0.54296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.9645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.2065, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 4 / 20 , Loss: tensor(1.1861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.4470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.0717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.3200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.2227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.1817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.4455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.4802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.3955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.4168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.1542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 24 Training Loss: 24.543788611888885 Training Image Accuracy: 0.615625 Training Text Accuracy: 0.584375\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.1252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(1.0230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.2323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.9860, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.9878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.2502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.0861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.3431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9881, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.9983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.4179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 25 Training Loss: 22.549220860004425 Training Image Accuracy: 0.61484375 Training Text Accuracy: 0.615625\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.2056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.9431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.9718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.0266, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.5397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.2433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.2507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.2528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.2894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.2348, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.4289, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.4269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.0098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 26 Training Loss: 24.30868351459503 Training Image Accuracy: 0.584375 Training Text Accuracy: 0.571875\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0480, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.1113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.1010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8785, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(1.0307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.0262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.9329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8415, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.1168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.2387, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 27 Training Loss: 19.872670769691467 Training Image Accuracy: 0.6703125 Training Text Accuracy: 0.66328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0346, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7827, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.9620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(1.3717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.2047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.9970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.2071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.9373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 28 Training Loss: 20.564057290554047 Training Image Accuracy: 0.67421875 Training Text Accuracy: 0.62421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(1.0003, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(0.8078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(1.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.9960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(1.0126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.9548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8718, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8449, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.0295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(1.1207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.0600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.9724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 29 Training Loss: 19.626762092113495 Training Image Accuracy: 0.6703125 Training Text Accuracy: 0.66640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.8924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.9308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8819, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.8111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(1.1091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8278, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 30 Training Loss: 17.012531340122223 Training Image Accuracy: 0.7265625 Training Text Accuracy: 0.7109375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.8672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(1.0481, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8485, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6499, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6416, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6696, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9248, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.9986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.0078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 31 Training Loss: 15.826253950595856 Training Image Accuracy: 0.75078125 Training Text Accuracy: 0.740625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7421, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.8343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8891, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.9752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8938, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.0816, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7247, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.0308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8570, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.0053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.0302, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.9263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 32 Training Loss: 17.727091073989868 Training Image Accuracy: 0.6953125 Training Text Accuracy: 0.68984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7376, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6565, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8231, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(1.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8934, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.7405, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 33 Training Loss: 15.71764761209488 Training Image Accuracy: 0.7625 Training Text Accuracy: 0.746875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.8899, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7435, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8077, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6995, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(1.0030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.8632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8008, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 34 Training Loss: 15.673408448696136 Training Image Accuracy: 0.73125 Training Text Accuracy: 0.7265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6566, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.9255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.8307, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7024, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.9872, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.9285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(1.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(1.0596, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 35 Training Loss: 16.341577172279358 Training Image Accuracy: 0.72734375 Training Text Accuracy: 0.73203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.8805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9890, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.8320, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8516, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5229, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8976, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7876, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 36 Training Loss: 16.36756306886673 Training Image Accuracy: 0.725 Training Text Accuracy: 0.725\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.9739, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.9163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(1.1192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.9245, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.9022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7714, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 37 Training Loss: 15.644852697849274 Training Image Accuracy: 0.7609375 Training Text Accuracy: 0.75\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6906, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5389, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7184, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7606, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7926, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8978, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 16 / 20 , Loss: tensor(0.6828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 38 Training Loss: 14.575884878635406 Training Image Accuracy: 0.76328125 Training Text Accuracy: 0.75234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5179, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5209, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 39 Training Loss: 12.551152646541595 Training Image Accuracy: 0.82578125 Training Text Accuracy: 0.80703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4507, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8036, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.8373, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6537, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.8704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7072, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 40 Training Loss: 12.404715329408646 Training Image Accuracy: 0.82265625 Training Text Accuracy: 0.8109375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5762, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.8558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7658, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6171, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 41 Training Loss: 13.940089404582977 Training Image Accuracy: 0.790625 Training Text Accuracy: 0.765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6367, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(1.0043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.9544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.9324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8409, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(1.0349, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6917, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7659, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 42 Training Loss: 15.14011001586914 Training Image Accuracy: 0.75703125 Training Text Accuracy: 0.7640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5656, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6802, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 12 / 20 , Loss: tensor(1.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 43 Training Loss: 13.341532766819 Training Image Accuracy: 0.790625 Training Text Accuracy: 0.7984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7305, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6038, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.8590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.9386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7818, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7228, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8621, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7443, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.8129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7070, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 44 Training Loss: 14.759393453598022 Training Image Accuracy: 0.74921875 Training Text Accuracy: 0.7609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6509, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(1.0366, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5595, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.9637, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8202, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 45 Training Loss: 14.151414811611176 Training Image Accuracy: 0.759375 Training Text Accuracy: 0.7609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8185, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6469, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5734, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5462, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7391, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6045, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.8094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 46 Training Loss: 12.673474967479706 Training Image Accuracy: 0.81171875 Training Text Accuracy: 0.79765625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5588, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6098, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5295, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5068, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.7303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7233, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7369, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7459, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7484, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6542, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 47 Training Loss: 13.04464966058731 Training Image Accuracy: 0.790625 Training Text Accuracy: 0.79453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5701, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7944, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5967, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5537, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 8 / 20 , Loss: tensor(0.5456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7355, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.8427, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5732, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(1.0814, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 48 Training Loss: 12.873430728912354 Training Image Accuracy: 0.8109375 Training Text Accuracy: 0.7984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.8004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5560, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5922, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.8189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.8653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6681, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.7083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.9905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 49 Training Loss: 14.222853243350983 Training Image Accuracy: 0.78359375 Training Text Accuracy: 0.76640625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6583, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.8009, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6838, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6654, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.7448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6046, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7669, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7643, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.8126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 50 Training Loss: 13.424350142478943 Training Image Accuracy: 0.796875 Training Text Accuracy: 0.78359375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5896, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6465, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7544, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 51 Training Loss: 11.343082249164581 Training Image Accuracy: 0.8328125 Training Text Accuracy: 0.840625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4163, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5396, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5991, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7214, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5928, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.7286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 52 Training Loss: 11.18298152089119 Training Image Accuracy: 0.85859375 Training Text Accuracy: 0.846875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.7512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6158, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 4 / 20 , Loss: tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5311, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4414, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4318, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5708, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 53 Training Loss: 10.362672865390778 Training Image Accuracy: 0.87265625 Training Text Accuracy: 0.859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5003, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3826, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5142, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5035, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.7269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.8936, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5053, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.7291, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7691, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 54 Training Loss: 11.374559074640274 Training Image Accuracy: 0.815625 Training Text Accuracy: 0.84453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.8235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6721, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4538, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5712, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6601, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6215, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 55 Training Loss: 12.343165278434753 Training Image Accuracy: 0.82109375 Training Text Accuracy: 0.82265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.7076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5430, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7490, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5517, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6657, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5916, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7141, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7711, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 56 Training Loss: 12.450634717941284 Training Image Accuracy: 0.79765625 Training Text Accuracy: 0.81328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5556, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4918, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5181, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5511, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6260, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6408, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6167, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.8576, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5953, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 57 Training Loss: 12.489810526371002 Training Image Accuracy: 0.8046875 Training Text Accuracy: 0.81796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 0 / 20 , Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6431, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.7587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4080, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(1.1957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5577, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6471, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.7272, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4357, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5512, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6977, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 58 Training Loss: 11.966533482074738 Training Image Accuracy: 0.825 Training Text Accuracy: 0.82421875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5841, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.7261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5625, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6429, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 59 Training Loss: 11.47016754746437 Training Image Accuracy: 0.8359375 Training Text Accuracy: 0.82890625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.7275, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.8258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4985, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5534, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5591, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5329, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 60 Training Loss: 10.777456432580948 Training Image Accuracy: 0.83046875 Training Text Accuracy: 0.8546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4626, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4728, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5447, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4850, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4889, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5388, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4887, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 61 Training Loss: 9.979994595050812 Training Image Accuracy: 0.86953125 Training Text Accuracy: 0.865625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4223, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4475, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5157, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4399, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5017, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6871, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4153, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 18 / 20 , Loss: tensor(0.4930, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 62 Training Loss: 9.20815885066986 Training Image Accuracy: 0.8984375 Training Text Accuracy: 0.88203125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5900, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4251, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3808, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 63 Training Loss: 8.435854583978653 Training Image Accuracy: 0.91484375 Training Text Accuracy: 0.9046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3417, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3882, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4735, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3164, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3893, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3099, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3829, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4341, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 64 Training Loss: 7.695187747478485 Training Image Accuracy: 0.91875 Training Text Accuracy: 0.90703125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3240, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4679, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3788, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3198, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4982, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4392, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4418, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3867, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 65 Training Loss: 8.151126861572266 Training Image Accuracy: 0.9171875 Training Text Accuracy: 0.9078125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4073, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4557, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5453, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 66 Training Loss: 9.344518959522247 Training Image Accuracy: 0.87421875 Training Text Accuracy: 0.88671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7094, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5378, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5466, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5552, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5464, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6005, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 15 / 20 , Loss: tensor(0.4250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4815, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6706, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7262, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.7147, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 67 Training Loss: 11.09088408946991 Training Image Accuracy: 0.828125 Training Text Accuracy: 0.8375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.9321, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6905, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6863, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4895, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6309, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.7041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6837, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6933, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6316, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 68 Training Loss: 12.703205704689026 Training Image Accuracy: 0.803125 Training Text Accuracy: 0.83046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5400, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7559, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.6050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7286, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6323, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5455, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4221, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5861, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 69 Training Loss: 11.772065162658691 Training Image Accuracy: 0.8390625 Training Text Accuracy: 0.81796875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5315, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4224, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5018, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5207, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5778, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5974, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.8183, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4598, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6704, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4791, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5962, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5823, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 70 Training Loss: 10.711852878332138 Training Image Accuracy: 0.8734375 Training Text Accuracy: 0.84609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5280, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3842, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5535, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4633, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4784, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4523, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6914, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 71 Training Loss: 9.430395662784576 Training Image Accuracy: 0.884375 Training Text Accuracy: 0.87265625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3530, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5424, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4810, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3393, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 12 / 20 , Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4752, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 72 Training Loss: 8.337689012289047 Training Image Accuracy: 0.90703125 Training Text Accuracy: 0.91171875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4649, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5343, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3613, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6361, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6803, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4282, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4839, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 73 Training Loss: 10.363544315099716 Training Image Accuracy: 0.8421875 Training Text Accuracy: 0.859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.6622, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5847, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3755, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6997, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.6554, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4062, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3836, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5407, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 74 Training Loss: 10.338766187429428 Training Image Accuracy: 0.8390625 Training Text Accuracy: 0.86328125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4767, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4030, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5463, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5365, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6945, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 75 Training Loss: 10.031276017427444 Training Image Accuracy: 0.86640625 Training Text Accuracy: 0.8609375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5960, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5244, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5013, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6299, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4904, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4984, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6610, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4733, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5331, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 76 Training Loss: 10.785412758588791 Training Image Accuracy: 0.85546875 Training Text Accuracy: 0.84296875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4145, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4456, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4913, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 8 / 20 , Loss: tensor(0.8441, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6660, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.6211, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5332, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6737, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 77 Training Loss: 10.805682629346848 Training Image Accuracy: 0.83515625 Training Text Accuracy: 0.84453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4573, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5644, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3831, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5540, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5804, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5261, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4802, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4746, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5047, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4382, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 78 Training Loss: 10.085445046424866 Training Image Accuracy: 0.86953125 Training Text Accuracy: 0.85234375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 79 Training Loss: 9.118038803339005 Training Image Accuracy: 0.88203125 Training Text Accuracy: 0.88125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.5086, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4158, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3457, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5060, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4412, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4303, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5942, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3590, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 80 Training Loss: 8.741308808326721 Training Image Accuracy: 0.89140625 Training Text Accuracy: 0.89453125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4653, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4285, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3411, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4690, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4584, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4541, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5284, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3646, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4989, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 81 Training Loss: 8.66979256272316 Training Image Accuracy: 0.9015625 Training Text Accuracy: 0.88671875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4533, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 4 / 20 , Loss: tensor(0.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3102, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3717, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5874, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3322, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3629, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4234, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3578, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4057, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 82 Training Loss: 8.04825747013092 Training Image Accuracy: 0.9 Training Text Accuracy: 0.91796875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3843, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2695, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3852, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3398, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4434, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3963, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4450, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 83 Training Loss: 7.020761996507645 Training Image Accuracy: 0.92734375 Training Text Accuracy: 0.925\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4022, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.2797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4148, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4187, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5886, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4004, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 84 Training Loss: 8.135888695716858 Training Image Accuracy: 0.9015625 Training Text Accuracy: 0.9\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4235, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3604, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.6114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4296, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 85 Training Loss: 8.522399246692657 Training Image Accuracy: 0.8953125 Training Text Accuracy: 0.8953125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3775, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.6271, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4710, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3853, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4138, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.6670, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4217, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4259, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4549, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 86 Training Loss: 9.265363216400146 Training Image Accuracy: 0.87578125 Training Text Accuracy: 0.87890625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4821, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 1 / 20 , Loss: tensor(0.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.6246, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5298, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.9162, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6270, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.6023, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(1.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5333, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.8528, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5671, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5548, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5433, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.7250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.5104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.6642, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 87 Training Loss: 12.008556842803955 Training Image Accuracy: 0.8203125 Training Text Accuracy: 0.83046875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4943, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4547, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4923, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.6605, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.7010, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.5089, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6748, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.9120, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4709, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4903, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.6474, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6006, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.5213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.6095, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 88 Training Loss: 11.260180830955505 Training Image Accuracy: 0.83828125 Training Text Accuracy: 0.828125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.5620, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3912, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.7879, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.6806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4801, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.7634, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.6470, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.7724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6375, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5543, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4817, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.5569, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5845, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.7822, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 89 Training Loss: 11.255521059036255 Training Image Accuracy: 0.83515625 Training Text Accuracy: 0.8375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4461, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4370, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4639, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4828, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5497, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4765, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4715, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5550, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.5865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4113, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4572, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 90 Training Loss: 9.284099996089935 Training Image Accuracy: 0.878125 Training Text Accuracy: 0.875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3436, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.5795, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3968, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4324, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4252, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.5954, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3384, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4948, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4233, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 19 / 20 , Loss: tensor(0.3924, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 91 Training Loss: 8.915916502475739 Training Image Accuracy: 0.88359375 Training Text Accuracy: 0.8875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3166, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3834, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3705, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3001, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4314, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4981, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3076, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3947, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4568, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 92 Training Loss: 7.726303368806839 Training Image Accuracy: 0.9171875 Training Text Accuracy: 0.91875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4002, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3226, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2911, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3264, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3858, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4949, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4277, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3624, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.5494, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 93 Training Loss: 7.892736464738846 Training Image Accuracy: 0.90859375 Training Text Accuracy: 0.903125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3703, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4763, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4290, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.5347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4274, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.5255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4379, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3635, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.6374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3805, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 94 Training Loss: 9.07957237958908 Training Image Accuracy: 0.87890625 Training Text Accuracy: 0.88984375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4720, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3868, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3473, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4756, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3730, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3672, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3862, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3374, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 95 Training Loss: 7.787190228700638 Training Image Accuracy: 0.91796875 Training Text Accuracy: 0.91875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3809, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.4243, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4232, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3647, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3210, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3203, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4840, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3449, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch: 16 / 20 , Loss: tensor(0.3524, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4347, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 96 Training Loss: 7.555694550275803 Training Image Accuracy: 0.9140625 Training Text Accuracy: 0.90390625\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3428, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3344, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3797, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4500, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.5526, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.3043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4397, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3983, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3724, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 97 Training Loss: 7.86100235581398 Training Image Accuracy: 0.915625 Training Text Accuracy: 0.90546875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3798, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.4200, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.5608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3194, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3894, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 98 Training Loss: 7.1848354190588 Training Image Accuracy: 0.9234375 Training Text Accuracy: 0.93125\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.4149, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.5161, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.5110, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.4273, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.6220, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.4034, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.3668, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.4597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.3727, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 99 Training Loss: 8.249094158411026 Training Image Accuracy: 0.8984375 Training Text Accuracy: 0.89921875\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.4069, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.4197, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.4096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.3980, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.4448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3833, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.2575, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.4192, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4139, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 13 / 20 , Loss: tensor(0.3510, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 14 / 20 , Loss: tensor(0.4294, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 15 / 20 , Loss: tensor(0.3636, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 16 / 20 , Loss: tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 17 / 20 , Loss: tensor(0.4386, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 18 / 20 , Loss: tensor(0.3410, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 19 / 20 , Loss: tensor(0.4319, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch: 100 Training Loss: 7.802944004535675 Training Image Accuracy: 0.9 Training Text Accuracy: 0.90859375\n",
      "\tBatch: 0 / 20 , Loss: tensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 1 / 20 , Loss: tensor(0.3865, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 2 / 20 , Loss: tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 3 / 20 , Loss: tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 4 / 20 , Loss: tensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 5 / 20 , Loss: tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 6 / 20 , Loss: tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 7 / 20 , Loss: tensor(0.3864, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 8 / 20 , Loss: tensor(0.3731, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 9 / 20 , Loss: tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 10 / 20 , Loss: tensor(0.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 11 / 20 , Loss: tensor(0.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "\tBatch: 12 / 20 , Loss: tensor(0.4053, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train_clip(clip_model, train_text, train_images, batch_size=64, lr=1e-4, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for alpha in (1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9):\n",
    "#     print(\"Alpha:\", alpha)\n",
    "#     clip_model = CLIP(\n",
    "#         embed_dim,\n",
    "#         image_resolution, (2,2,2,2), 64,\n",
    "#         16, vocab_size, transformer_width, transformer_heads, transformer_layers\n",
    "#     ).to(device)\n",
    "#     train_clip(clip_model, train_text, train_images, batch_size=64, lr=alpha, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
