{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eO1tSqzp8YE"
   },
   "source": [
    "This file contains the implementation of ridge (L2) regression for mapping fMRI embeddings to CLIP and word2vec embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d14zQ3DZq6MK"
   },
   "source": [
    "First setup baseline model (word2vec) (Not yet implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT4mOgANq4sG",
    "outputId": "da6cf362-0555-454c-8199-8c5feabb7ffb"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# semeval-2016-2017-task3-subtaskA-unannotated\n",
    "model = api.load(\"glove-twitter-25\")  # download the model and return as object ready for use\n",
    "# model.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "GahCiBSmdpZc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import nibabel as nib\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "# from google.colab import drive\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z63hCATpLLOt",
    "outputId": "b6eba5ad-53b3-4753-d60a-a774b16e59c8"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')\n",
    "fMRI_folder = Path('doi_10.5061_dryad.gt413__v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1SWm20pKzuU",
    "outputId": "0b848180-1242-48c4-c82d-06e6e80349b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 0\n",
      "Subject: 1\n"
     ]
    }
   ],
   "source": [
    "NUM_SUBJS = 8\n",
    "subjects_fmri = [] #stores all 8 subject fmri np arrays\n",
    "\n",
    "# fMRI_folder = Path('./doi_10.5061_dryad.gt413__v1')\n",
    "# assert fMRI_folder.exists(), f\"Foldder: {fMRI_folder} does not exist.\"\n",
    "\n",
    "for subj_id in range(2):\n",
    "    print(\"Subject:\",subj_id)\n",
    "#     fmri_file_name = str(subj_id) + '_masked_2d.npy'\n",
    "#     fmri = np.load(fMRI_folder / fmri_file_name)\n",
    "    fmri_file_name = str(subj_id) + '_smooth_nifti_4d.nii'\n",
    "    fmri = nib.load(fMRI_folder / fmri_file_name)\n",
    "    fmri = np.array(fmri.dataobj)\n",
    "    assert isinstance(fmri, np.ndarray), f\"Imported fmri_scan for subject {subj_id} is not of type numpy.ndarray\"\n",
    "    assert(fmri.ndim) == 4, f\"Imported fmri_scan for subject {subj_id} is not 4 dimensional\"\n",
    "    subjects_fmri.append(fmri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 53, 60, 50, 1311)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(subjects_fmri) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBZTp5VgVEom",
    "outputId": "dfe79b3d-f7d0-4b42-c69b-6a7635586ba8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 60, 50, 1311)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(subjects_fmri[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HKm-vOaOJwZH"
   },
   "outputs": [],
   "source": [
    "feature_matrix = np.zeros((5176,195)) #stores the feature vectors as a row for each word\n",
    "feature_names = [] #stores the names of all features in order\n",
    "feature_types = {} #stores the types of features and all the names of the features for each type\n",
    "\n",
    "features = sio.loadmat(fMRI_folder/'story_features.mat')\n",
    "feature_count = 0\n",
    "for feature_type in features['features'][0]:\n",
    "    feature_types[feature_type[0][0]] = []\n",
    "    if isinstance(feature_type[1][0], str):\n",
    "        feature_types[feature_type[0][0]].append(feature_type[1][0])\n",
    "        feature_names.append(feature_type[1][0])\n",
    "    else:\n",
    "        for feature in feature_type[1][0]:\n",
    "            feature_types[feature_type[0][0]].append(feature[0])\n",
    "            feature_names.append(feature[0])\n",
    "    feature_matrix[:, feature_count:feature_count+feature_type[2].shape[1]] = feature_type[2] #adds the (5176xN) feature values to the feature matrix for the current feature group\n",
    "    feature_count += feature_type[2].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9Ks5wTcKJmjz"
   },
   "outputs": [],
   "source": [
    "words_info = [] #stores tuples of (word, time, features) sorted by time appeared\n",
    "\n",
    "mat_file = 'subject_1.mat' #only looks at the first subject file, somewhere it said all the timings were the same so this should be safe\n",
    "mat_contents = sio.loadmat(fMRI_folder/mat_file)\n",
    "# print(mat_content)\n",
    "for count, row in enumerate(mat_contents['words'][0]):\n",
    "    word_value = row[0][0][0][0]\n",
    "    time = row[1][0][0]\n",
    "    \n",
    "    word_tuple = (word_value, time, feature_matrix[count,:])\n",
    "    words_info.append(word_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DP3j_XQJnJR",
    "outputId": "094873e7-c700-4223-84ae-087150e3f246"
   },
   "outputs": [],
   "source": [
    "chapter_nine_text = \"\"\n",
    "for row in mat_contents['words'][0]:\n",
    "    chapter_nine_text += row[0][0][0][0] + \" \"\n",
    "# print(chapter_nine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjvOavtmUsTG",
    "outputId": "a69f8cd4-dd3c-47be-99a2-b1fcfdf391de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (53, 60, 50, 1311)\n",
      "1 (53, 60, 50, 1311)\n"
     ]
    }
   ],
   "source": [
    "for count, subject in enumerate(subjects_fmri):\n",
    "    print(count, np.shape(subject))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fmri_indices', 'rb') as f:\n",
    "    fmri_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muTykRqfJcpY"
   },
   "source": [
    "Harrison's implementation of Gaussian weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "FOE-RCeGJcNV"
   },
   "outputs": [],
   "source": [
    "def hrf_alignment(num_words, words_info, NUM_SUBJS, subjects_fmri):\n",
    "\n",
    "    subjects_samples = [[] for i in range(NUM_SUBJS)] #stores lists of all the samples for each subject\n",
    "    window = signal.windows.gaussian(16, std=1) #gaussian window for the 4 fMRI scans\n",
    "    num_words = num_words\n",
    "    word_count = 0\n",
    "    while word_count < len(words_info) - 24:\n",
    "        #gets the 4 input words, and the 4 consecutive words while verifying they were read in sequence\n",
    "        scan_words = []\n",
    "        start_time = words_info[word_count][1]\n",
    "        in_sequence = True #tracks if the words are in sequence or not\n",
    "        for i in range(num_words):\n",
    "            word_info = words_info[word_count + i]\n",
    "            if word_info[1] != start_time + 0.5*i:\n",
    "                #if some of the words are not in sequence, skip forward 1 word after innter loop\n",
    "                in_sequence = False\n",
    "            scan_words.append(word_info[0])\n",
    "        if not in_sequence:\n",
    "            word_count +=1\n",
    "            continue\n",
    "        fmri_time = start_time #fMRI is taken at first word read\n",
    "        fmri_index = fmri_time//2 #since a scan happens every two seconds, the index is the time divided by 2\n",
    "        if not np.issubdtype(fmri_index, np.integer):\n",
    "            #if the first word is not aligned with the fmri scan (i.e. its not the first word in a TR)\n",
    "            word_count += 1\n",
    "            continue\n",
    "        break_found = False\n",
    "        for count, subject in enumerate(subjects_fmri):\n",
    "#             print(\"Subject:\",count)\n",
    "            #adds tuple of (fmri_scan, four words)\n",
    "            for i in range(num_words): #time delay of reading word after fMRI scan\n",
    "                delay = 0.5*i #delay after first word\n",
    "                for j in range(1,5): #get next 4 fMRI scans\n",
    "                    fMRI_delay = 2*j - delay #delay until jth next fMRI scan\n",
    "                    weight = window[int(2*fMRI_delay)-1] #gets the gaussian weighting (16 points instead of 8 to allow for .5)\n",
    "                    try:\n",
    "                        curr_fmri_idx = fmri_indices.index((start_time + math.floor(i/4) + 2*j)//2) #gets the index of the jth next fMRI scan\n",
    "                    except:\n",
    "#                         print(\"break found at index:\",(start_time + math.floor(i/4) + 2*j)//2)\n",
    "                        break_found = True\n",
    "                        break\n",
    "                    #adds weight fMRI scan\n",
    "                    if j == 1:\n",
    "                        word_scan = weight*subject[:,:,:,curr_fmri_idx]\n",
    "                    else:\n",
    "                        word_scan += weight*subject[:,:,:,curr_fmri_idx]\n",
    "                if break_found:\n",
    "                    break\n",
    "                if i == 0:\n",
    "                    summed_weighted_scans = word_scan\n",
    "                else:\n",
    "                    summed_weighted_scans += word_scan\n",
    "            if break_found:\n",
    "                break\n",
    "            subjects_samples[count].append((summed_weighted_scans/num_words, scan_words))\n",
    "        if break_found:\n",
    "            word_count += 1\n",
    "            continue \n",
    "#         print(\"Created sample:\")\n",
    "#         print(\"\\tScan time:\", str(start_time))\n",
    "#         print(\"\\tInput words:\", str(scan_words))\n",
    "        #if successful, skip forward to the next set of 4 words\n",
    "        word_count += 4\n",
    "    return subjects_samples\n",
    "\n",
    "    print(\"Total number of samples:\", str(len(subjects_samples[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "hDooPY-xnS96"
   },
   "outputs": [],
   "source": [
    "def get_fMRI_embedding(subjects_samples):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    flattened_shape = reduce(np.multiply, subjects_samples[0][0].shape)\n",
    "    X_matrix = np.zeros((len(subjects_samples), flattened_shape))\n",
    "\n",
    "    for idx, sample in enumerate(subjects_samples):\n",
    "        tmp = sample[0]\n",
    "        # Reshape the voxels \n",
    "        tmp = tmp.ravel()\n",
    "        X_matrix[idx,:] = tmp\n",
    "        \n",
    "    # Apply voxelwise standardization        \n",
    "    X_matrix = scaler.fit_transform(X_matrix)\n",
    "    \n",
    "    return X_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "ZoeD2JzgXvSY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jai's Implementation of clip embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_embedding(subject_sample, model,processor):\n",
    "    word_list = []\n",
    "    for i in range(len(subject_sample)):\n",
    "        word_list.append(subject_sample[i][1])\n",
    "    new_word_list = [' '.join(sublist) for sublist in word_list]\n",
    "    \n",
    "    inputs = processor(text=new_word_list, images=image, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # text_embeds is in the same space as the given image\n",
    "        text_embeds = outputs['text_embeds']\n",
    "\n",
    "        # pooler_output is just the text embedding \n",
    "        # This is what we want to use I think \n",
    "        pooler_output = outputs['text_model_output']['pooler_output']\n",
    "#         print(pooler_output.numpy().shape)\n",
    "    return pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "UzhyDXB3qNsU"
   },
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "\n",
    "def split_data(X_matrix, Y_matrix):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_matrix, y_matrix,\n",
    "                                                        test_size=0.20,\n",
    "                                                        shuffle=False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "XTAuddpyeVcI"
   },
   "outputs": [],
   "source": [
    "# Train Ridge Regression Model\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \n",
    "    ridge_model = Ridge(alpha=1.0)\n",
    "    model = ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "D_M1TZx5Ru1n"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, random_text_embedding):\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Predict text embedding from test fMRI data\n",
    "    y_pred = model.predict(X_test)\n",
    "#     print(np.shape(y_pred))\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    prediction_similarity_true = cosine_similarity(y_test, y_pred)\n",
    "    prediction_similarity_random = cosine_similarity(random_text_embedding, y_pred)\n",
    "#     print(np.shape(prediction_similarity_true), np.shape(prediction_similarity_true))\n",
    "    \n",
    "     # Count the occurrences of \"1\" in the first column    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        if prediction_similarity_true[i].mean() < prediction_similarity_random[i].mean():\n",
    "            correct_predictions +=1\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = (correct_predictions / X_test.shape[0])\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Z4cuRbSqqRza",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_two_way_class_result(model, X_test, y_test, y_matrix, batches):\n",
    "    accuracy = []\n",
    "    for i in range(batches):\n",
    "        idx = np.arange(len(y_test))\n",
    "        np.random.shuffle(idx)\n",
    "\n",
    "        random_text_embedding = y_matrix[idx]\n",
    "\n",
    "        test_accuracy = evaluate_model(model, X_test, y_test, random_text_embedding)\n",
    "        accuracy.append(test_accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracy)/ batches\n",
    "    \n",
    "    print(accuracy)\n",
    "    print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "NEaDKYWTR7Mp",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining aligned fMRI scan for context length: 4---------------------------------------------\n",
      "---------Obtaining clip and fMRI embedding for subject 0-----------------\n",
      "Subject 0 \n",
      " fMRI Embedding Shape: (1235, 159000) \n",
      " Text Embedding Shape: torch.Size([1235, 768])\n",
      "---------Spliting data for subject 0-----------------\n",
      "---------Training started for subject 0-----------------\n",
      "---------Getting two way classification accuracy for subject 0-----------------\n",
      "\n",
      "[0.3724696356275304, 0.41295546558704455, 0.4008097165991903, 0.44129554655870445, 0.38866396761133604, 0.4048582995951417, 0.4089068825910931, 0.38461538461538464]\n",
      "Average Accuracy: 40.18%\n",
      "---------Obtaining clip and fMRI embedding for subject 1-----------------\n",
      "Subject 1 \n",
      " fMRI Embedding Shape: (1235, 159000) \n",
      " Text Embedding Shape: torch.Size([1235, 768])\n",
      "---------Spliting data for subject 1-----------------\n",
      "---------Training started for subject 1-----------------\n",
      "---------Getting two way classification accuracy for subject 1-----------------\n",
      "\n",
      "[0.44534412955465585, 0.48582995951417, 0.4534412955465587, 0.4534412955465587, 0.44129554655870445, 0.4574898785425101, 0.43724696356275305, 0.46963562753036436]\n",
      "Average Accuracy: 45.55%\n",
      "Subject: 1 \n",
      " Context Length: 4 \n",
      " Average Accuracy: 0.45546558704453444\n",
      "\n",
      "\n",
      "Obtaining aligned fMRI scan for context length: 8---------------------------------------------\n",
      "---------Obtaining clip and fMRI embedding for subject 0-----------------\n",
      "Subject 0 \n",
      " fMRI Embedding Shape: (1233, 159000) \n",
      " Text Embedding Shape: torch.Size([1233, 768])\n",
      "---------Spliting data for subject 0-----------------\n",
      "---------Training started for subject 0-----------------\n",
      "---------Getting two way classification accuracy for subject 0-----------------\n",
      "\n",
      "[0.46153846153846156, 0.4493927125506073, 0.47368421052631576, 0.4493927125506073, 0.4291497975708502, 0.4291497975708502, 0.4534412955465587, 0.44129554655870445]\n",
      "Average Accuracy: 44.84%\n",
      "---------Obtaining clip and fMRI embedding for subject 1-----------------\n",
      "Subject 1 \n",
      " fMRI Embedding Shape: (1233, 159000) \n",
      " Text Embedding Shape: torch.Size([1233, 768])\n",
      "---------Spliting data for subject 1-----------------\n",
      "---------Training started for subject 1-----------------\n",
      "---------Getting two way classification accuracy for subject 1-----------------\n",
      "\n",
      "[0.5020242914979757, 0.4939271255060729, 0.5141700404858299, 0.5141700404858299, 0.5425101214574899, 0.5060728744939271, 0.46963562753036436, 0.5546558704453441]\n",
      "Average Accuracy: 51.21%\n",
      "Subject: 1 \n",
      " Context Length: 8 \n",
      " Average Accuracy: 0.5121457489878543\n",
      "\n",
      "\n",
      "Obtaining aligned fMRI scan for context length: 12---------------------------------------------\n",
      "---------Obtaining clip and fMRI embedding for subject 0-----------------\n",
      "Subject 0 \n",
      " fMRI Embedding Shape: (1228, 159000) \n",
      " Text Embedding Shape: torch.Size([1228, 768])\n",
      "---------Spliting data for subject 0-----------------\n",
      "---------Training started for subject 0-----------------\n",
      "---------Getting two way classification accuracy for subject 0-----------------\n",
      "\n",
      "[0.34959349593495936, 0.3333333333333333, 0.33739837398373984, 0.34959349593495936, 0.3333333333333333, 0.35772357723577236, 0.34552845528455284, 0.3333333333333333]\n",
      "Average Accuracy: 34.25%\n",
      "---------Obtaining clip and fMRI embedding for subject 1-----------------\n",
      "Subject 1 \n",
      " fMRI Embedding Shape: (1228, 159000) \n",
      " Text Embedding Shape: torch.Size([1228, 768])\n",
      "---------Spliting data for subject 1-----------------\n",
      "---------Training started for subject 1-----------------\n",
      "---------Getting two way classification accuracy for subject 1-----------------\n",
      "\n",
      "[0.47560975609756095, 0.45121951219512196, 0.45121951219512196, 0.47560975609756095, 0.4878048780487805, 0.45934959349593496, 0.5, 0.4715447154471545]\n",
      "Average Accuracy: 47.15%\n",
      "Subject: 1 \n",
      " Context Length: 12 \n",
      " Average Accuracy: 0.4715447154471545\n",
      "\n",
      "\n",
      "Obtaining aligned fMRI scan for context length: 16---------------------------------------------\n",
      "---------Obtaining clip and fMRI embedding for subject 0-----------------\n",
      "Subject 0 \n",
      " fMRI Embedding Shape: (1227, 159000) \n",
      " Text Embedding Shape: torch.Size([1227, 768])\n",
      "---------Spliting data for subject 0-----------------\n",
      "---------Training started for subject 0-----------------\n",
      "---------Getting two way classification accuracy for subject 0-----------------\n",
      "\n",
      "[0.3902439024390244, 0.3902439024390244, 0.3861788617886179, 0.4024390243902439, 0.3780487804878049, 0.4024390243902439, 0.3983739837398374, 0.3943089430894309]\n",
      "Average Accuracy: 39.28%\n",
      "---------Obtaining clip and fMRI embedding for subject 1-----------------\n",
      "Subject 1 \n",
      " fMRI Embedding Shape: (1227, 159000) \n",
      " Text Embedding Shape: torch.Size([1227, 768])\n",
      "---------Spliting data for subject 1-----------------\n",
      "---------Training started for subject 1-----------------\n",
      "---------Getting two way classification accuracy for subject 1-----------------\n",
      "\n",
      "[0.5365853658536586, 0.5203252032520326, 0.532520325203252, 0.5365853658536586, 0.5040650406504065, 0.4878048780487805, 0.5203252032520326, 0.5121951219512195]\n",
      "Average Accuracy: 51.88%\n",
      "Subject: 1 \n",
      " Context Length: 16 \n",
      " Average Accuracy: 0.5188008130081301\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_lengths = [4,8,12,16]\n",
    "NUM_SUBJS = 2\n",
    "for length in context_lengths:\n",
    "    # Step 1: Obtain aligned fMRI embedding with words\n",
    "    print(f'Obtaining aligned fMRI scan for context length: {length}---------------------------------------------')\n",
    "    subjects_samples = hrf_alignment(length, words_info, NUM_SUBJS, subjects_fmri)\n",
    "\n",
    "    # Step 2: Obtain text and fMRI embedding\n",
    "    # get embeddings for subject 1\n",
    "    for subject in range(NUM_SUBJS):\n",
    "        print(f'---------Obtaining clip and fMRI embedding for subject {subject}-----------------')\n",
    "        y_matrix = get_clip_embedding(subjects_samples[subject], model, processor)\n",
    "        X_matrix = get_fMRI_embedding(subjects_samples[subject])\n",
    "        print(f'Subject {subject} \\n fMRI Embedding Shape: {np.shape(X_matrix)} \\n Text Embedding Shape: {np.shape(y_matrix)}')\n",
    "        \n",
    "        # Split data for training\n",
    "        print(f'---------Spliting data for subject {subject}-----------------')\n",
    "        X_train, X_test, y_train, y_test = split_data(X_matrix, y_matrix)\n",
    "        \n",
    "        print(f'---------Training started for subject {subject}-----------------')\n",
    "        # Train model\n",
    "        model_ = train_model(X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(f'---------Getting two way classification accuracy for subject {subject}-----------------\\n')\n",
    "\n",
    "        batches = 8\n",
    "        accuracy = obtain_two_way_class_result(model_, X_test, y_test, y_matrix, batches)\n",
    "        \n",
    "    print(f'Subject: {subject} \\n Context Length: {length} \\n Average Accuracy: {accuracy}\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
